---
title: "Auto-correlation: correlograms and determination of independent sample"
author: "Andrew Purgiel"
date: "1/13/2021"
output: html_document
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(
  fig.path = 'figures/',
  warning = FALSE,
  message = FALSE,
  echo = FALSE,
  fig.width = 10, fig.height = 3,
  cache = FALSE)
```

```{r libraries}
library(dplyr)
library(purrr)
library(tidyr)
library(openair)
library(ggplot2)
library(readr)
library(googlesheets4)
library(lubridate)
library(gridExtra) #for making ggplot autocorrelation plot grids
library(ggpubr) # for making time series plot grids (with common legends)
library(tseries) # for tests of stationarity

```


```{r data_import, eval = F}

##Import CSV with Real Time Data
omni_hourly<- read_rds('./csv_created_article/omni_hourly_calibrated.rds')


```

# only use data up to June 2021
```{r censor_date, eval = F}
omni_hourly <- omni_hourly %>% filter(datehour<ymd_hms('2021-06-01 00:00:00'))


```



```{r functions_misc}

##Define a char vector of home numbers using a number vector,
##ex: x <- home.list(c(1:15)) for homes 1-15
threedig <- function(x) {
  if (nchar(x) == 1) {a <- paste0('00', x)
  return(a)
  }
  
  if (nchar(x) == 2) {a<- paste0('0', x)
  return(a)
  }
  else return(a)
}

home.list <- function(x) sapply(x, threedig)

# make function to label metric names with subscripts and seasons
labeller.all <- as_labeller(c(
  'pm25'='PM[2.5]', 'voc'="TVOC",
  'co2' = 'CO[2]', 'temp' = 'Temperature', 'humid' = 'Humidity',
  'lux' = 'Light', 'spl_a' = 'Noise',
  'ac' = 'Cooling', 'shoulder' = 'Shoulder', 'heat' = 'Heating',
  'kitchen' = 'Kitchen', 'living' = 'Living Room', 'bedroom' = 'Bedroom',
  'outdoor' = 'Outdoor', 'garage'= 'Garage'
  ), default = label_parsed)

```

```{r define_variables}


#define homes for analysis
homes_all <- home.list(c(1:4, 7:16))

# define indoor rooms
locations_indoor <- c('living', 'bedroom', 'kitchen')

# # define homes that have data for all indoor rooms (if needed)
# homes_avail <- homes_all[-2]

# define metrics for acf testing
metrics_all <- c('pm25', 'voc', 'co2', 'temp', 'humid', 'lux', 'spl_a')

clusters_all <- c('heat', 'shoulder', 'ac')

##For plot labeling pruposes
xsmall <- 6
small <- 15
medium <- 20
large <- 26


# color blind pallette
# check http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/#a-colorblind-friendly-palette
cbbPalette <- c('black' = "#000000",
                'light_orange' = "#E69F00",
                'light_blue' = "#56B4E9",
                'green' = "#009E73",
                'yellow' = "#F0E442",
                'dark_blue' = "#0072B2",
                'dark_orange' = "#D55E00",
                'purple' = "#CC79A7"
                )
# define colors for room-comparisons
room_colors <- c(cbbPalette['green'],
                   cbbPalette['purple'],
                   cbbPalette['light_orange']
                   )%>% unname()

room_breaks <- c('living', 'bedroom', 'kitchen')
room_labels <- c('Living', 'Bedroom', 'Kitchen')

# define colors for energy clusters
energy_colors <- c(cbbPalette['light_blue'],
                   cbbPalette['green'],
                   cbbPalette['dark_orange'],
                   cbbPalette['black'])%>% unname()

energy_breaks <- c('ac', 'shoulder', 'heat', 'overall')
energy_labels <- c('Cooling', 'Shoulder', 'Heating', 'Entire Period')

```


# count the amount of missing data
```{r function_count_missing_values, include = FALSE}

##function to count missing day values for a home/room
count.missing <- function(data, hm, loc, metric,
                          # if start/end date not specified, first and last
                          # date for specified home/location used
                          start_date = '1971-01-01 00:00:00',
                          end_date = '2099-01-01 00:00:00') {
  

          avg_data <- data %>%
  filter(home == hm & location == loc) %>%
                filter(datehour > ymd_hms(start_date) & datehour < ymd_hms(end_date)) %>%
  mutate(date = floor_date(datehour, unit = 'days')) %>%
  group_by(date) %>%
  summarize_if(is.numeric, list(~mean(., na.rm = TRUE))) %>%
  ungroup() %>%
    complete(date = seq(min(date), max(date), by="day"))

  
      a<- avg_data %>%
    select(all_of(metric)) %>%
    is.na() %>%
    sum()
      
  return(a)
}

```

```{r count_missing_values, eval = F}

# count the amount of days completely missing data for all homes in a specified room
 sapply(homes_all, count.missing,
        loc = 'living',
        data = omni_hourly,
       metric = 'pm25')

```


# create datasets with NA input for missing day values for each sensor
```{r create_daily_df, eval = FALSE}

# all homes/locations in one dataframe
# with missing dates put in as NA values
## daily
omni_daily_data_complete <- omni_hourly %>%
  mutate(date = floor_date(datehour, unit = 'days')) %>%
  group_by(home, location, date) %>%
  summarize_if(is.numeric, list(~mean(., na.rm = TRUE))) %>%
    complete(date = seq(min(date), max(date), by="day")) %>%
  ungroup()%>%
  mutate(date = ymd(date)) %>%
  arrange(home, location, date)




```

```{r add_clusters, eval = FALSE}
# add home types ------------------

# classify homes into "types" based on cluster pattern
# and add home types to data

home_type_df <- read_csv('../sense/csv_created_sense_article/home_type_df.csv')

homes_tier3<-home_type_df %>% filter(home_type == 'tier3') %>%
  pull(home) # ac-shoulder-heat

homes_tier2<-home_type_df %>% filter(home_type == 'tier2') %>%
  pull(home) # shoulder-heat (sometimes second shoulder)

homes_tier1<-home_type_df %>% filter(home_type == 'tier1') %>%
  pull(home)


omni_daily_data_complete<- omni_daily_data_complete %>%
  mutate(home_type = case_when(
    home %in% homes_tier3 ~ 'tier3',
    home %in% homes_tier2 ~ 'tier2',
    home %in% homes_tier1 ~ 'tier1',
    TRUE ~ 'unclassified'))



# add date range clusters to data -------------------------

energy_cluster_df <- read_csv('../sense/csv_created_sense_article/energy_cluster_df.csv')

############# using for loop

# make an empty column to fill with cluster function
omni_daily_data_complete$energy_cluster <- NA

#specify all homes that have specified energy clusters
homes_clustered <- levels(as.factor(energy_cluster_df$home))

for(i in 1:length(homes_clustered)) { 
  # for each home
  # identify the df matrix index of each cluster cluster_type
  cluster_type_indeces <- which(energy_cluster_df$home == homes_clustered[i])

    for(j in 1:length(cluster_type_indeces)) {
    # for each cluster type in each home in the energycluster dataframe
      # indentify the values in the data that are match the home
      # and are within the dates specified by the cluster
    omni_daily_data_complete$energy_cluster[
      which(omni_daily_data_complete$home == homes_clustered[i] &
              between(omni_daily_data_complete$date,
                      energy_cluster_df[cluster_type_indeces[j],
                                      'start_date'][[1]],
                      energy_cluster_df[cluster_type_indeces[j],
                                      'end_date'][[1]])
      )
      # add the identified cluster type of each value
      # in the new column in the data
    ] <- energy_cluster_df[cluster_type_indeces[j], 'cluster_type'][[1]]
  }
}

# convert any NA clusters to "unclassified"
omni_daily_data_complete <- omni_daily_data_complete %>%
  mutate(energy_cluster = if_else(is.na(energy_cluster), 'unclassified', energy_cluster))




```

```{r daily_df_csv, eval = FALSE}
# make a df with rows of NA for days within each home with no data
write_csv(omni_daily_data_complete, paste0('./csv_created_article/acf/omni_daily_data_complete.csv'))

# create dated backup
write_csv(omni_daily_data_complete, paste0('./csv_created_article/acf/omni_daily_data_complete_', Sys.Date(),'.csv'))

```

```{r import_daily_data}
omni_daily_data_complete <- read_csv('./csv_created_article/acf/omni_daily_data_complete.csv')

```

# Autocorrelation plots  

#specify omission criteria    
```{r ggacf_omission_criteria}
# not omitted, but highligthed in ggacf plots, and possibly omitted later
days_avail_min <- 25
pairs_min <- 20
missing_pct_min <- 1/9*100

```



```{r ggacf_function, include= FALSE}

# # # variables for testing-----------------
# data <- omni_daily_data_complete
# hm <- '001'
# loc <- 'kitchen'
# met <- 'pm25'
# lag.max <- 14
# cluster <- 'heat'
# type <- 'correlation'
# ci <- 0.95
# ci.col <- 'blue'
# 
# rm(data, hm, loc, met, lag.max, cluster, type, ci, ci.col)

##Define an autocorrelation plot function in ggplot------------------

###Make acf function in ggplot
##from: https://stackoverflow.com/questions/28857241/r-combine-plots-that-use-parmfrow-internally

ggacf <- function(data,  hm, loc, met, cluster,
                  lag_max_plot = 30,ci=0.95, type="correlation") {

    x <- data %>% 
    filter(home == hm & location == loc)
  
  x<- if(!is.null(cluster)) {
    # filter by cluster if cluster is specified
    x %>% 
      filter(energy_cluster == cluster) %>%
      pull(all_of(met))
    }else {
    x %>% 
      pull(all_of(met))
    }

  if(length(x) < 3) return() # don't calculate anything if there are less than 
  
  # count days in monitoring period with available data
  days_avail <- sum(!is.na(x))
  
  # count percentage of missing values
  missing <- sum(is.na(x))/length(x)*100
  
  # set limit of how many lags for which the function performs calculations
  lag_max_calc <- if_else(length(x)<=31, length(x)-1, 30)
  
  x_acf <- acf(x, plot=F, lag.max=lag_max_calc, type=type,
               
               ##if missing a value, continue calculation
               ##with line below in acf function
               na.action = na.pass
  )
  
  # find actual n value (doesn't count when one of the data in a pair is NA)
  lags <- c(1:lag_max_calc)
  
  lag_counts <- map(lags, function(x) {
    data %>%
      filter(home == hm & location == loc & energy_cluster == cluster)%>%
      pull(all_of(met)) %>%
      diff(lag = x) %>%
      is.na() %>%
      `!` %>% #count how many are not NA
      sum()
  }
  ) %>% 
    unlist() %>%
    as.data.frame()%>%
    rename('n_lag'= '.') %>%
    mutate(lag = lags)
  
  df_acf <- data.frame(lag=x_acf$lag, acf=x_acf$acf,
                       n_lag = if(type == 'correlation') {
                         c(NA,lag_counts$n_lag)
                       } else if(type == 'partial') lag_counts$n_lag ) %>%
    mutate(
      # from UMich Notes, Sales et al. 1980
      ci_high = -qnorm((1-ci)/2)/sqrt(n_lag),
      ci_low = qnorm((1-ci)/2)/sqrt(n_lag)
      
    )%>%
    mutate(home =hm, location = loc, energy_cluster = cluster, metric = met,
           miss = missing, avail = days_avail)
}

#test------------
# test <- ggacf(data = omni_daily_data_complete,
#                   hm = '001', loc = 'bedroom',
#                   met = 'pm25', cluster = 'heat')
    
```


# make data and csv
```{r, eval = FALSE}

# make data for all available sensors
acf_data <- map(
  metrics_all, function(x_metric){
    
    map(
      locations_indoor, function(x_location){
        
        map(
          homes_all, function(x_home) {
            
        map(
          clusters_all, function(x_cluster) {
            
            ggacf(data = omni_daily_data_complete,
                  hm = x_home, loc = x_location,
                  met = x_metric, cluster = x_cluster)
          })%>%
  bind_rows()
      })%>%
  bind_rows()
  })%>%
  bind_rows()
  }) %>%
  bind_rows() %>%
  mutate(pair_amount = ifelse(n_lag > pairs_min, 'enough', 'not_enough'))


write_csv(acf_data, './csv_created_article/acf/acf_data.csv')

write_csv(acf_data, paste0('./csv_created_article/acf/acf_data_', Sys.Date(), '.csv'))

```

# import acf_data
```{r}
acf_data <- read_csv('./csv_created_article/acf/acf_data.csv')
```


# plot ACF for all conditions

* define function
```{r}
acf.grid <- function( loc, clust, n_rows = 2){
  map(
   c('pm25', 'voc', 'co2'), function(x_metric){
    
    map(
      loc, function(x_location){

            
        map(
          clust, function(x_cluster) {

a <- acf_data %>% filter(metric == x_metric, energy_cluster == x_cluster,
                         location == x_location)%>%
  mutate(pair_amount = ifelse(n_lag > pairs_min, 'enough', 'not_enough')) %>%
  filter(lag<=30)

   location_label <- case_when(
     loc == 'bedroom' ~ 'Bedroom',
     loc == 'kitchen' ~ 'Kitchen',
     loc == 'living' ~ 'Living Room'
     )
   
      season_label <- case_when(
     clust == 'ac' ~ 'Cooling Season',
     clust == 'shoulder' ~ 'Shoulder Season',
     clust == 'heat' ~ 'Heating Season'
     )

ggplot(a, aes(x = lag, y = acf))+
  geom_hline(yintercept=0) +
    geom_segment(aes(xend=lag, yend=0,
                     color = pair_amount))+ 
  scale_color_manual(
    breaks = c('enough', 'not_enough'),
    values = c('black', 'red'),
    labels = c(paste0('n>', pairs_min),
               paste0('n<', pairs_min)),
    name = 'Lag Pairs'
  )+
    geom_line(aes(x = lag, y = ci_high),
              linetype = 'dashed', color = 'blue')+
    geom_line(aes(x = lag, y = ci_low),
              linetype = 'dashed', color = 'blue')+
    # geom_text(aes(x = lag, y = acf+0.05, label = n_lag),
    #           size = xsmall)+ # annotate w/ n used to calculate acf for each lag
    theme_bw() +
    xlab("Lag, days") +
    # geom_text(aes(label=paste('*missing', signif(unique(miss),3), '%')), x = 15, y = 0.6)+
  facet_wrap(c('home'), nrow = n_rows)+
  ylab('ACF')+
  ggtitle(paste0( location_label, ', ', season_label))+
  theme(
    strip.background = element_blank(),
    strip.text = element_text(size = small -3),
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_blank(),
    axis.text = element_text(size = small -3),
    axis.title = element_text(size = small -3),
    legend.text = element_text(size = small -3),
    legend.title = element_text(size = small -3)
  )+
  scale_x_continuous(
    breaks = c(0,7,14,21, 28)
  )

})
      })
   })
}
```



```{r, fig.height = 2, fig.width = 6, eval = F}
acf.grid('living', 'ac', n_rows = 1)
```

```{r, fig.height = 3.5, fig.width = 8, eval = F}
acf.grid('living', 'shoulder')
```

```{r, fig.height = 3.5, fig.width = 8, eval = F}
acf.grid('living', 'heat')
```




```{r, fig.height = 2, fig.width = 4, eval = F}
acf.grid('kitchen', 'ac', n_rows = 1)
```

```{r, fig.height = 3.5, fig.width = 6, eval = F}
acf.grid('kitchen', 'shoulder')
```

```{r, fig.height = 3.5, fig.width = 8, eval = F}
acf.grid('kitchen', 'heat')
```





```{r, fig.height = 2, fig.width = 8, eval = F}
acf.grid('bedroom', 'ac', n_rows = 1)
```

```{r, fig.height = 3.5, fig.width = 8, eval = F}
acf.grid('bedroom', 'shoulder')
```

```{r, fig.height = 3.5, fig.width = 8, eval = F}
acf.grid('bedroom', 'heat')
```


* Example ACF plots 
```{r}
# Example ACF plots for high and low amounts of data points
# Homes 4 and 7, VOC, Shoulder

a <- acf_data %>% filter(metric == 'voc', energy_cluster == 'shoulder',
                         location == 'living', home %in% c('004', '007'))%>%
  mutate(pair_amount = ifelse(n_lag > pairs_min, 'enough', 'not_enough')) %>%
  filter(lag<=30)



ggplot(a, aes(x = lag, y = acf))+
  geom_hline(yintercept=0) +
    geom_segment(aes(xend=lag, yend=0,
                     color = pair_amount))+ 
  scale_color_manual(
    breaks = c('enough', 'not_enough'),
    values = c('black', 'red'),
    labels = c(paste0('n>', pairs_min),
               paste0('n<', pairs_min)),
    name = 'Lag Pairs'
  )+
    geom_line(aes(x = lag, y = ci_high),
              linetype = 'dashed', color = 'blue')+
    geom_line(aes(x = lag, y = ci_low),
              linetype = 'dashed', color = 'blue')+

    theme_bw() +
    xlab("Lag, days") +
    # geom_text(aes(label=paste('*missing', signif(unique(miss),3), '%')), x = 15, y = 0.6)+
  facet_wrap(c('home'))+
  ylab('ACF')+
  # ggtitle(paste0( location_label, ', ', season_label))+
  theme(
    strip.background = element_blank(),
    panel.grid.minor = element_blank(),
    panel.grid.major.y = element_blank(),
    # strip.text = element_text(size = small -3),
    # axis.text = element_text(size = small -3),
    # axis.title = element_text(size = small -3),
    # legend.text = element_text(size = small -3),
    # legend.title = element_text(size = small -3)
  )+
  scale_x_continuous(
    breaks = c(0,7,14,21, 28)
  )

```


# count data that will be omitted, but dont omit data from csv
```{r}

##### Count data that will be omitted (but don't omit yet) 

# isolate 3 metrics considered in thesis
acf_ieq <- acf_data %>%
  filter(metric %in% c('pm25', 'voc', 'co2', 'temp'))


  # make dataframe with counts of different types of "missingness"
# for each condition for all metrics


  acf_lags2 <- acf_ieq %>%
        group_by(home, location, energy_cluster, metric) %>%
    summarise(
              days_avail = unique(avail),
              missing_pct = unique(miss),
              .groups = 'drop')%>% 
    left_join(
      acf_ieq %>%
      filter(acf <= ci_high
           & acf >= ci_low
    ) %>%
        group_by(home, location, energy_cluster, metric) %>%
    summarise(lag_signif = min(lag),
              .groups = 'drop'),
    by = c("home", "location", "energy_cluster", "metric")
  )

  # count amount of homes for each indicator for each condition
n_homes <- acf_lags2 %>% count(metric, location, energy_cluster)

# count amount of condtions for each metric
n_conditions<- acf_lags2 %>%
  count(metric)


# omit smaples that had less than the minimum days available
# and count remaining samples by metric
acf_day_omit <- acf_lags2 %>%
  filter(days_avail >= days_avail_min)

n_day_omit <- acf_day_omit %>%
  count(metric)


# omit smaples that were missing more than 11.1% of days in sampling period
# and count remaining samples by metric
acf_pct_omit <- acf_day_omit %>%
  filter(missing_pct <= missing_pct_min)

n_pct_omit <- acf_pct_omit %>%
  count(metric)

# omit smaples that did not achieve insignificant ACF by 30 days
# and count remaining samples by metric
acf_sig_omit <- acf_pct_omit %>%
  filter(!is.na(lag_signif))

n_sig_omit <- acf_sig_omit %>%
  count(metric)


#### Make CSV, wihtout omitting data

  # find first lag point when acf goes inside confidence intervals
  acf_lags <- acf_data %>%
    filter(acf <= ci_high
           & acf >= ci_low
    ) %>%
        group_by(home, location, energy_cluster, metric) %>%
    summarise(lag_signif = min(lag),
              days_avail = unique(avail),
              missing_pct = unique(miss),
              .groups = 'drop')


```

# make lag df
* make csvs
```{r, eval = F}

#write file
write_csv(acf_lags, paste0('./csv_created_article/acf/acf_lags.csv'))

# create dated backup
write_csv(acf_lags, paste0('./csv_created_article/acf/acf_lags_',Sys.Date(), '.csv'))

```


## Plots of all homes without clusters


### for some homes, acf stops decreasing (especially pm25), likely due to non-stationarity of data  

### shorter time periods due seem to avoid the slow decrease, see home 002 only has slight issue in one time period


## Calculate how many lags (days) it takes for pollutant/metric to
## not be significantly autocorrelated


```{r acf_lag_data_import}
acf_lags <- read_csv('./csv_created_article/acf/acf_lags.csv')
```


```{r lag_df_omissions}

#  omit samples that have less than available days specified above (days_avail_min)
# and omit samples with a missing pct greater than % specified above
# (missing_pct_min)


acf_lags_filter <- acf_lags %>%
  # mutate(lag_signif = if_else(is.infinite(lag_signif), 35, lag_signif)) %>%
  filter(days_avail >=days_avail_min & missing_pct <= missing_pct_min)

n_metrics_lags <- acf_lags %>% pull(metric) %>% as.factor() %>% levels() %>% length()


```



```{r lag_plots, fig.height = 3, fig.width = 8, eval = TRUE}

####### compare all metrics, pooled cluster periods-------
a <- acf_lags_filter %>% 
  filter(energy_cluster %in% c('ac', 'shoulder', 'heat'))%>%
  filter(metric %in% c('pm25', 'voc', 'co2', 'temp'))

# change order for plotting
a$location <- factor(a$location, levels = c('kitchen', 'living', 'bedroom'))
a$metric <- factor(a$metric, levels = c('pm25', 'voc', 'co2', 'temp'))
a$energy_cluster <- factor(a$energy_cluster, levels = c('ac', 'shoulder', 'heat'))

inf_count <-a %>% filter(lag_signif %>%is.infinite()) %>% nrow()

# make n labels
n_labels <- a %>%
  filter(lag_signif %>%is.finite()) %>%
  group_by(location, metric) %>%
  summarise(
    label_position=median(lag_signif, na.rm= TRUE)+5,
    label_value=n(), .groups = 'drop'
  ) %>%
  mutate(label_value = paste0('n=',label_value))

# boxplots by location, pooled clusters
ggplot(data = a ,
       aes(x = location, y = lag_signif))+
  geom_boxplot(outlier.shape = NA)+
  geom_jitter(aes(
    color=energy_cluster,
  #   shape = ifelse(is.infinite(lag_signif),
  #                  '4',
  #                  '16')
   ),
  height = 0)+
  facet_wrap(vars(metric), labeller = labeller.all, nrow  = 1)+
  # scale_y_continuous(oob= scales::squish_infinite)+
  scale_x_discrete(
    limits = room_breaks,
    labels = room_labels
  )+
 scale_color_manual(name = "Season",
                       breaks = energy_breaks,
                       labels = energy_labels,
                     values = energy_colors,
                       guide = "legend")+
  geom_text(data=n_labels, aes(x = location, y=19,
                               label=label_value),vjust=0)+
  coord_cartesian(ylim= c(0,30))+
  ylab('Day Lags Before Insignificance')+
  xlab('Room')+
  theme_bw()+
  theme(
    panel.grid.major.x = element_blank(),
        strip.background = element_blank(),
    strip.text = element_text(size = small -3),
    axis.text.y = element_text(size = small -3),
    axis.text.x = element_text(size = small -4),
    axis.title = element_text(size = small -3),
    legend.text = element_text(size = small -3),
    legend.title = element_text(size = small -3)
  )+
  scale_y_continuous(
    breaks = c(0,7,14,21,28)
  )
  

###########

####### compare all metrics, pooled rooms---------

# make n labels
n_labels <- a %>%
  filter(lag_signif %>%is.finite()) %>%
  group_by(energy_cluster, metric) %>%
  summarise(
    label_position=median(lag_signif, na.rm= TRUE)+5,
    label_value=n(), .groups = 'drop'
  ) %>%
  mutate(label_value = paste0('n=',label_value))

# boxplots by cluster, pooled rooms
ggplot(data = a ,
       aes(x = energy_cluster, y = lag_signif))+
  geom_boxplot(outlier.shape = NA)+
  geom_jitter(aes(
    color=location,
  #   shape = ifelse(is.infinite(lag_signif),
  #                  '4',
  #                  '16')
   ), 
  height = 0)+
  facet_wrap(vars(metric), labeller = labeller.all, nrow  = 1)+
  # scale_y_continuous(oob= scales::squish_infinite)+
    scale_x_discrete(
    limits = energy_breaks[c(1:3)],
    labels = energy_labels[c(1:3)]
  )+
  scale_color_manual(name = "Room",
                       breaks = room_breaks,
                       labels = room_labels,
                       values = room_colors,
                       guide = "legend")+
  geom_text(data=n_labels, aes(x = energy_cluster, y=19,
                               label=label_value),vjust=0)+
    coord_cartesian(ylim= c(0,30))+
  ylab('Day Lags Before Insignificance')+
    xlab('Season')+
  theme_bw()+
  theme(
    panel.grid.major.x = element_blank(),
        strip.background = element_blank(),
    strip.text = element_text(size = small -3),
    axis.text.y = element_text(size = small -3),
    axis.text.x = element_text(size = small -4),
    axis.title = element_text(size = small -3),
    legend.text = element_text(size = small -3),
    legend.title = element_text(size = small -3)
  )+
  scale_y_continuous(
    breaks = c(0,7,14,21,28)
  )


```

## seems to be not much difference in significant lag by room,
## but may be difference between clusters
## however, this could be due to heating periods beings longer, and less stationary

```{r lag_table_csv, eval = FALSE}
# don't include Inf values in calculations
acf_lags_finite <- acf_lags_filter %>%
    filter(!is.infinite(lag_signif))


lag_summary_cluster <- acf_lags_finite %>%
    filter(energy_cluster %in% c('heat', 'ac', 'shoulder'))%>%
  group_by(metric, energy_cluster) %>%
  summarise(median = median(lag_signif),
            q3 = quantile(lag_signif, probs= 3/4),
                        mean = mean(lag_signif),
            sd = sd(lag_signif), 
                 n = sum(days_avail),
                        .groups = 'drop')

lag_summary_total <- acf_lags_finite %>%
  filter(energy_cluster %in% c('heat', 'ac', 'shoulder'))%>%
  group_by(metric) %>%
  summarise(median = median(lag_signif),
            q3 = quantile(lag_signif, probs= 3/4),
                                    mean = mean(lag_signif),
            sd = sd(lag_signif), 
                 n = sum(days_avail),
            .groups = 'drop') %>%
  mutate(energy_cluster = 'total')

lag_summary <- bind_rows(lag_summary_total, lag_summary_cluster)

# write file
write_csv(lag_summary, paste0('./csv_created_article/acf/lag_summary.csv'))
# create dated backup file
write_csv(lag_summary, paste0('./csv_created_article/acf/lag_summary_', Sys.Date(), '.csv'))

```


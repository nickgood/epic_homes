---
title: "Representativity"
output:
  html_document:
    toc: true
    toc_float: true
    theme: paper
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.path = 'figures/',
  warning = FALSE,
  message = FALSE,
  echo = FALSE,
  fig.width = 10, fig.height = 3,
  cache = FALSE)
```

```{r libraries, include=FALSE}
library(dplyr)
library(purrr)
library(tidyr)
library(openair)
library(ggplot2)
library(readr)
library(googlesheets4)
library(lubridate)
library(gridExtra)
library(runner) # for moving window functions
library(ggpubr) # for tesing log-normality
# library(cubature) # for alternative method of integrating kld function
# library(entropy) # for KLD function
# library(fitdistrplus) # for fitting distribution to data NOTE, MASS::select CONFLICTS WITH dplyr::select

```

```{r import_omni_minute_data, eval = FALSE}
# omni_data<- read_csv('./csv_created/omni_all_locations.csv')
# 
# zero_test <- omni_data %>%
#   group_by(home, location) %>%
#   summarize(pm25_zeros = sum(pm25 == 0), pm25_n = n()) %>%
#   mutate(pm25_zero_pct = pm25_zeros/pm25_n*100) %>%
#   ungroup()



```

```{r import_omni_hourly, eval = TRUE}
omni_hourly<- read_rds('./csv_created/omni_hourly_calibrated.rds')

```


```{r censor_date}
omni_hourly <- omni_hourly %>% filter(datehour<ymd_hms('2021-06-01 00:00:00'))


```

```{r import_energy_cluster_homes}
# import energy cluster dataframe for all homes
energy_cluster_df <- read_csv('../sense/csv_created_sense/energy_cluster_df.csv')
```

```{r import_acf_lags}
# import summary df of how many lags required
# before autocorrelation was insignificant
lag_summary_df <- read_csv('./csv_created/lag_summary.csv')
```



```{r functions_misc}

#Function to only display 3 significant figures (for tables)
signif3 <- function(x){
  signif(x, digits = 3)
}

##Define a char vector of home numbers using a number vector,
##ex: x <- home.list(c(1:15)) for homes 1-15
threedig <- function(x) {
  if (nchar(x) == 1) {a <- paste0('00', x)
  return(a)
  }
  
  if (nchar(x) == 2) {a<- paste0('0', x)
  return(a)
  }
  else return(a)
}

home.list <- function(x) sapply(x, threedig)


# give a row of NA values with identifers to help with identifying
# causes of errors in function
na.result <- function(error, location = NA, season = NA, n_data_avail = NA) {
  tibble(
  'info_gain' = NA,
  'location' = location, # sample_length,
  'monitor_season' = season, # period_label,
  'n_data_avail' = n_data_avail,
  'error' = error,
  'warn' = warn # return warning if triggered
)
}

# make function to label metric names with subscripts
labeller.metrics <- as_labeller(c('pm25'='PM[2.5]', 'voc'="TVOC"),
                           default = label_parsed)

# make function to label season names
labeller.clusters <- as_labeller(c('ac'='Summer', 'heat'="Winter",
                                  'shoulder' ='Shoulder'),
                           default = label_parsed)

```

```{r define_variables}

# list of all home numbers
homes_all <- home.list(1:17)

clusters_all <- c('heat','shoulder', 'ac')
locations_indoor <- c('living', 'kitchen', 'bedroom')
metrics_all <- c('pm25', 'voc')

# sequence of representative thresholds to test
threshold_seq <- c(0.1, 0.2, 0.3)

# sequence of days to test thresholds for shape entropy values

pdf_days <- c(3,7,10,14,21)

warn <- 'none'

# color blind pallette
# check http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/#a-colorblind-friendly-palette
cbbPalette <- c('black' = "#000000",
                'light_orange' = "#E69F00",
                'light_blue' = "#56B4E9",
                'green' = "#009E73",
                'yellow' = "#F0E442",
                'dark_blue' = "#0072B2",
                'dark_orange' = "#D55E00",
                'purple' = "#CC79A7"
                )
# define colors for energy clusters
energy_colors <- c(cbbPalette['light_blue'],
                   cbbPalette['green'],
                   cbbPalette['dark_orange'])%>% unname()
energy_shapes <- c(15, 16, 17)
energy_breaks <- c('ac', 'shoulder', 'heat')
energy_labels <- c('Summer', 'Shoulder', 'Winter')

```

```{r function_info_gain_master}

# calculate kld for continuous probability distributions

# define variables for testing-----------------------

# date_ranges_entire <- list(c('2020-08-26', '2020-12-01'))
# home_num <- '011'
# data <- omni_hourly
# monitor_season <- date_ranges_entire[1]
# metric <- 'voc'
# all_time <- TRUE
# warn <- 'none'
# room <- 'living'
# season_avail_limit <- 0
# 
# 
# # remove variables after done testing
# rm(tested_sample_sequence,
#    date_ranges_entire,
# home_num,
# monitor_season,
# monitor_period,
# metric,
# days,
# days2,
# all_time,
# data,
# data_season,
# data_year,
# entire,
# date_col_season,
# date_col_year,
# all_dates_season,
# all_dates_year,
# room,
# season_avail_limit
# )

# entropy function hourly data ----------------------------

    
# function to calculate scaled entropy for a house
# during multiple different time periods
info.gain.table <- function(
  home_num, metric,
  
  # date range of entire monitoring period
  # in the form: list(
  #                    c('YYYY-MM-DD', 'YYYY-MM-DD'),
  #                    c('YYYY-MM-DD', 'YYYY-MM-DD')
  #                  )
  # data in start and end day included
  date_ranges_entire,
  sample_length, # sampling period lengths (days)
season_avail_limit = 0, # only use data from a sensor if it has at least this fraction of data available (0 means no periods are omitted if they have any data)
all_time = TRUE, # if TRUE, compare each short sampling period to entire monitoring year of home
data = omni_hourly) {
  
  output <<- na.result(NA) # clear error output in case it was triggered previously
  warn <<- 'none'# clear warning output in case it was triggered previously
  
  if(metric %in% c('pm25', 'voc')) {
    # define LOD of metric to be 1/2 minimum detected (non-zero) value
    LOD <- data %>%
      filter(!!sym(metric)!=0) %>%
      pull(all_of(metric))%>%
      min()
  }
  
  
  # function to find scaled_entropy for samples in a given monitor season
  
  info.gain.season <- function(monitor_season) {
    
    
    # must unlist the listed range that is used in lapply funnction
    monitor_season <- unlist(monitor_season)
    
    # stop if monitoring season is empty
    if(is_empty(monitor_season)) {
      output <<- na.result('likely_no_cluster')
      stop()
    } 
    
    
    #define label for later use in table
    period_label <- paste(as.Date(monitor_season[1]), '-',
                          as.Date(monitor_season[2]))
    
    # warn that times will be rounded to full day for entire monitoring period
    
    if(
      any( c(
        second(as.POSIXct(monitor_season[1])),
        minute(as.POSIXct(monitor_season[1])),
        hour(as.POSIXct(monitor_season[1])),
        
        second(as.POSIXct(monitor_season[2])),
        minute(as.POSIXct(monitor_season[2])),
        hour(as.POSIXct(monitor_season[2]))) > 0
      )
    ) {
      output <<- na.result('incorrect_date',
                           period_label)
      stop()
    }
    
    #     # make column of all dates (increments ofhour) within year
    # # including all locations
    # all_dates_year <- seq.POSIXt(
    #   from = as.POSIXct(
    #     data %>%
    #   filter(home == home_num &
    #            location %in% c('living', 'bedroom', 'kitchen'))%>%
    #     pull(datehour) %>% min(), tz = 'UTC'),
    # 
    #   to =  as.POSIXct( data %>%
    #   filter(home == home_num &
    #            location %in% c('living', 'bedroom', 'kitchen'))%>%
    #     pull(datehour) %>% max(), tz = 'UTC'),
    #   by = '5 min')
    
    # make column of all dates (increments ofhour) within season
    # including all locations
    all_dates_season <- seq.POSIXt(
      from = as.POSIXct(monitor_season[1],tz = 'UTC'),
      to =  floor_date(as.POSIXct( monitor_season[2],
                                   tz = 'UTC')+24*60*60-1,
                       unit = 'hour'), by = 'hour')
    
    # make df for recorded values in season for given location
    data <-   data %>%
      select(datehour, home, location, all_of(metric))%>%
      filter(home == home_num,location %in% locations_indoor) %>%
      # choose season date range
      filter(
        datehour >= ymd(monitor_season[1]) &
          datehour <= ymd(monitor_season[2])
      )
    
    if(metric %in% c('pm25', 'voc')) {
      # convert 0 values to LOD/2 in to allow for log-normal distrib. estimation
      data <- data %>%
        mutate_at(all_of(metric), function(x) ifelse(x==0, LOD/2, x))
    }
    
    # check data availability for entire season for each room
    # and define which rooms have enough data
    rooms_with_data <- data %>%
      group_by(location) %>%
      summarize(n_avail = n()/length(all_dates_season)) %>%
      filter(n_avail > season_avail_limit) %>%
      pull(location)
    
    # give error if not all three rooms have enough data
    if(length(rooms_with_data) < 3){
      output <<- na.result(paste0('only_data_',paste0(rooms_with_data,
                                                      collapse = '_')))
      stop()
    }
    
    
    data_wide <- data %>%
      pivot_wider(names_from = c(location),
                  values_from = all_of(metric))
    
    # function to be applied to each room individually
    # to determine covariance matrix, variance of each room, and relative mutual info
    
    # note location of missing values across all room data sets
    # so the variance can be corrected
    # in the mutual information calculation
    missing_indeces <- lapply(rooms_with_data, function(x) {
      data_wide %>% pull(x) %>% is.na() %>% which()
    }) %>%
      unlist()
    
    #remove incolmplete rows and take log
    data_wide_complete_log <- if(is_empty(missing_indeces)) {
      data_wide%>%
        mutate_if(is.numeric, log)
    } else{
      data_wide %>% slice(-c(missing_indeces)) %>%
        mutate_if(is.numeric, log)
    }
    
    # make matrix with cov function
    #NOTE: if a value is missing from one data set, the function will delete that value from all data-sets when calculating variance and covariance
    
    
    info_gain_rooms <- 
      map(rooms_with_data,
          function(room){

            other_rooms <- rooms_with_data[-which(rooms_with_data == room)]
            
            # calculate info gain based on Osses Equation 4
            cov_mat_all <- cov(matrix(c(
              data_wide_complete_log %>% pull(room),
              data_wide_complete_log %>% pull(other_rooms[1]),
              data_wide_complete_log %>% pull(other_rooms[2])
            ), ncol = 3))
            
            cov_mat_complement <- cov(matrix(c(
              data_wide_complete_log %>% pull(other_rooms[1]),
              data_wide_complete_log %>% pull(other_rooms[2])
            ), ncol = 2))
            
            cov_complement <- cov(
              data_wide_complete_log %>% pull(other_rooms[1]),
              data_wide_complete_log %>% pull(other_rooms[2])
            )


            
            variance_complement <-
              (
              var(data_wide_complete_log %>% pull(other_rooms[1])) +
                var(data_wide_complete_log %>% pull(other_rooms[2])) +
                2*cov_complement
            )/
              length(other_rooms)^2
            
            
            
                        info_gain <-
              -0.5*
                  log(
                    det(cov_mat_all)/
                        (det(cov_mat_complement)*variance_complement)
                    )
            
            list('info_gain' = info_gain,
                 'location' = room,
                 'monitor_season' = period_label,
                 # amount of data points  for which all three rooms were available
                 'n_data_avail' = nrow(data_wide_complete_log) 
            )
          }
      ) %>%
      bind_rows()
    
    # add no error note, and warning if triggered
    c(
      info_gain_rooms,
      list(
        'error' = rep('none', nrow(info_gain_rooms)),
        'warn' = rep(warn, nrow(info_gain_rooms))
      )
    )
    
    
  }%>%
    # if season results in an error, return the error message in a df
    tryCatch(error = function(e) output)
  
  # info_gain for all specified date ranges  
  info_gain_data_season <- lapply(date_ranges_entire, info.gain.season)
  
  
  # bind all into a dataframe
  bind_rows(info_gain_data_season) %>%
    mutate(
      home = home_num,
      metric = metric,
      period_compare = ifelse(all_time == TRUE, 'year', 'season'))
}

 


# test function--------------------------

# start <- Sys.time()
# 
# test<- info.gain.table('004', 'pm25',
# 
#                            date_ranges_entire = list(
#                              c('2020-12-01', '2020-12-31'),
#                                                      c('2020-11-01',
#                                                        '2020-11-30')),
#                            all_time = TRUE)
# end <- Sys.time()
# run2 <- end- start

```

```{r functions_csv_creation}

# make functions to look up starting and ending date of
# energy cluster period based on home
 pick.start <- function(x_home, x_cluster) {
   energy_cluster_df %>%
   filter(home == x_home & cluster_type == x_cluster) %>%
   pull(start_date) %>% as.character()
 }
 
  pick.end <- function(x_home, x_cluster) {
   energy_cluster_df %>%
   filter(home == x_home & cluster_type == x_cluster) %>%
   pull(end_date) %>% as.character()
  }
  
  # fun to pick minimum sample length to test based on metric
  pick.sample.min <- function(x_metric) {
    lag_summary_df %>%
      # use the pooled median of all clusters
      filter(metric == x_metric, energy_cluster == 'total') %>%
      pull(median)
  }
  
  # # test functions
   # pick.start('006', 'heat')
  # pick.end('004', 'heat')
```


```{r data_maker, eval = FALSE}

all_time_choice <- TRUE

info_gain_df <-  
  
  lapply(metrics_all, function(x_metric) {
    
    lapply(clusters_all, function(x_cluster) {
      
      lapply(homes_all, function(x_home) {
        
        start_date <- pick.start(x_home, x_cluster)
        end_date <- pick.end(x_home, x_cluster)
        
        
        
        info.gain.table(
          x_home, metric = x_metric,
          date_ranges_entire = list(c(start_date,
                                      end_date)),
          all_time = all_time_choice) %>%
          # add in column for energy_cluster
          mutate(energy_cluster = x_cluster) 
      }
      ) %>%
        bind_rows()
      
    }
    ) %>%
      bind_rows()
  }
  ) %>%
  bind_rows()

# make csv of all data
write_csv(info_gain_df, file =
            paste0('./csv_created/representativeness_data/info_gain.csv'))
# make dated backup
write_csv(info_gain_df, file =
            paste0('./csv_created/representativeness_data/info_gain_',
                   Sys.Date(), '.csv'))



```

# Plotting

```{r import_info_gain_data}
info_gain_df <- read_csv('./csv_created/representativeness_data/info_gain.csv')

```


```{r omissions_cleaning}
# remove na spec values from runs
info_gain_df_clean <- info_gain_df%>% 
  filter(period_compare == 'year', # only comparing sample to whole mon. period
         !is.na(info_gain)) # with insufficient data in cluster/year/no cluster

```


```{r create_rep_df}

represent_df <- info_gain_df_clean %>%
  group_by(home, metric) %>%
  mutate(info_gain_max = max(info_gain), info_gain_min = min(info_gain)) %>%
  ungroup() %>%
  mutate(represent = (info_gain- info_gain_min)/(info_gain_max-info_gain_min))


unwanted_scaled_na <- represent_df %>%
  filter(represent %>% is.na())

```

### `r unwanted_scaled_na %>% nrow()` unexpected missing values in representativity data

## Boxplot of Values
```{r plot_rep_rooms, fig.width = 7, fig.height = 3}

ggplot(represent_df, aes(x = location, y = represent))+
  geom_boxplot(outlier.shape = NA)+
  geom_jitter( aes(color = energy_cluster, shape = energy_cluster),
               width = 0.1)+
  facet_wrap(vars(metric), labeller = labeller.metrics)+
  # specify shape and color for each season
  list(
    scale_color_manual(
      breaks = energy_breaks,
                     values = energy_colors,
                     labels = energy_labels,
                     name = 'Season'
                     ),
  scale_shape_manual(
    breaks = energy_breaks,
                     values = energy_shapes,
                         labels = energy_labels,
                     name = 'Season'
    )
  )+
  theme_classic()+
  xlab('Room')+
  ylab('Representativeness')
```


## Rank Table of Values

### All seasons together
```{r table_rank, fig.height = 3.5, fig.width = 8}

a <- represent_df %>%
  group_by(home, energy_cluster, metric) %>%
  mutate(rank = rank(represent) %>% as.factor()) %>%
  ungroup() %>%
  mutate(home_clust = interaction(home, energy_cluster),
         loc_abbr = toupper(substring(location, 1,1)))

ggplot(a, (aes(x = home, y = rank)))+
  geom_text(aes(label = loc_abbr, color = energy_cluster,
                group = energy_cluster),
            position =position_dodge(width = 1)
            )+
  facet_wrap(vars(metric), labeller = labeller.metrics)+
  theme_minimal()+
  theme(panel.grid = element_blank())+
  scale_y_discrete(breaks = c('1','2','3'),
                   labels = c('Lowest', '', 'Highest'))+
  ylab('Representativeness Rank')+
  xlab('Home')+
  geom_vline(
    xintercept = seq(1.5,length(a %>% pull(home)%>%as.factor%>% levels)-0.5, 1),
    color = 'grey')+ # insert lines between homes
  scale_color_manual(breaks = energy_breaks,
                     values = energy_colors,
                     labels = energy_labels,
                     name = 'Season')


```

### Seasons Separate
```{r table_rank_season, fig.height = 3.5, fig.width = 8}

# rank.table <- function (x_energy_cluster){
#   
# a <- represent_df %>%
#   filter(energy_cluster == x_energy_cluster) %>%
#   group_by(home, energy_cluster, metric) %>%
#   mutate(rank = rank(represent) %>% as.factor()) %>%
#   ungroup() %>%
#   mutate(
#          loc_abbr = toupper(substring(location, 1,1)))
# 
# ggplot(a, (aes(x = home, y = rank)))+
#   geom_text(aes(label = loc_abbr))+
#   facet_wrap(vars(metric), labeller = labeller.metrics)+
#   theme_minimal()+
#   theme(panel.grid = element_blank())+
#   scale_y_discrete(breaks = c('1','2','3'),
#                    labels = c('Lowest', '', 'Highest'))+
#   ylab('Representativeness Rank')+
#   xlab('Home')+
#   geom_vline(
#     xintercept = seq(1.5,length(a %>% pull(home)%>%as.factor%>% levels)-0.5, 1),
#     color = 'grey')+
#   ggtitle(paste('Season:', x_energy_cluster))+
#   theme(plot.title = element_text(hjust = 0.5))
# }
# 
# rank.table('heat')
# rank.table('ac')
# rank.table('shoulder')


rank.table <- function (x_metric){
  
a <- represent_df %>%
  filter(metric == x_metric) %>%
  group_by(home, energy_cluster, metric) %>%
  mutate(rank = rank(represent) %>% as.factor()) %>%
  ungroup() %>%
  mutate(
         loc_abbr = toupper(substring(location, 1,1)))

ggplot(a, (aes(x = home, y = rank)))+
  geom_text(aes(label = loc_abbr))+
  facet_wrap(vars(energy_cluster), labeller = labeller.clusters,
             scales = 'free_x')+
  theme_minimal()+
  theme(panel.grid = element_blank())+
  scale_y_discrete(breaks = c('1','2','3'),
                   labels = c('Lowest', '', 'Highest'))+
  ylab('Representativeness Rank')+
  xlab('Home')+
  geom_vline(
    xintercept = seq(1.5,length(a %>% pull(home)%>%as.factor%>% levels)-0.5, 1),
    color = 'grey')+
  ggtitle(x_metric)+
  theme(plot.title = element_text(hjust = 0.5))
}

rank.table('pm25')
rank.table('voc')

```


# rank line plot
```{r , fig.height = 3.5, fig.width = 8}

rank.line <- function (x_metric){
  
a <- represent_df %>%
  filter(metric == x_metric) %>%
  group_by(home, energy_cluster, metric) %>%
  mutate(rank = rank(represent) %>% as.factor()) %>%
  ungroup() 

ggplot(a, (aes(x = home, y = rank, group = location)))+
  geom_line(aes(color = location), size = 1.5)+
  facet_wrap(vars(energy_cluster), labeller = labeller.clusters,
             scales = 'free_x')+
  theme_minimal()+
  theme(panel.grid = element_blank())+
  scale_y_discrete(breaks = c('1','2','3'),
                   labels = c('Lowest', '', 'Highest'))+
  ylab('Representativeness Rank')+
  xlab('Home')+
  geom_vline(
    xintercept = seq(1.5,length(a %>% pull(home)%>%as.factor%>% levels)-0.5, 1),
    color = 'grey')+
  ggtitle(x_metric)+
  theme(plot.title = element_text(hjust = 0.5))
}

rank.line('pm25')
rank.line('voc')

```
















```{r original_osses_method}

# # calculate kld for continuous probability distributions
# 
# # define variables for testing-----------------------
# 
# # date_ranges_entire <- list(c('2020-08-26', '2020-12-01'))
# # home_num <- '011'
# # data <- omni_hourly
# # monitor_season <- date_ranges_entire[1]
# # metric <- 'voc'
# # all_time <- TRUE
# # warn <- 'none'
# # room <- 'living'
# # season_avail_limit <- 0
# # 
# # 
# # # remove variables after done testing
# # rm(tested_sample_sequence,
# #    date_ranges_entire,
# # home_num,
# # monitor_season,
# # monitor_period,
# # metric,
# # days,
# # days2,
# # all_time,
# # data,
# # data_season,
# # data_year,
# # entire,
# # date_col_season,
# # date_col_year,
# # all_dates_season,
# # all_dates_year,
# # room,
# # season_avail_limit
# # )
# 
# # entropy function hourly data ----------------------------
# 
#     
# # function to calculate scaled entropy for a house
# # during multiple different time periods
# info.gain.table <- function(
#   home_num, metric,
#   
#   # date range of entire monitoring period
#   # in the form: list(
#   #                    c('YYYY-MM-DD', 'YYYY-MM-DD'),
#   #                    c('YYYY-MM-DD', 'YYYY-MM-DD')
#   #                  )
#   # data in start and end day included
#   date_ranges_entire,
#   sample_length, # sampling period lengths (days)
# season_avail_limit = 0, # only use data from a sensor if it has at least this fraction of data available (0 means no periods are omitted if they have any data)
# all_time = TRUE, # if TRUE, compare each short sampling period to entire monitoring year of home
# data = omni_hourly) {
#   
#   output <<- na.result(NA) # clear error output in case it was triggered previously
#   warn <<- 'none'# clear warning output in case it was triggered previously
#   
#   if(metric %in% c('pm25', 'voc')) {
#     # define LOD of metric to be 1/2 minimum detected (non-zero) value
#     LOD <- data %>%
#       filter(!!sym(metric)!=0) %>%
#       pull(all_of(metric))%>%
#       min()
#   }
#   
#   
#   # function to find scaled_entropy for samples in a given monitor season
#   
#   info.gain.season <- function(monitor_season) {
#     
#     
#     # must unlist the listed range that is used in lapply funnction
#     monitor_season <- unlist(monitor_season)
#     
#     # stop if monitoring season is empty
#     if(is_empty(monitor_season)) {
#       output <<- na.result('likely_no_cluster')
#       stop()
#     } 
#     
#     
#     #define label for later use in table
#     period_label <- paste(as.Date(monitor_season[1]), '-',
#                           as.Date(monitor_season[2]))
#     
#     # warn that times will be rounded to full day for entire monitoring period
#     
#     if(
#       any( c(
#         second(as.POSIXct(monitor_season[1])),
#         minute(as.POSIXct(monitor_season[1])),
#         hour(as.POSIXct(monitor_season[1])),
#         
#         second(as.POSIXct(monitor_season[2])),
#         minute(as.POSIXct(monitor_season[2])),
#         hour(as.POSIXct(monitor_season[2]))) > 0
#       )
#     ) {
#       output <<- na.result('incorrect_date',
#                            period_label)
#       stop()
#     }
#     
#     #     # make column of all dates (increments ofhour) within year
#     # # including all locations
#     # all_dates_year <- seq.POSIXt(
#     #   from = as.POSIXct(
#     #     data %>%
#     #   filter(home == home_num &
#     #            location %in% c('living', 'bedroom', 'kitchen'))%>%
#     #     pull(datehour) %>% min(), tz = 'UTC'),
#     # 
#     #   to =  as.POSIXct( data %>%
#     #   filter(home == home_num &
#     #            location %in% c('living', 'bedroom', 'kitchen'))%>%
#     #     pull(datehour) %>% max(), tz = 'UTC'),
#     #   by = '5 min')
#     
#     # make column of all dates (increments ofhour) within season
#     # including all locations
#     all_dates_season <- seq.POSIXt(
#       from = as.POSIXct(monitor_season[1],tz = 'UTC'),
#       to =  floor_date(as.POSIXct( monitor_season[2],
#                                    tz = 'UTC')+24*60*60-1,
#                        unit = 'hour'), by = 'hour')
#     
#     # make df for recorded values in season for given location
#     data <-   data %>%
#       select(datehour, home, location, all_of(metric))%>%
#       filter(home == home_num,location %in% locations_indoor) %>%
#       # choose season date range
#       filter(
#         datehour >= ymd(monitor_season[1]) &
#           datehour <= ymd(monitor_season[2])
#       )
#     
#     if(metric %in% c('pm25', 'voc')) {
#       # convert 0 values to LOD/2 in to allow for log-normal distrib. estimation
#       data <- data %>%
#         mutate_at(all_of(metric), function(x) ifelse(x==0, LOD/2, x))
#     }
#     
#     # check data availability for entire season for each room
#     # and define which rooms have enough data
#     rooms_with_data <- data %>%
#       group_by(location) %>%
#       summarize(n_avail = n()/length(all_dates_season)) %>%
#       filter(n_avail > season_avail_limit) %>%
#       pull(location)
#     
#     # give error if not all three rooms have enough data
#     if(length(rooms_with_data) < 3){
#       output <<- na.result(paste0('only_data_',paste0(rooms_with_data,
#                                                       collapse = '_')))
#       stop()
#     }
#     
#     
#     data_wide <- data %>%
#       pivot_wider(names_from = c(location),
#                   values_from = all_of(metric))
#     
#     # function to be applied to each room individually
#     # to determine covariance matrix, variance of each room, and relative mutual info
#     
#     # note location of missing values across all room data sets
#     # so the variance can be corrected
#     # in the mutual information calculation
#     missing_indeces <- lapply(rooms_with_data, function(x) {
#       data_wide %>% pull(x) %>% is.na() %>% which()
#     }) %>%
#       unlist()
#     
#     #remove incolmplete rows and take log
#     data_wide_complete_log <- if(is_empty(missing_indeces)) {
#       data_wide%>%
#         mutate_if(is.numeric, log)
#     } else{
#       data_wide %>% slice(-c(missing_indeces)) %>%
#         mutate_if(is.numeric, log)
#     }
#     
#     # make matrix with cov function
#     #NOTE: if a value is missing from one data set, the function will delete that value from all data-sets when calculating variance and covariance
#     
#     
#     info_gain_rooms <- 
#       map(rooms_with_data,
#           function(room){
# 
#             other_rooms <- rooms_with_data[-which(rooms_with_data == room)]
#             
#             ## make complement data set by averaging each measurment between to rooms
#             ## and find the covariance between these two rooms
#             # calculate info gain based on Osses Equation 4
#             cov_mat_all <- cov(matrix(c(
#               data_wide_complete_log %>% pull(room),
#               data_wide_complete_log %>% pull(other_rooms[1]),
#               data_wide_complete_log %>% pull(other_rooms[2])
#             ), ncol = 3))
#             
#             cov_mat_complement <- cov(matrix(c(
#               data_wide_complete_log %>% pull(other_rooms[1]),
#               data_wide_complete_log %>% pull(other_rooms[2])
#             ), ncol = 2))
#             
#             cov_complement <- cov(
#               data_wide_complete_log %>% pull(other_rooms[1]),
#               data_wide_complete_log %>% pull(other_rooms[2])
#             )
# 
#             variance_room <- var(data_wide_complete_log %>% pull(room))
#             
#             mean_room <- mean(data_wide_complete_log %>% pull(room))
#             
#             variance_complement <-
#               (
#               var(data_wide_complete_log %>% pull(other_rooms[1])) +
#                 var(data_wide_complete_log %>% pull(other_rooms[2])) +
#                 2*cov_complement
#             )/
#               length(other_rooms)^2 
#             
#             mean_complement <-mean( c(
#               data_wide_complete_log %>% pull(other_rooms[1]),
#               data_wide_complete_log %>% pull(other_rooms[2])
#             ) )
# 
#             info_gain <-
#               0.5*(
#                 variance_room/variance_complement-1-
#                   log(
#                     det(cov_mat_all)/
#                         (det(cov_mat_complement)*variance_complement)
#                     )+
#                   ((mean_room-mean_complement)^2)/variance_complement
#               )
#             
#             list('info_gain' = info_gain,
#                  'location' = room,
#                  'monitor_season' = period_label,
#                  # amount of data points  for which all three rooms were available
#                  'n_data_avail' = nrow(data_wide_complete_log) 
#             )
#           }
#       ) %>%
#       bind_rows()
#     
#     # add no error note, and warning if triggered
#     c(
#       info_gain_rooms,
#       list(
#         'error' = rep('none', nrow(info_gain_rooms)),
#         'warn' = rep(warn, nrow(info_gain_rooms))
#       )
#     )
#     
#     
#   }%>%
#     # if season results in an error, return the error message in a df
#     tryCatch(error = function(e) output)
#   
#   # info_gain for all specified date ranges  
#   info_gain_data_season <- lapply(date_ranges_entire, info.gain.season)
#   
#   
#   # bind all into a dataframe
#   bind_rows(info_gain_data_season) %>%
#     mutate(
#       home = home_num,
#       metric = metric,
#       period_compare = ifelse(all_time == TRUE, 'year', 'season'))
# }
# 
#  
# 
# 
# # test function--------------------------
# 
# # start <- Sys.time()
# # 
# # test<- info.gain.table('004', 'pm25',
# # 
# #                            date_ranges_entire = list(
# #                              c('2020-12-01', '2020-12-31'),
# #                                                      c('2020-11-01',
# #                                                        '2020-11-30')),
# #                            all_time = TRUE)
# # end <- Sys.time()
# # run2 <- end- start


```


---
title: "Specificity"
output:
  html_document:
    toc: true
    toc_float: true
    theme: paper
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.path = 'figures/',
  warning = FALSE,
  message = FALSE,
  echo = FALSE,
  fig.width = 10, fig.height = 3,
  cache = FALSE)
```

```{r libraries, include=FALSE}
library(dplyr)
library(purrr)
library(tidyr)
library(openair)
library(ggplot2)
library(readr)
library(googlesheets4)
library(lubridate)
library(gridExtra)
library(runner) # for moving window functions
library(ggpubr) # for tesing log-normality
# library(cubature) # for alternative method of integrating kld function
# library(entropy) # for KLD function
# library(fitdistrplus) # for fitting distribution to data NOTE, MASS::select CONFLICTS WITH dplyr::select
library(infotheo) # to test mutual information
library(pryr) # to look at source code from C
```

```{r import_omni_minute_data, eval = FALSE}
omni_data<- read_rds('./csv_created/omni_calibrated.rds')

zero_test <- omni_data %>%
  group_by(home, location) %>%
  summarize(pm25_zeros = sum(pm25 == 0), pm25_n = n()) %>%
  mutate(pm25_zero_pct = pm25_zeros/pm25_n*100) %>%
  ungroup()



```

```{r import_omni_hourly_data, eval = FALSE}
omni_hourly_data<- read_rds('./csv_created/omni_hourly_calibrated.rds')

```

```{r import_energy_cluster_homes}
# import energy cluster dataframe for all homes
energy_cluster_df <- read_csv('./csv_created/from_sense/energy_cluster_df.csv')
```

```{r import_acf_lags}
# import summary df of how many lags required
# before autocorrelation was insignificant
lag_summary_df <- read_csv('./csv_created/lag_summary.csv')
```



```{r functions_misc}

#Function to only display 3 significant figures (for tables)
signif3 <- function(x){
  signif(x, digits = 3)
}

##Define a char vector of home numbers using a number vector,
##ex: x <- home.list(c(1:15)) for homes 1-15
threedig <- function(x) {
  if (nchar(x) == 1) {a <- paste0('00', x)
  return(a)
  }
  
  if (nchar(x) == 2) {a<- paste0('0', x)
  return(a)
  }
  else return(a)
}

home.list <- function(x) sapply(x, threedig)


# give a row of NA values with identifers to help with identifying
# causes of errors in function
na.result <- function(error, location = NA, season = NA, n_data_avail = NA) {
  tibble(
  'mutual_info' = NA,
  'location' = location, # sample_length,
  'monitor_season' = season, # period_label,
  'n_data_avail' = n_data_avail,
  'error' = error,
  'warn' = warn # return warning if triggered
)
}

# make function to label metric names with subscripts
labeller.metrics <- as_labeller(c('pm25'='PM[2.5]', 'voc'="TVOC"),
                           default = label_parsed)
```

```{r define_variables}

# list of all home numbers
homes_all <- home.list(1:17)

clusters_all <- c('heat','shoulder', 'ac')
locations_indoor <- c('living', 'kitchen', 'bedroom')
metrics_all <- c('pm25', 'voc')

# sequence of representative thresholds to test
threshold_seq <- c(0.1, 0.2, 0.3)

# sequence of days to test thresholds for shape entropy values

pdf_days <- c(3,7,10,14,21)

warn <- 'none'

```

```{r function_mutual_info_master}

# # define variables for testing-----------------------
# 
# # date_ranges_entire <- list(c('2020-11-01', '2020-11-30'))
# # home_num <- '004'
# # data <- omni_hourly_data
# # monitor_season <- date_ranges_entire[1]
# # metric <- 'voc'
# # all_time <- TRUE
# # warn <- 'none'
# # room <- 'living'
# # season_avail_limit <- 0
# # 
# # 
# # # remove variables after done testing
# # rm(tested_sample_sequence,
# #    date_ranges_entire,
# # home_num,
# # monitor_season,
# # monitor_period,
# # metric,
# # days,
# # days2,
# # all_time,
# # data,
# # data_season,
# # data_year,
# # entire,
# # date_col_season,
# # date_col_year,
# # all_dates_season,
# # all_dates_year,
# # room,
# # season_avail_limit
# # )
# 
# # entropy function hourly data ----------------------------
# 
#     
# # function to calculate scaled entropy for a house
# # during multiple different time periods
# mutual.info.table <- function(
#   home_num, metric,
#   
#   # date range of entire monitoring period
#   # in the form: list(
#   #                    c('YYYY-MM-DD', 'YYYY-MM-DD'),
#   #                    c('YYYY-MM-DD', 'YYYY-MM-DD')
#   #                  )
#   # data in start and end day included
#   date_ranges_entire,
#   sample_length, # sampling period lengths (days)
# season_avail_limit = 0, # only use data from a sensor if it has at least this fraction of data available (0 means no periods are omitted if they have any data)
# all_time = TRUE, # if TRUE, compare each short sampling period to entire monitoring year of home
# data = omni_hourly_data) {
#   
#   output <<- na.result(NA) # clear error output in case it was triggered previously
#   warn <<- 'none'# clear warning output in case it was triggered previously
#   
#   if(metric %in% c('pm25', 'voc')) {
#     # define LOD of metric to be 1/2 minimum detected (non-zero) value
#     LOD <- data %>%
#       filter(!!sym(metric)!=0) %>%
#       pull(all_of(metric))%>%
#       min()
#   }
#   
#   
#   # function to find scaled_entropy for samples in a given monitor season
#   
#   mutual.info.season <- function(monitor_season) {
#     
#     
#     # must unlist the listed range that is used in lapply funnction
#     monitor_season <- unlist(monitor_season)
#     
#     # stop if monitoring season is empty
#     if(is_empty(monitor_season)) {
#       output <<- na.result('likely_no_cluster')
#       stop()
#     } 
#     
#     
#     #define label for later use in table
#     period_label <- paste(as.Date(monitor_season[1]), '-',
#                           as.Date(monitor_season[2]))
#     
#     # warn that times will be rounded to full day for entire monitoring period
#     
#     if(
#       any( c(
#         second(as.POSIXct(monitor_season[1])),
#         minute(as.POSIXct(monitor_season[1])),
#         hour(as.POSIXct(monitor_season[1])),
#         
#         second(as.POSIXct(monitor_season[2])),
#         minute(as.POSIXct(monitor_season[2])),
#         hour(as.POSIXct(monitor_season[2]))) > 0
#       )
#     ) {
#       output <<- na.result('incorrect_date',
#                            period_label)
#       stop()
#     }
#     
#     #     # make column of all dates (increments ofhour) within year
#     # # including all locations
#     # all_dates_year <- seq.POSIXt(
#     #   from = as.POSIXct(
#     #     data %>%
#     #   filter(home == home_num &
#     #            location %in% c('living', 'bedroom', 'kitchen'))%>%
#     #     pull(datehour) %>% min(), tz = 'UTC'),
#     # 
#     #   to =  as.POSIXct( data %>%
#     #   filter(home == home_num &
#     #            location %in% c('living', 'bedroom', 'kitchen'))%>%
#     #     pull(datehour) %>% max(), tz = 'UTC'),
#     #   by = '5 min')
#     
#     # make column of all dates (increments ofhour) within season
#     # including all locations
#     all_dates_season <- seq.POSIXt(
#       from = as.POSIXct(monitor_season[1],tz = 'UTC'),
#       to =  floor_date(as.POSIXct( monitor_season[2],
#                                    tz = 'UTC')+24*60*60-1,
#                        unit = 'hour'), by = 'hour')
#     
#     # make df for recorded values in season for given location
#     data <-   data %>%
#       select(datehour, home, location, all_of(metric))%>%
#       filter(home == home_num,location %in% locations_indoor) %>%
#       # choose season date range
#       filter(
#         datehour >= ymd(monitor_season[1]) &
#           datehour <= ymd(monitor_season[2])
#       )
#     
#     if(metric %in% c('pm25', 'voc')) {
#       # convert 0 values to LOD/2 in to allow for log-normal distrib. estimation
#       data <- data %>%
#         mutate_at(all_of(metric), function(x) ifelse(x==0, LOD/2, x))
#     }
#     
#     # check data availability for entire season for each room
#     # and define which rooms have enough data
#     rooms_with_data <- data %>%
#       group_by(location) %>%
#       summarize(n_avail = n()/length(all_dates_season)) %>%
#       filter(n_avail > season_avail_limit) %>%
#       pull(location)
#     
#     # give error if not all three rooms have enough data
#     if(length(rooms_with_data) < 3){
#       output <<- na.result(paste0('only_data_',paste0(rooms_with_data,
#                                                       collapse = '_')))
#       stop()
#     }
#     
#     
#     data_wide <- data %>%
#       pivot_wider(names_from = c(location),
#                   values_from = all_of(metric))
#     
#     # function to be applied to each room individually
#     # to determine covariance matrix, variance of each room, and relative mutual info
#     
#     # note location of missing values across all room data sets
#     # so the variance can be corrected
#     # in the mutual information calculation
#     missing_indeces <- lapply(rooms_with_data, function(x) {
#       data_wide %>% pull(x) %>% is.na() %>% which()
#     }) %>%
#       unlist()
#     
#     #remove incolmplete rows and take log
#     data_wide_complete_log <- if(is_empty(missing_indeces)) {
#       data_wide%>%
#         mutate_if(is.numeric, log)
#     } else{
#       data_wide %>% slice(-c(missing_indeces)) %>%
#         mutate_if(is.numeric, log)
#     }
#     
#     # make matrix with cov function
#     #NOTE: if a value is missing from one data set, the function will delete that value from all data-sets when calculating variance and covariance
#     
#     
#     mutual_info_rooms <- 
#       map(rooms_with_data,
#           function(room){
#             
#             other_rooms <- rooms_with_data[-which(rooms_with_data == room)]
#             
#             ## make complement data set by averaging each measurment between to rooms
#             ## and find the covariance between these two rooms
#             data_complement <- data_wide_complete_log %>%
#               select(all_of(other_rooms))%>%
#               mutate(mean = rowMeans(.)) %>% pull(mean)
#             
#             cov_complement <- cov(data_wide_complete_log %>% pull(other_rooms[1]),
#                                   data_wide_complete_log %>% pull(other_rooms[2]))
#             
#             cov_matrix <- cov(
#               matrix(c(data_wide_complete_log %>% pull(room),
#                        data_complement), ncol = 2), 
#               use = 'complete.obs')
#             
#             cov_determinant <- det(cov_matrix)
#             
#             variance_room <- var(data_wide_complete_log %>% pull(room))
#             variance_complement <- (
#               var(data_wide_complete_log %>% pull(other_rooms[1])) +
#                 var(data_wide_complete_log %>% pull(other_rooms[2])) +
#                 2*cov_complement
#             )/length(other_rooms)^2
#             
#             mutual_info <-
#               -0.5*log( cov_determinant/ (variance_room*variance_complement) )
#             
#             list('mutual_info' = mutual_info,
#                  'location' = room,
#                  'monitor_season' = period_label,
#                  # amount of data points  for which all three rooms were available
#                  'n_data_avail' = nrow(data_wide_complete_log) 
#             )
#           }
#       ) %>%
#       bind_rows()
#     
#     # add no error note, and warning if triggered
#     c(
#       mutual_info_rooms,
#       list(
#         'error' = rep('none', nrow(mutual_info_rooms)),
#         'warn' = rep(warn, nrow(mutual_info_rooms))
#       )
#     )
#     
#     
#   }%>%
#     # if season results in an error, return the error message in a df
#     tryCatch(error = function(e) output)
#   
#   # mutual_info for all specified date ranges  
#   mutual_info_data_season <- lapply(date_ranges_entire, mutual.info.season)
#   
#   
#   # bind all into a dataframe
#   bind_rows(mutual_info_data_season) %>%
#     mutate(
#       home = home_num,
#       metric = metric,
#       period_compare = ifelse(all_time == TRUE, 'year', 'season'))
# }
# 
#  
# 
# 
# # test function--------------------------
# 
# # start <- Sys.time()
# # 
# # test<- mutual.info.table('004', 'pm25',
# # 
# #                            date_ranges_entire = list(
# #                              c('2020-12-01', '2020-12-31'),
# #                                                      c('2020-11-01',
# #                                                        '2020-11-30')),
# #                            all_time = TRUE)
# # end <- Sys.time()
# # run2 <- end- start

```

```{r functions_csv_creation}

# make functions to look up starting and ending date of
# energy cluster period based on home
 pick.start <- function(x_home, x_cluster) {
   energy_cluster_df %>%
   filter(home == x_home & cluster_type == x_cluster) %>%
   pull(start_date) %>% as.character()
 }
 
  pick.end <- function(x_home, x_cluster) {
   energy_cluster_df %>%
   filter(home == x_home & cluster_type == x_cluster) %>%
   pull(end_date) %>% as.character()
  }
  
  # fun to pick minimum sample length to test based on metric
  pick.sample.min <- function(x_metric) {
    lag_summary_df %>%
      # use the pooled median of all clusters
      filter(metric == x_metric, energy_cluster == 'total') %>%
      pull(median)
  }
  
  # # test functions
   # pick.start('006', 'heat')
  # pick.end('004', 'heat')
```


```{r data_maker, eval = FALSE}

all_time_choice <- TRUE

mutual_info_df <-  
  
  lapply(metrics_all, function(x_metric) {
    
    lapply(clusters_all, function(x_cluster) {
      
      lapply(homes_all, function(x_home) {
        
        start_date <- pick.start(x_home, x_cluster)
        end_date <- pick.end(x_home, x_cluster)
        
        
        
        mutual.info.table(
          x_home, metric = x_metric,
          date_ranges_entire = list(c(start_date,
                                      end_date)),
          all_time = all_time_choice) %>%
          # add in column for energy_cluster
          mutate(energy_cluster = x_cluster) 
      }
      ) %>%
        bind_rows()
      
    }
    ) %>%
      bind_rows()
  }
  ) %>%
  bind_rows()


# make csv of all data
write_csv(mutual_info_df, file =
            paste0('./csv_created/representativeness_data/mutual_info_',
                   Sys.Date(), '.csv'))



```

# Plotting

```{r import_mutual_info_data}
mutual_info_df <- read_csv('./csv_created/representativeness_data/mutual_info.csv')

```


```{r omissions_cleaning}
# remove na spec values from runs
mutual_info_df_clean <- mutual_info_df%>% 
  filter(period_compare == 'year', # only comparing sample to whole mon. period
         !is.na(mutual_info)) # with insufficient data in cluster/year/no cluster

```


```{r create_scaled_spec_df}

spec_df <- mutual_info_df_clean %>%
  group_by(home, metric) %>%
  mutate(mutual_info_max = max(mutual_info)) %>%
  ungroup() %>%
  mutate(specificity = 1-mutual_info/mutual_info_max)


unwanted_scaled_na <- spec_df %>%
  filter(specificity %>% is.na())

```

### `r unwanted_scaled_na %>% nrow()` unexpected missing values in scaled spec data

```{r plot_spec_rooms}
ggplot(spec_df, aes(x = location, y = specificity))+
  geom_boxplot(outlier.shape = NA)+
  geom_jitter( aes(color = energy_cluster), width = 0.1)+
  facet_wrap(vars(metric), labeller = labeller.metrics)+
  scale_color_manual(breaks = c('ac', 'shoulder', 'heat'),
                     values = c('blue', 'green', 'red'),
                     name = 'Season')
```

```{r table_rank}

a <- spec_df %>%
  group_by(home, energy_cluster, metric) %>%
  mutate(rank = rank(specificity) %>% as.factor()) %>%
  ungroup() %>%
  mutate(home_clust = interaction(home, energy_cluster),
         loc_abbr = toupper(substring(location, 1,1)))

ggplot(a, (aes(x = home, y = rank)))+
  geom_text(aes(label = loc_abbr, color = energy_cluster,
                group = energy_cluster),
            position =position_dodge(width = 1)
            )+
  facet_wrap(vars(metric), labeller = labeller.metrics)+
  theme_minimal()+
  theme(panel.grid = element_blank())+
  scale_y_discrete(breaks = c('1','2','3'), labels = c('least', '', 'greatest'))+
  ylab('Specificity Rank')+
  geom_vline(
    xintercept = seq(1.5,length(a %>% pull(home)%>%as.factor%>% levels)-0.5, 1),
    color = 'grey')+ # insert lines between homes
  scale_color_manual(breaks = c('ac', 'shoulder', 'heat'),
                     values = c('blue', 'green', 'red'),
                     name = 'Season')


```



# Testing
* NOTE: MAY BE OLD FUNCTION
```{r master_func_testing}

# define variables for testing-----------------------

date_ranges_entire <- list(c('2020-11-01', '2020-11-30'))
home_num <- '004'
data <- omni_hourly_data
monitor_season <- date_ranges_entire[1]
metric <- 'voc'
all_time <- TRUE
warn <- 'none'
room <- 'living'
season_avail_limit <- 0
# 
# 
# # remove variables after done testing
# rm(tested_sample_sequence,
#    date_ranges_entire,
# home_num,
# monitor_season,
# monitor_period,
# metric,
# days,
# days2,
# all_time,
# data,
# data_season,
# data_year,
# entire,
# date_col_season,
# date_col_year,
# all_dates_season,
# all_dates_year,
# room,
# season_avail_limit
# )

# entropy function hourly data ----------------------------

    
# function to calculate scaled entropy for a house
# during multiple different time periods
mutual.info.table <- function(
  home_num, metric,
  
  # date range of entire monitoring period
  # in the form: list(
  #                    c('YYYY-MM-DD', 'YYYY-MM-DD'),
  #                    c('YYYY-MM-DD', 'YYYY-MM-DD')
  #                  )
  # data in start and end day included
  date_ranges_entire,
  sample_length, # sampling period lengths (days)
season_avail_limit = 0, # only use data from a sensor if it has at least this fraction of data available (0 means no periods are omitted if they have any data)
all_time = TRUE, # if TRUE, compare each short sampling period to entire monitoring year of home
data = omni_hourly_data) {
  
  output <<- na.result(NA) # clear error output in case it was triggered previously
  warn <<- 'none'# clear warning output in case it was triggered previously
  
  if(metric %in% c('pm25', 'voc')) {
    # define LOD of metric to be 1/2 minimum detected (non-zero) value
    LOD <- data %>%
      filter(!!sym(metric)!=0) %>%
      pull(all_of(metric))%>%
      min()
  }
  
  
  # function to find scaled_entropy for samples in a given monitor season
  
  mutual.info.season <- function(monitor_season) {
    
    
    # must unlist the listed range that is used in lapply funnction
    monitor_season <- unlist(monitor_season)
    
    # stop if monitoring season is empty
    if(is_empty(monitor_season)) {
      output <<- na.result('likely_no_cluster')
      stop()
    } 
    
    
    #define label for later use in table
    period_label <- paste(as.Date(monitor_season[1]), '-',
                          as.Date(monitor_season[2]))
    
    # warn that times will be rounded to full day for entire monitoring period
    
    if(
      any( c(
        second(as.POSIXct(monitor_season[1])),
        minute(as.POSIXct(monitor_season[1])),
        hour(as.POSIXct(monitor_season[1])),
        
        second(as.POSIXct(monitor_season[2])),
        minute(as.POSIXct(monitor_season[2])),
        hour(as.POSIXct(monitor_season[2]))) > 0
      )
    ) {
      output <<- na.result('incorrect_date',
                           period_label)
      stop()
    }
    
    #     # make column of all dates (increments ofhour) within year
    # # including all locations
    # all_dates_year <- seq.POSIXt(
    #   from = as.POSIXct(
    #     data %>%
    #   filter(home == home_num &
    #            location %in% c('living', 'bedroom', 'kitchen'))%>%
    #     pull(datehour) %>% min(), tz = 'UTC'),
    # 
    #   to =  as.POSIXct( data %>%
    #   filter(home == home_num &
    #            location %in% c('living', 'bedroom', 'kitchen'))%>%
    #     pull(datehour) %>% max(), tz = 'UTC'),
    #   by = '5 min')
    
    # make column of all dates (increments ofhour) within season
    # including all locations
    all_dates_season <- seq.POSIXt(
      from = as.POSIXct(monitor_season[1],tz = 'UTC'),
      to =  floor_date(as.POSIXct( monitor_season[2],
                                   tz = 'UTC')+24*60*60-1,
                       unit = 'hour'), by = 'hour')
    
    # make df for recorded values in season for given location
    data <-   data %>%
      select(datehour, home, location, all_of(metric))%>%
      filter(home == home_num,location %in% locations_indoor) %>%
      # choose season date range
      filter(
        datehour >= ymd(monitor_season[1]) &
          datehour <= ymd(monitor_season[2])
      )
    
    if(metric %in% c('pm25', 'voc')) {
      # convert 0 values to LOD/2 in to allow for log-normal distrib. estimation
      data <- data %>%
        mutate_at(all_of(metric), function(x) ifelse(x==0, LOD/2, x))
    }
    
    # check data availability for entire season for each room
    # and define which rooms have enough data
    rooms_with_data <- data %>%
      group_by(location) %>%
      summarize(n_avail = n()/length(all_dates_season)) %>%
      filter(n_avail > season_avail_limit) %>%
      pull(location)
    
    # give error if not all three rooms have enough data
    if(length(rooms_with_data) < 3){
      output <<- na.result(paste0('only_data_',paste0(rooms_with_data,
                                                      collapse = '_')))
      stop()
    }
    
    
    data_wide <- data %>%
      pivot_wider(names_from = c(location),
                  values_from = all_of(metric))
    
    # function to be applied to each room individually
    # to determine covariance matrix, variance of each room, and relative mutual info
    
    # note location of missing values across all room data sets
    # so the variance can be corrected
    # in the mutual information calculation
    missing_indeces <- lapply(rooms_with_data, function(x) {
      data_wide %>% pull(x) %>% is.na() %>% which()
    }) %>%
      unlist()
    
    #remove incolmplete rows and take log
    data_wide_complete_log <- if(is_empty(missing_indeces)) {
      data_wide%>%
        mutate_if(is.numeric, log)
    } else{
      data_wide %>% slice(-c(missing_indeces)) %>%
        mutate_if(is.numeric, log)
    }
    
    # make matrix with cov function
    #NOTE: if a value is missing from one data set, the function will delete that value from all data-sets when calculating variance and covariance
    
    
    mutual_info_rooms <- 
      map(rooms_with_data,
          function(room){
            
            
            
            
            other_rooms <- rooms_with_data[-which(rooms_with_data == room)]
           ## Try mutinformation func----------------------- 
            # use with 2 normally dist vectors and compare with Osses formula---------
            room_norm <- runif(10000000, -2.3, 7)
             complement_norm <- runif(10000000, -2.5, 7.2)
             all_norm <- c(room_norm)
             
             # calculate from infotheo R package
            mut_info1 <- mutinformation(discretize(room_norm, nbins = 1000),
                                        discretize(complement_norm, nbins = 1000))
            # try with less bins in calc
            mut_info1b <- mutinformation(discretize(room_norm, nbins = 100),
                                        discretize(complement_norm, nbins = 100))
             #estimate using Osses Normal formula
             variance_room <- var(room_norm)
             variance_complement <- var(complement_norm)
             
            cov_matrix <- cov(
              matrix(c(room_norm, complement_norm), ncol = 2))
            
            cov_determinant <- det(cov_matrix)
            
            
              mut_info2 <- -0.5*log( cov_determinant/
                                       (variance_room*variance_complement) )
            
              # use with 3 normally dist vectors and compare with Osses formula---------
              room_norm <- runif(10000, -2.3, 7)
             complement1_norm <- runif(10000, -2.5, 7.2)
             complement2_norm <- runif(10000, -2.0, 7.1)
             complementall_norm <- matrix(c(complement1_norm, complement2_norm),
                                          ncol = 2)
             allrooms_norm <- matrix(c(room_norm, complementall_norm), ncol = 3)
             
             # calculate from infotheo R package
             ## try with complement matrix
            mut_info1 <- mutinformation(discretize(room_norm),
                                        discretize(complementall_norm))
             ## try with complement vector
            mut_info1b <- mutinformation(discretize(room_norm),
                                        discretize(c(
                                          complement1_norm,
                                          complement2_norm
                                        )))

             #estimate using Osses Normal formula
            cov_all <- cov(allrooms_norm)
             cov_complement <- cov(complementall_norm)
             variance_room <- var(room_norm)
             
             mut_info2 <- -0.5*log( det(cov_all)/
                                       (variance_room*det(cov_complement)))

            # look at function source code----------------------
            getAnywhere(mutinformation())
            getAnywhere(entropy())
            
            # download package to look at compiled code
            # download.packages(pkgs = "infotheo", 
            #       destdir = ".",
            #       type = "source")
            
            
            
            # test if number of bins matters------------------------
            # compare mi calculated from vector A to vector B
            # to vector 2A (A stacked on top of itself) to vector B
              data_room <- data_wide_complete_log %>%
              pull(all_of(other_rooms[1])) %>%
              discretize()
            
            data_complement1 <- data_wide_complete_log %>%
              pull(all_of(room)) %>%
              discretize()
            
            data_complement2 <- stack(data_wide_complete_log, c(room, room)) %>%
              pull(values) %>%
              discretize()
            
            data_complement3 <- stack(data_wide_complete_log, rep(room, 10)) %>%
              pull(values) %>%
              discretize()
            
            mutinformation(data_room, data_complement1)
            
            mutinformation(data_room, data_complement2)
                        mutinformation(data_room, data_complement3)


            
            # method 1: assume complement is two vectors, while room is one -----------
            data_room <- data_wide_complete_log %>%
              select(all_of(room)) %>%
              discretize()

            data_complement <- data_wide_complete_log %>%
              select(all_of(other_rooms))%>%
              discretize()

            mutinformation(data_room, data_complement)
            
            # method 2: assume complement vector is vector that is
            # double the length of room vector----------------
              data_room <- data_wide_complete_log %>%
              pull(all_of(room)) %>%
              discretize()
            
            
            data_complement <- stack(data_wide_complete_log, other_rooms) %>%
              pull(values) %>%
              discretize()

            mutinformation(data_room, data_complement)

            test <- discretize(USArrests)
            
            # method 3: assume complement vector is vector of average values-------
            ## make complement data set by averaging each measurment between to rooms
            ## and find the covariance between these two rooms
            data_complement <- data_wide_complete_log %>%
              select(all_of(other_rooms))%>%
              mutate(mean = rowMeans(.)) %>% pull(mean)
            
            cov_complement <- cov(data_wide_complete_log %>% pull(other_rooms[1]),
                                  data_wide_complete_log %>% pull(other_rooms[2]))
            
            cov_matrix <- cov(
              matrix(c(data_wide_complete_log %>% pull(room),
                       data_complement), ncol = 2), 
              use = 'complete.obs')
            
            cov_determinant <- det(cov_matrix)
            
            variance_room <- var(data_wide_complete_log %>% pull(room))
            variance_complement <- (
              var(data_wide_complete_log %>% pull(other_rooms[1])) +
                var(data_wide_complete_log %>% pull(other_rooms[2])) +
                2*cov_complement
            )/length(other_rooms)^2
            
            mutual_info <-
              -0.5*log( cov_determinant/ (variance_room*variance_complement) )
            
            list('mutual_info' = mutual_info,
                 'location' = room,
                 'monitor_season' = period_label,
                 # amount of data points  for which all three rooms were available
                 'n_data_avail' = nrow(data_wide_complete_log) 
            )
          }
      ) %>%
      bind_rows()
    
    # add no error note, and warning if triggered
    c(
      mutual_info_rooms,
      list(
        'error' = rep('none', nrow(mutual_info_rooms)),
        'warn' = rep(warn, nrow(mutual_info_rooms))
      )
    )
    
    
  }%>%
    # if season results in an error, return the error message in a df
    tryCatch(error = function(e) output)
  
  # mutual_info for all specified date ranges  
  mutual_info_data_season <- lapply(date_ranges_entire, mutual.info.season)
  
  
  # bind all into a dataframe
  bind_rows(mutual_info_data_season) %>%
    mutate(
      home = home_num,
      metric = metric,
      period_compare = ifelse(all_time == TRUE, 'year', 'season'))
}

 


# test function--------------------------

# start <- Sys.time()
# 
# test<- mutual.info.table('004', 'pm25',
# 
#                            date_ranges_entire = list(
#                              c('2020-12-01', '2020-12-31'),
#                                                      c('2020-11-01',
#                                                        '2020-11-30')),
#                            all_time = TRUE)
# end <- Sys.time()
# run2 <- end- start

```


# Old FUnctions

```{r function_specificty_minutely_master, eval = FALSE}

# # calculate kld for continuous probability distributions
# 
# # define variables for testing-----------------------
# 
# date_ranges_entire <- list(c('2020-11-01', '2020-11-30'))
# home_num <- '004'
# data <- omni_data
# monitor_season <- date_ranges_entire[1]
# metric <- 'voc'
# all_time <- TRUE
# warn <- 'none'
# room <- 'living'
# season_avail_limit <- 0
# 
# 
# # remove variables after done testing
# rm(tested_sample_sequence,
#    date_ranges_entire,
# home_num,
# monitor_season,
# monitor_period,
# metric,
# days,
# days2,
# all_time,
# data,
# data_season,
# data_year,
# entire,
# date_col_season,
# date_col_year,
# all_dates_season,
# all_dates_year,
# room,
# season_avail_limit
# )
# 
# # entropy function minutely data ----------------------------
# 
# 
# # function to calculate scaled entropy for a house
# # during multiple different time periods
# specificity.table <- function(
#   home_num, metric,
# 
#   # date range of entire monitoring period
#   # in the form: list(
#   #                    c('YYYY-MM-DD', 'YYYY-MM-DD'),
#   #                    c('YYYY-MM-DD', 'YYYY-MM-DD')
#   #                  )
#   # data in start and end day included
#   date_ranges_entire,
#   sample_length, # sampling period lengths (days)
# season_avail_limit = 0, # only use data from a sensor if it has at least this fraction of data available (0 means no periods are omitted if they have any data)
# all_time = TRUE, # if TRUE, compare each short sampling period to entire monitoring year of home
#   data = omni_data) {
# 
#   output <<- na.result(NA) # clear error output in case it was triggered previously
#   warn <<- 'none'# clear warning output in case it was triggered previously
# 
#   if(metric %in% c('pm25', 'voc')) {
#     # define LOD of metric to be 1/2 minimum detected (non-zero) value
#     LOD <- data %>%
#       filter(!!sym(metric)!=0) %>%
#       pull(all_of(metric))%>%
#       min()
#   }
# 
# 
#   # function to find scaled_entropy for samples in a given monitor season
# 
#   specifity.season <- function(monitor_season) {
# 
# 
#     # must unlist the listed range that is used in lapply funnction
#     monitor_season <- unlist(monitor_season)
# 
#     # stop if monitoring season is empty
#     if(is_empty(monitor_season)) {
#       output <<- na.result('likely_no_cluster')
#       stop()
#     }
# 
# 
#     #define label for later use in table
#     period_label <- paste(as.Date(monitor_season[1]), '-',
#                           as.Date(monitor_season[2]))
# 
#     # warn that times will be rounded to full day for entire monitoring period
# 
#     if(
#         any( c(
#         second(as.POSIXct(monitor_season[1])),
#         minute(as.POSIXct(monitor_season[1])),
#         hour(as.POSIXct(monitor_season[1])),
# 
#         second(as.POSIXct(monitor_season[2])),
#         minute(as.POSIXct(monitor_season[2])),
#         hour(as.POSIXct(monitor_season[2]))) > 0
#     )
#     ) {
#       output <<- na.result('incorrect_date',
#                            period_label)
#       stop()
#     }
# 
#     #     # make column of all dates (increments of 5 min) within year
#     # # including all locations
#     # all_dates_year <- seq.POSIXt(
#     #   from = as.POSIXct(
#     #     data %>%
#     #   filter(home == home_num &
#     #            location %in% c('living', 'bedroom', 'kitchen'))%>%
#     #     pull(datetime) %>% min(), tz = 'UTC'),
#     #
#     #   to =  as.POSIXct( data %>%
#     #   filter(home == home_num &
#     #            location %in% c('living', 'bedroom', 'kitchen'))%>%
#     #     pull(datetime) %>% max(), tz = 'UTC'),
#     #   by = '5 min')
# 
#     # make column of all dates (increments of 5 min) within season
#     # including all locations
#     all_dates_season <- seq.POSIXt(
#       from = as.POSIXct(monitor_season[1],tz = 'UTC'),
#       to =  floor_date(as.POSIXct( monitor_season[2],
#                                    tz = 'UTC')+24*60*60-1,
#                        unit = '5 min'), by = '5 min')
# 
#                   # make df for recorded values in season for given location
#     data <-   data %>%
#       select(datetime, home, location, all_of(metric))%>%
#       filter(home == home_num,location %in% locations_indoor) %>%
#       # choose season date range
#       filter(
#         datetime >= ymd(monitor_season[1]) &
#           datetime <= ymd(monitor_season[2])
#       )
# 
#         if(metric %in% c('pm25', 'voc')) {
#       # convert 0 values to LOD/2 in to allow for log-normal distrib. estimation
#       data <- data %>%
#         mutate_at(all_of(metric), function(x) ifelse(x==0, LOD/2, x))
#     }
# 
#         # check data availability for entire season for each room
#     # and define which rooms have enough data
#     rooms_with_data <- data %>%
#       group_by(location) %>%
#       summarize(n_avail = n()/length(all_dates_season)) %>%
#       filter(n_avail > season_avail_limit) %>%
#       pull(location)
# 
#     # give error if not all three rooms have enough data
#     if(length(rooms_with_data) < 3){
#             output <<- na.result(paste0('only_data_',paste0(rooms_with_data,
#                                         collapse = '_')))
#       stop()
#     }
# 
# 
#     data_wide <- data %>%
#       pivot_wider(names_from = c(location),
#                   values_from = all_of(metric))
# 
#     # function to be applied to each room individually
#     # to determine covariance matrix, variance of each room, and relative mutual info
# 
#       # note location of missing values across all room data sets
#     # so the variance can be corrected
#     # in the mutual information calculation
#     missing_indeces <- lapply(rooms_with_data, function(x) {
#       data_wide %>% pull(x) %>% is.na() %>% which()
#     }) %>%
#       unlist()
# 
#     #remove incolmplete rows and take log
#     data_wide_complete_log <- if(is_empty(missing_indeces)) {
#       data_wide%>%
#         mutate_if(is.numeric, log)
#     } else{
#       data_wide %>% slice(-c(missing_indeces)) %>%
#         mutate_if(is.numeric, log)
#     }
# 
#         # make matrix with cov function
#         #NOTE: if a value is missing from one data set, the function will delete that value from all data-sets when calculating variance and covariance
# 
# 
#         specificity_rooms <-
#           map(rooms_with_data,
#               function(room){
# 
#                 other_rooms <- rooms_with_data[-which(rooms_with_data == room)]
# 
#                 ## make compliment data set by averaging each measurment between to rooms
#                 data_comp <- data_wide_complete_log %>% select(all_of(other_rooms))%>%
#                   mutate(mean = rowMeans(.)) %>% pull(mean)
# 
#                 cov_matrix <- cov(
#                   matrix(c(data_wide_complete_log %>% pull(room),
#                            data_comp), ncol = 2),
#                   use = 'complete.obs')
# 
#                 cov_determinant <- det(cov_matrix)
# 
#                 variance_room <- var(data_wide_complete_log %>% pull(room))
#                 variance_complement <- var(data_comp)
#                 specificity <-
#                   -0.5*log( cov_determinant/ (variance_room*variance_complement) )
# 
#                 list('specificity' = specificity,
#                      'location' = room,
#                      'monitor_season' = period_label,
#                      # amount of data points  for which all three rooms were available
#                      'n_data_avail' = nrow(data_wide_complete_log)
#                 )
#               }
#           ) %>%
#           bind_rows()
# 
#         # add no error note, and warning if triggered
#          c(
#           specificity_rooms,
#           list(
#             'error' = rep('none', nrow(specificity_rooms)),
#             'warn' = rep(warn, nrow(specificity_rooms))
#           )
#          )
# 
# 
#   }%>%
#     # if season results in an error, return the error message in a df
#     tryCatch(error = function(e) output)
# 
# # specificity for all specified date ranges
#   specifity_data_season <- lapply(date_ranges_entire, specifity.season)
# 
# 
#   # bind all into a dataframe
# bind_rows(specifity_data_season) %>%
#     mutate(
#            home = home_num,
#            metric = metric,
#            period_compare = ifelse(all_time == TRUE, 'year', 'season'))
# }
# 
# 
# 
# 
# # test function--------------------------
# 
# # start <- Sys.time()
# # 
# # test<- specificity.table('004', 'pm25',
# # 
# #                            date_ranges_entire = list(
# #                              c('2020-12-01', '2020-12-31'),
# #                                                      c('2020-11-01',
# #                                                        '2020-11-30')),
# #                            all_time = TRUE)
# # end <- Sys.time()
# # run2 <- end- start

```

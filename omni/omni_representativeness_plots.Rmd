---
title: "Representativeness"
output:
  html_document:
    toc: true
    toc_float: true
    theme: paper
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.path = 'figures/',
  warning = FALSE,
  message = FALSE,
  echo = FALSE,
  fig.width = 10, fig.height = 3,
  cache = FALSE)
```

```{r libraries, include=FALSE}
library(dplyr)
library(purrr)
library(tidyr)
library(openair)
library(ggplot2)
library(readr)
library(googlesheets4)
library(lubridate)
library(gridExtra)
library(runner) # for moving window functions
library(ggpubr) # for tesing log-normality
# library(cubature) # for alternative method of integrating kld function
# library(entropy) # for KLD function
# library(fitdistrplus) # for fitting distribution to data NOTE, MASS::select CONFLICTS WITH dplyr::select

```

```{r import_omni_minute_data}
# omni_data<- read_csv('./csv_created/omni_all_locations.csv')

# # remove all variables but omni_data
# rm(list=setdiff(ls(), "omni_data"))

# zero_test <- omni_data %>%
#   group_by(home, location) %>%
#   summarize(pm25_zeros = sum(pm25 == 0), pm25_n = n()) %>%
#   mutate(pm25_zero_pct = pm25_zeros/pm25_n*100) %>%
#   ungroup()

```


```{r import_energy_cluster_homes}
# import energy cluster dataframe for all homes
energy_cluster_df <- read_csv('../sense/csv_created_sense/energy_cluster_df.csv')
```



```{r import_assessment_data}

assessment_data <- read_csv('../drive_sync/epic_homes/data/homes/home_assessment_data.csv')

# # using googlesheets4
# assessment_data <- read_sheet('https://docs.google.com/spreadsheets/d/12vWpqdmzIII0vEKH79xpmICUYGuzc8PjfBT2_3YjIHU/edit?usp=sharing', sheet = 'data')
```


```{r functions_misc}

#Function to only display 3 significant figures (for tables)
signif3 <- function(x){
  signif(x, digits = 3)
}

##Define a char vector of home numbers using a number vector,
##ex: x <- home.list(c(1:15)) for homes 1-15
threedig <- function(x) {
  if (nchar(x) == 1) {a <- paste0('00', x)
  return(a)
  }
  
  if (nchar(x) == 2) {a<- paste0('0', x)
  return(a)
  }
  else return(a)
}

home.list <- function(x) sapply(x, threedig)

# make function to label metric names with subscripts
labeller.metrics <- as_labeller(c('pm25'='PM[2.5]', 'voc'="TVOC"),
                           default = label_parsed)

# make function to label metric names with subscripts and seasons
labeller.metrics.seasons <- as_labeller(c(
  'pm25'='PM[2.5]', 'voc'="TVOC",
  'ac' = 'AC', 'shoulder' = 'Shoulder', 'heat' = 'Heat'
  ), default = label_parsed)

```



```{r define_variables}
# fraction of sample needed to use sample of certain length
frac_samp_required <- 0

# method of scaling relative entropy to scaled entropy
# 'universal' or 'conditional'
max_method <- 'conditional'

long_term_period <- 'year'

month_cluster <- FALSE

overlap <- TRUE

# cluster to plot for deviation plots
season <- 'all'


# list of all home numbers
homes_all <- home.list(1:17)
homes_tier3 <- home.list(c(1,2,7,9,12))
homes_tier2 <- home.list(c(4,10,11,13,15))
homes_no5 <- home.list(c(1:4,6:16))


clusters_all <- c('heat','shoulder', 'ac')
locations_indoor <- c('living', 'kitchen', 'bedroom')
metrics_all <- c('pm25', 'voc')
# sequence of representative thresholds to test
thresh_vector <- c(0.6, 0.7, 0.9)

# sequence of days to test thresholds for shape entropy values
pdf_days <- c(3,7,19,27)

pdf_days_pm <- pdf_days
pdf_days_voc <- pdf_days


# color blind pallette
# check http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/#a-colorblind-friendly-palette
cbbPalette <- c('black' = "#000000",
                'light_orange' = "#E69F00",
                'light_blue' = "#56B4E9",
                'green' = "#009E73",
                'yellow' = "#F0E442",
                'dark_blue' = "#0072B2",
                'dark_orange' = "#D55E00",
                'purple' = "#CC79A7"
                )
# define colors for energy clusters
energy_colors <- c(cbbPalette['light_blue'],
                   cbbPalette['green'],
                   cbbPalette['dark_orange'],
                   cbbPalette['black'])%>% unname()

energy_breaks <- c('ac', 'shoulder', 'heat', 'all')
energy_labels <- c('AC', 'Shoulder', 'Heat', 'Entire Period')

# define colors for sampling length
length_colors <- c(cbbPalette['black'],
                   cbbPalette['purple'],
                   cbbPalette['light_blue'],
                   cbbPalette['yellow'])%>% unname()

# define colors for thresholds
threshold_colors <- c(cbbPalette['dark_blue'],
                   cbbPalette['green'],
                   cbbPalette['dark_orange'])%>% unname()

# attempt 2
threshold_colors <- c(cbbPalette['dark_blue'],
                   cbbPalette['purple'],
                   cbbPalette['light_orange'])%>% unname()

# for labeling purposes
xsmall <- 2
smaller <- 4
small <- 6
medium <- 16
large <- 24

```

```{r import_pdf_data}

# read in csv files
entropy_df <-
  if(long_term_period == 'year' & overlap == TRUE & month_cluster == FALSE) {
    
    bind_rows(
      read_csv(file = './csv_created/representativeness_data/rep_data_shape_hourly_pdf.csv'),
      read_csv(file = './csv_created/representativeness_data/rep_data_time_hourly_pdf.csv'))
    
  }else if(long_term_period == 'season'& overlap == TRUE & month_cluster == FALSE){
    
    bind_rows(
      read_csv(file = './csv_created/representativeness_data/rep_data_shape_hourly_pdf_season.csv'),
      read_csv(file = './csv_created/representativeness_data/rep_data_time_hourly_pdf_season.csv'))
    
  }else if(long_term_period == 'year' & overlap == FALSE & month_cluster == FALSE){
    
    bind_rows(
      read_csv(file = './csv_created/representativeness_data/rep_data_shape_hourly_pdf_no_overlap.csv'),
      read_csv(file = './csv_created/representativeness_data/rep_data_time_hourly_pdf_no_overlap.csv'))
    
  }else if(long_term_period == 'season'& overlap == FALSE & month_cluster == FALSE){
    
    bind_rows(
      read_csv(file = './csv_created/representativeness_data/rep_data_shape_hourly_pdf_season_no_overlap.csv'),
      read_csv(file = './csv_created/representativeness_data/rep_data_time_hourly_pdf_season_no_overlap.csv'))
    
  }else if(long_term_period == 'season'& overlap == TRUE & month_cluster == TRUE){
    
    bind_rows(
      read_csv(file = './csv_created/representativeness_data/rep_data_shape_hourly_pdf_season_month.csv'),
      read_csv(file = './csv_created/representativeness_data/rep_data_time_hourly_pdf_season_month.csv'))
  }


```

```{r cleaning_omissions}
# count omissions --------------

n_homes_enrolled <- 17 # n of homes enrolled
n_indoor_sensors <- 16*3+2 # Home 002 never had kitchen installed
n_all_data_omitted <- 3 # Home 005 had less than 2 weeks of data
n_homes_data <-16 # n of homes with data used at least partially
n_indoor_sensors_data <- 15*3+2 # n of indoor sensors with data used at least partially
n_sensors_ac <- 5*3+2 # n of sensors in homes with ac detected
n_sensors_ac_ignore <- 3 # Home 011 ac usage ignored because only detected 5 days 

# no cluster

# clustered <- entropy_df%>%
#   filter(home != '005') %>% # omit home 5 from count
#   filter(!(home == '002' & location == 'kitchen')) %>% # omit home 002 kitchen from count
#     filter(!(grepl('likely_no_cluster', error))) %>%
#   filter(grepl('missing', error)) %>%
#   group_by(method, metric, energy_cluster) %>%
#   summarize(n = n(), .groups = 'drop')
# 
# 
# pm_time_no_cluster <- entropy_df%>%
#   filter(method == 'time', metric == 'pm25',
#          grepl('likely_no_cluster', error)) %>%
#   group_by(home, location, energy_cluster) %>%
#   summarize(n = n(), .groups = 'drop')


# clean dataframes ------------------------


# test <- kld_max_df_clean %>%
#   group_by(home, location, energy_cluster) %>%
#   summarise(n = n(), .groups = 'drop')

# kld values
# remove na kld values from runs with insufficient data
entropy_df_clean <- entropy_df%>% 
  filter(period_compare == long_term_period, # only comparing sample to whole mon. period
    !is.na(kld), # with insufficient data in cluster/year/no cluster
  n_samp_avail >= frac_samp_required) %>% # with less than certain percentage of available samples
# omit home 011 in shoulder season for severe lack of data
  filter(!(home =='011' & location == 'bedroom' & energy_cluster == 'shoulder')) %>%
    mutate(
      median_diff_pct = abs(median_sample - median_entire)/median_entire*100,
      mean_diff_pct = abs(mean_sample - mean_entire)/mean_entire*100,
      # median_ratio = median_sample/median_entire,
      # variance_ratio = variance_sample/variance_entire,
      iqr_diff_pct = abs(iqr_sample-iqr_entire)/iqr_entire*100,
      variance_diff_pct = abs(variance_sample-variance_entire)/variance_entire*100,
      max_hour_diff = abs(max_hour_sample - max_hour_entire),
      max_diff_pct = abs(max_sample - max_entire)/max_entire*100
      # max_ratio = max_sample/max_entire,
      
           )

kld_max_df_clean <- entropy_df_clean %>%
  filter(sample_length == 1)

```


```{r kld_max_determine, fig.height=10.5, fig.width = 8}

# make box plots of values in each group
ggplot(kld_max_df_clean, aes(y = kld,
                       group = interaction(home, location, energy_cluster, period_compare)))+
  geom_boxplot()+
  facet_wrap(vars(method, metric, energy_cluster))

# one max per kld method-----------------

kld_max_shape <-  kld_max_df_clean %>%
  filter(method== 'shape') %>%
  group_by(home, location, energy_cluster, metric, period_compare) %>%
    summarise(cutoff = mean(kld), .groups = 'drop') %>%
  # summarise(cutoff = median(kld)+1.5*IQR(kld), .groups = 'drop') %>%
  pull(cutoff) %>%max()


kld_max_time <-  kld_max_df_clean %>%
  filter(method== 'time') %>%
  group_by(home, location, energy_cluster, metric, period_compare) %>%
    summarise(cutoff = mean(kld), .groups = 'drop') %>%
  # summarise(cutoff = median(kld)+1.5*IQR(kld), .groups = 'drop') %>%
  pull(cutoff) %>%max()

# one max per metric per kld method---------------
kld_max_metric <- kld_max_df_clean %>%
  group_by(sample_length, home, location, energy_cluster, metric, method, period_compare) %>%
      summarise(cutoff = mean(kld), .groups = 'drop') %>%
  group_by(sample_length, metric, method, period_compare) %>%
        summarise(max_kld_cutoff = max(cutoff), .groups = 'drop') %>%
    # summarise(max_kld_cutoff = median(kld), .groups = 'drop') %>%
  rename(sample_min = sample_length)

# one max per metric per home per kld method---------------
kld_max_home <- kld_max_df_clean %>%
  group_by(sample_length, home, location, energy_cluster, metric, method, period_compare) %>%
      summarise(cutoff = mean(kld), .groups = 'drop') %>%
  group_by(sample_length, metric, method, home, period_compare) %>%
        summarise(max_kld_cutoff = max(cutoff), .groups = 'drop') %>%
    # summarise(max_kld_cutoff = median(kld), .groups = 'drop') %>%
  rename(sample_min = sample_length)

# one max per metric per sensor per time period per kld method -----------------

kld_max_conditional <- kld_max_df_clean %>%
  group_by(sample_length, home, location, energy_cluster, metric, method, period_compare) %>%
      summarise(max_kld_cutoff = mean(kld), .groups = 'drop') %>%
  # summarise(max_kld_cutoff = median(kld), .groups = 'drop') %>%
  rename(sample_min = sample_length)


```

 * If "universal" maximum relative entropy is used to scale, the *average* of the *average relative entropy values (calculated separately for each condition)* for sample length of 1 day was determined **between all sensors, energy clusters, and metrics** and chosen as the "zero" point in the scale, for each method separately. So there was only one max value for each method (time and shape).
 * If "metric" maximum relative entropy is used to scale, the *average* of the *average relative entropy values (calculated separately for each condition)* for sample length of 1 day was determined **between all sensors and energy clusters for each metric separately** was chosen as the "zero" point in the scale, for each method separately.
 * add on home to metric if home was used
 * If conditional maximum relative entropy is used to scale, the *average* relative entropy values for sample length of 1 day **for each metric recorded by each sensor during each energy cluster separately** was chosen as the "zero" point in the scale, for each method separately. So in this case there were about 50+ different maximum values. 
 
```{r create_scaled_entropy_df}

# if( max_method == 'universal'){
# 
# scaled_entropy_df <- entropy_df_clean %>%
#   mutate(scaled_kld = case_when(
#     method == 'time' ~ 1- kld/kld_max_time,
#         method == 'shape' ~ 1 - kld/kld_max_shape,
#     TRUE ~ NA_real_
#   ))
# 
# }else if (max_method == 'metric'){
# 
# scaled_entropy_df <- entropy_df_clean %>%
#   # join a and b, keep all rows in a
#   left_join(
#     kld_max_metric,
#             by = c('metric', 'method')) %>%
#   mutate(scaled_kld = 1-kld/max_kld_cutoff)
# 
# }else if (max_method == 'conditional'){
# 
# scaled_entropy_df <- entropy_df_clean %>%
#   # join a and b, keep all rows in a
#   left_join(
#         kld_max_conditional,
#             by = c('home', 'location', 'energy_cluster',
#                    'metric', 'method')) %>%
#   mutate(scaled_kld = 1-kld/max_kld_cutoff)
# }
# 
# # insert column telling which method was used
# scaled_entropy_df <- scaled_entropy_df %>%
#   mutate(kld_max_method = max_method)

# 
# scaled_entropy_df <- 
#   bind_rows(
#     
#     entropy_df_clean %>%
#   mutate(scaled_kld = case_when(
#     method == 'time' ~ 1- kld/kld_max_time,
#         method == 'shape' ~ 1 - kld/kld_max_shape,
#     TRUE ~ NA_real_
#   )) %>% mutate(kld_max_method = 'universal'),
#   
# entropy_df_clean %>%
#   # join a and b, keep all rows in a
#   left_join(
#     kld_max_metric,
#             by = c('metric', 'method')) %>%
#   mutate(scaled_kld = 1-kld/max_kld_cutoff,
#          kld_max_method = 'metric'),
# 
# entropy_df_clean %>%
#   # join a and b, keep all rows in a
#   left_join(
#         kld_max_conditional,
#             by = c('home', 'location', 'energy_cluster',
#                    'metric', 'method')) %>%
#   mutate(scaled_kld = 1-kld/max_kld_cutoff,
#          kld_max_method = 'conditional')
# )

scaled_entropy_df <- list(
  #scaled only per method (time/shape)
   entropy_df_clean %>%
  mutate(
    index = row_number(),
    scaled_kld_universal = case_when(
    method == 'time' ~ 1- kld/kld_max_time,
        method == 'shape' ~ 1 - kld/kld_max_shape,
    TRUE ~ NA_real_
  )),
        # scaled per metric as well
    entropy_df_clean %>%
    mutate(index = row_number()) %>%
  # join a and b, keep all rows in a
  left_join(
    kld_max_metric,
            by = c('metric', 'method')) %>%
  mutate(scaled_kld_metric = 1-kld/max_kld_cutoff) %>%
      select(index, scaled_kld_metric),
  
  # scaled per home
entropy_df_clean %>%
  mutate(index = row_number()) %>%
# join a and b, keep all rows in a
  left_join(
        kld_max_home,
            by = c('home',
                   'metric', 'method')) %>%
  mutate(scaled_kld_home = 1-kld/max_kld_cutoff) %>%
      select(index, scaled_kld_home),

  # scaled per complete condition
entropy_df_clean %>%
  mutate(index = row_number()) %>%
# join a and b, keep all rows in a
  left_join(
        kld_max_conditional,
            by = c('home', 'location', 'energy_cluster',
                   'metric', 'method')) %>%
  mutate(scaled_kld_conditional = 1-kld/max_kld_cutoff) %>%
      select(index, scaled_kld_conditional)
)%>% reduce(full_join, by = 'index')





unwanted_scaled_na <- scaled_entropy_df %>%
  filter(scaled_kld_universal %>% is.na() | 
           scaled_kld_metric %>% is.na() |
           scaled_kld_conditional %>% is.na())

```

### `r unwanted_scaled_na %>% nrow()` unexpected missing values in scaled entropy data

## Testing Different Entropy Thresholds


### Effect on when individual sample Scaled Entropy crosses below threshold

```{r pdf_plots, eval = FALSE}

# time -------------------

meth <- 'time'
## pm25

{
  met <- 'pm25'
  
  a <- scaled_entropy_df %>% filter(metric == met, method == meth,
                                    sample_length %in% (
                                      if(met == 'pm25') pdf_days_pm else
                                        if(met == 'voc') pdf_days_voc else
                                          stop('met not correct')
                                    ),
                                      kld_max_method == max_method
  )
  
  lvls <- levels(as.factor(a$sample_length))
  values <- by(a, a$sample_length, function(x) sum(!is.na(x$scaled_kld)))
  below0 <- by(a, a$sample_length, function(x) sum(x$scaled_kld <0))
  labels <- paste(lvls,", n=",as.integer(values),", ", below0, " values < 0",sep="")
  
  ggplot(a, aes(x = scaled_kld, fill = as.factor(sample_length)))+
    geom_density(alpha = 0.5)+
    xlab("Temporal Representativeness")+
    ggtitle(label = paste(
      if(meth == 'time') 'Time-Structured Representativeness of' else
        if(meth == 'shape') 'Magnitude-Based Representativeness of', met))+
    coord_cartesian(xlim = c(0,1))+ # limit Representativeness from 0 to 1
    labs(fill = 'Length of Sample, days')+
    scale_fill_manual( values = length_colors,
                       labels=labels) +
    annotate('text', x = -Inf, y = Inf, hjust = 0, vjust = 1,
             label = paste0('Scale Method:\n',
                            max_method))+
    # add threshold lines
    lapply(c(1:3), function(i) {
    geom_vline(xintercept = thresh_vector[i],
               linetype = 'dashed',
               color = 'black', lwd = 1)
      })+
    # add threshold values
    lapply(c(1:3), function(i) {
      annotate('text', x=thresh_vector[i]-0.02, y = -0.1,
             label=thresh_vector[i],
             angle=90, size=xsmall+1, color = 'black')
    })+
    theme_classic()+
    theme(
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank()
    )
}

##  voc

{
  met <- 'voc'
  
  a <- scaled_entropy_df %>% filter(metric == met, method == meth,
                                    sample_length %in% (
                                      if(met == 'pm25') pdf_days_pm else
                                        if(met == 'voc') pdf_days_voc else
                                          stop('met not correct')
                                    ),
                                      kld_max_method == max_method
  )
  
  lvls <- levels(as.factor(a$sample_length))
  values <- by(a, a$sample_length, function(x) sum(!is.na(x$scaled_kld)))
  below0 <- by(a, a$sample_length, function(x) sum(x$scaled_kld <0))
  labels <- paste(lvls,", n=",as.integer(values),", ", below0, " values < 0",sep="")
  
  ggplot(a, aes(x = scaled_kld, fill = as.factor(sample_length)))+
    geom_density(alpha = 0.5)+
    xlab("Temporal Representativeness")+
    ggtitle(label = paste(
      if(meth == 'time') 'Time-Structured Representativeness of' else
        if(meth == 'shape') 'Magnitude-Based Representativeness of', met))+
    coord_cartesian(xlim = c(0,1))+ # limit Representativeness from 0 to 1
    labs(fill = 'Length of Sample, days')+
    scale_fill_manual( values = length_colors,
                       labels=labels) +
    annotate('text', x = -Inf, y = Inf, hjust = 0, vjust = 1,
             label = paste0('Scale Method:\n',
                            max_method))+
    # add threshold lines
    lapply(c(1:3), function(i) {
    geom_vline(xintercept = thresh_vector[i],
               linetype = 'dashed',
               color = 'black', lwd = 1)
      })+
    # add threshold values
    lapply(c(1:3), function(i) {
      annotate('text', x=thresh_vector[i]-0.02, y = -0.1,
             label=thresh_vector[i],
             angle=90, size=xsmall+1, color = 'black')
    })+
    theme_classic()+
    theme(
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank()
    )
}

# shape -------------------

meth <- 'shape'

## pm25 

{
  met <- 'pm25'
  
  a <- scaled_entropy_df %>% filter(metric == met, method == meth,
                                    sample_length %in% (
                                      if(met == 'pm25') pdf_days_pm else
                                        if(met == 'voc') pdf_days_voc else
                                          stop('met not correct')
                                    ),
                                      kld_max_method == max_method
  )
  
  lvls <- levels(as.factor(a$sample_length))
  values <- by(a, a$sample_length, function(x) sum(!is.na(x$scaled_kld)))
  below0 <- by(a, a$sample_length, function(x) sum(x$scaled_kld <0))
  labels <- paste(lvls,", n=",as.integer(values),", ", below0, " values < 0",sep="")
  
  ggplot(a, aes(x = scaled_kld, fill = as.factor(sample_length)))+
    geom_density(alpha = 0.5)+
    xlab("Temporal Representativeness")+
    ggtitle(label = paste(
      if(meth == 'time') 'Time-Structured Representativeness of' else
      if(meth == 'shape') 'Magnitude-Based Representativeness of', met))+
    coord_cartesian(xlim = c(0,1))+ # limit Representativeness from 0 to 1
    labs(fill = 'Length of Sample, days')+
    scale_fill_manual( values = length_colors,
                       labels=labels) +
    annotate('text', x = -Inf, y = Inf, hjust = 0, vjust = 1,
             label = paste0('Scale Method:\n',
                            max_method))+
    # add threshold lines
    lapply(c(1:3), function(i) {
    geom_vline(xintercept = thresh_vector[i],
               linetype = 'dashed',
               color = 'black', lwd = 1)
      })+
    # add threshold values
    lapply(c(1:3), function(i) {
      annotate('text', x=thresh_vector[i]-0.02, y = -0.1,
             label=thresh_vector[i],
             angle=90, size=xsmall+1, color = 'black')
    })+
    theme_classic()+
    theme(
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank()
    )
}

##  voc

{
  met <- 'voc'
  
  a <- scaled_entropy_df %>% filter(metric == met, method == meth,
                                    sample_length %in% (
                                      if(met == 'pm25') pdf_days_pm else
                                        if(met == 'voc') pdf_days_voc else
                                          stop('met not correct')
                                    ),
                                      kld_max_method == max_method
  )
  
  lvls <- levels(as.factor(a$sample_length))
  values <- by(a, a$sample_length, function(x) sum(!is.na(x$scaled_kld)))
  below0 <- by(a, a$sample_length, function(x) sum(x$scaled_kld <0))
  labels <- paste(lvls,", n=",as.integer(values),", ", below0, " values < 0",sep="")
  
  ggplot(a, aes(x = scaled_kld, fill = as.factor(sample_length)))+
    geom_density(alpha = 0.5)+
    xlab("Temporal Representativeness")+
    ggtitle(label = paste(
      if(meth == 'time') 'Time-Structured Representativeness of' else
        if(meth == 'shape') 'Magnitude-Based Representativeness of', met))+
    coord_cartesian(xlim = c(0,1))+ # limit Representativeness from 0 to 1
    labs(fill = 'Length of Sample, days')+
    scale_fill_manual( values = length_colors,
                       labels=labels) +
    annotate('text', x = -Inf, y = Inf, hjust = 0, vjust = 1,
             label = paste0('Scale Method:\n',
                            max_method))+
    # add threshold lines
    lapply(c(1:3), function(i) {
    geom_vline(xintercept = thresh_vector[i],
               linetype = 'dashed',
               color = 'black', lwd = 1)
      })+
    # add threshold values
    lapply(c(1:3), function(i) {
      annotate('text', x=thresh_vector[i]-0.02, y = -0.1,
             label=thresh_vector[i],
             angle=90, size=xsmall+1, color = 'black')
    })+
    theme_classic()+
    theme(
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank()
    )

}




```

### Test how many samples exceed represetnativeness threshold
### at different threshod values

```{r threshold_table, eval = FALSE}
 
frac.above.threshold <- function(threshold) {

  a <- scaled_entropy_df %>%
      group_by(method, metric, energy_cluster, sample_length) %>%
    summarize(
      n_condition = n(), # count total number in each group
      n_greater = sum(scaled_kld>=threshold), # count number in each group > thresh
      frac_greater = n_greater/n_condition, .groups = 'drop') %>%
    mutate(thresh = threshold)
}

threshold_df <- map(thresh_vector, frac.above.threshold) %>% bind_rows()

```

```{r barchart_threshold, fig.height=7, fig.width = 10.5, eval = FALSE}

# Time Structured--------------

meth <- 'time'
a <- threshold_df %>% filter(sample_length %in% c(3,7,11,15),
                             method == meth)
 # bar chart showing fraction that acieved representativeness by smaple_length
# facet by metric and method
ggplot(a, aes(x = as.factor(sample_length), y = frac_greater,
                         fill = as.factor(thresh)))+
  geom_col(position = 'dodge')+
  facet_grid(vars(factor(energy_cluster,
                         levels = energy_breaks)),
             vars(metric),
             labeller = labeller.metrics.seasons)+
  # # add n of sample length for each condition
  # geom_text(aes( label = n_condition), y = 1.05, size = smaller)+
  ggtitle(label = paste(meth, 'Samples Greater than Representativeness Thresholds'))+
  ylab('Fraction Greater than Threshold')+
  xlab('Sample Length, days')+
  coord_cartesian(ylim = c(0,1.05))+
  scale_fill_manual(values = threshold_colors,
                    name = 'Threshold')+
  theme_bw()+
  theme(
    title = element_text(size = medium),
    axis.title = element_text(size = medium+2),
    axis.text = element_text(size = medium),
    strip.text = element_text(size = medium),
    legend.text = element_text(size = medium),
    legend.title = element_text(size = medium),
    panel.grid.major.x = element_blank())+
  scale_y_continuous(breaks = c(0, 0.5, 1),
                     minor_breaks = c(0.25, 0.75))

# Magnitude-Based--------------

meth <- 'shape'
a <- threshold_df %>% filter(sample_length %in% c(3,7,11, 15),
                             method == meth)
 # bar chart showing fraction that acieved representativeness by smaple_length
# facet by metric and method
ggplot(a, aes(x = as.factor(sample_length), y = frac_greater,
                         fill = as.factor(thresh)))+
  geom_col(position = 'dodge')+
  facet_grid(vars(factor(energy_cluster,
                         levels = energy_breaks)),
             vars(metric),
             labeller = labeller.metrics.seasons)+
  # # add n of sample length for each condition
  # geom_text(aes( label = n_condition), y = 1.05, size = smaller)+
  ggtitle(label = paste(meth, 'Samples Greater than Representativeness Thresholds'))+
  ylab('Fraction Greater than Threshold')+
  xlab('Sample Length, days')+
    coord_cartesian(ylim = c(0,1.05))+
  scale_fill_manual(values = threshold_colors,
                    name = 'Threshold')+
  theme_bw()+
  theme(
    title = element_text(size = medium),
    axis.title = element_text(size = medium+2),
    axis.text = element_text(size = medium),
    strip.text = element_text(size = medium),
    legend.text = element_text(size = medium),
    legend.title = element_text(size = medium),
    panel.grid.major.x = element_blank())+
  scale_y_continuous(breaks = c(0, 0.5, 1),
                     minor_breaks = c(0.25, 0.75))


  
```


## Average Representativeness as function of sample length
```{r determine_max_for_avg_data}
# pooled rooms------------------------
## one max per kld method-----------------

avg_pooled_kld_max_universal <-  kld_max_df_clean %>%
  group_by(home, energy_cluster, metric, method, period_compare) %>%
    summarise(kld_cutoff = mean(kld), .groups = 'drop')%>%
    group_by(method, period_compare) %>%
    summarise(max_kld = max(kld_cutoff), .groups = 'drop')

## one max per metric per kld method---------------
avg_pooled_kld_max_metric <-  kld_max_df_clean %>%
  group_by(home, energy_cluster, metric, method, period_compare) %>%
    summarise(kld_cutoff = mean(kld), .groups = 'drop')%>%
    group_by(method, metric, period_compare) %>%
    summarise(max_kld = max(kld_cutoff), .groups = 'drop')

## one max per metric per home per kld method---------------
avg_pooled_kld_max_home <-  kld_max_df_clean %>%
  group_by(home, energy_cluster, metric, method, period_compare) %>%
    summarise(kld_cutoff = mean(kld), .groups = 'drop')%>%
    group_by(method, metric, home, period_compare) %>%
    summarise(max_kld = max(kld_cutoff), .groups = 'drop')

## one max per metric per sensor per time period per kld method -----------------

avg_pooled_kld_max_conditional <-  kld_max_df_clean %>%
  group_by(home, energy_cluster, metric, method, period_compare) %>%
    summarise(max_kld = mean(kld), .groups = 'drop')




# rooms not pooled------------------------
## one max per kld method-----------------

avg_kld_max_universal <-  kld_max_df_clean %>%
  group_by(home, energy_cluster, metric, method, location, period_compare) %>%
    summarise(kld_cutoff = mean(kld), .groups = 'drop')%>%
    group_by(method, period_compare) %>%
    summarise(max_kld = max(kld_cutoff), .groups = 'drop')

## one max per metric per kld method---------------
avg_kld_max_metric <-  kld_max_df_clean %>%
  group_by(home, energy_cluster, metric, method, location, period_compare) %>%
    summarise(kld_cutoff = mean(kld), .groups = 'drop')%>%
    group_by(method, metric, period_compare) %>%
    summarise(max_kld = max(kld_cutoff), .groups = 'drop')

## one max per metric per home per kld method---------------
avg_kld_max_home <-  kld_max_df_clean %>%
  group_by(home, energy_cluster, metric, method, location, period_compare) %>%
    summarise(kld_cutoff = mean(kld), .groups = 'drop')%>%
    group_by(method, metric, home, period_compare) %>%
    summarise(max_kld = max(kld_cutoff), .groups = 'drop')

## one max per metric per sensor per time period per kld method -----------------

avg_kld_max_conditional <-  kld_max_df_clean %>%
  group_by(home, energy_cluster, metric, method, location, period_compare) %>%
    summarise(max_kld = mean(kld), .groups = 'drop')


```

```{r create_avg_scaled_kld_df}

# rooms pooled------------------------

avg_pooled_kld_df <- entropy_df_clean %>%
  group_by(metric, home, energy_cluster, sample_length, method, period_compare) %>%
  summarize(
    avg_kld = mean(kld), n_samples = n(), .groups = 'drop')%>%
    group_by(metric, home, energy_cluster, method, period_compare) %>%
  mutate(n_samples_max = max(n_samples),
         n_samples_frac = n_samples/n_samples_max) %>%
  ungroup()

avg_pooled_scaled_entropy_df <- list(
  #scaled only per method (time/shape)
avg_pooled_kld_df%>%
    left_join(avg_pooled_kld_max_universal,
              by = c('method', 'period_compare')) %>%
  mutate(avg_kld_scaled_universal = 1-avg_kld/max_kld)%>%
  select(-max_kld),

  # scaled per metric as well
avg_pooled_kld_df %>%
    left_join(avg_pooled_kld_max_metric,
              by = c('method', 'metric', 'period_compare')) %>%
  mutate(avg_kld_scaled_metric = 1-avg_kld/max_kld)%>%
  select(-max_kld),

  # scaled per home as well
avg_pooled_kld_df %>%
    left_join(avg_pooled_kld_max_home,
              by = c('method', 'metric', 'home', 'period_compare')) %>%
  mutate(avg_kld_scaled_home = 1-avg_kld/max_kld)%>%
  select(-max_kld),

  # scaled per condition as well
avg_pooled_kld_df %>%
    left_join(avg_pooled_kld_max_conditional,
              by = c('metric', 'home', 'energy_cluster',
                     'method', 'period_compare')) %>%
  mutate(avg_kld_scaled_conditional = 1-avg_kld/max_kld)%>%
  select(-max_kld)

) %>% reduce(full_join, by = c('metric', 'home', 'energy_cluster',
                               'sample_length', 'method', 'avg_kld',
                               'n_samples', 'n_samples_max', 'n_samples_frac',
                               'period_compare'))
  
  
 # rooms not pooled ----------------- 
  avg_kld_df <- entropy_df_clean %>%
  group_by(metric, home, energy_cluster, sample_length, method, location, period_compare) %>%
  summarize(
    avg_kld = mean(kld), n_samples = n(), .groups = 'drop')%>%
    group_by(metric, home, energy_cluster, method, location, period_compare) %>%
  mutate(n_samples_max = max(n_samples),
         n_samples_frac = n_samples/n_samples_max) %>%
  ungroup()

avg_scaled_entropy_df <- list(
  #scaled only per method (time/shape)
avg_kld_df%>%
    left_join(avg_kld_max_universal,
              by = c('method', 'period_compare')) %>%
  mutate(avg_kld_scaled_universal = 1-avg_kld/max_kld)%>%
  select(-max_kld),

  # scaled per metric as well
avg_kld_df %>%
    left_join(avg_kld_max_metric,
              by = c('method', 'metric', 'period_compare')) %>%
  mutate(avg_kld_scaled_metric = 1-avg_kld/max_kld)%>%
  select(-max_kld),

  # scaled per metric as well
avg_kld_df %>%
    left_join(avg_kld_max_home,
              by = c('method', 'metric', 'home', 'period_compare')) %>%
  mutate(avg_kld_scaled_home = 1-avg_kld/max_kld)%>%
  select(-max_kld),

  # scaled per condition as well
avg_kld_df %>%
    left_join(avg_kld_max_conditional,
              by = c('metric', 'home', 'energy_cluster',
                     'method', 'location', 'period_compare')) %>%
  mutate(avg_kld_scaled_conditional = 1-avg_kld/max_kld)%>%
  select(-max_kld)

) %>% reduce(full_join, by = c('metric', 'home', 'energy_cluster',
                               'sample_length', 'method', 'avg_kld',
                               'n_samples', 'n_samples_max', 'n_samples_frac',
                               'location', 'period_compare'))
```



```{r function_avg_entropy_plotter}

entropy.plot <- function (
  hm, meth,
  scale_method, # 'universal', 'metric', 'home', or 'condtitional'
  # omit a sampling period of given length
  # if this proportion of possible samples
  # were not availabel in data
  simple = FALSE,
  metrics = c('pm25', 'voc'),
  room = 'pooled' # or choose a room
  ) {
  
  data <- if(room == 'pooled') avg_pooled_scaled_entropy_df else{
                 avg_scaled_entropy_df %>% filter(location == room)}
  
  # add ach50 for home to plot
ach50 <- assessment_data %>% filter( home == hm) %>%
  pull(ach50)
ach50 <- if(is_empty(ach50)) NA else if (is.na(ach50)) {
  NA} else ach50

  # for one home:
  a <- data %>%
    filter(home == hm & metric %in% metrics & method == meth)

  if(nrow(a) == 0) {
    plot <- NULL # return NULL if no data for home/metric/cluster combo
  }else {
    
    if(scale_method == 'universal'){
      rep_measure <- 'avg_kld_scaled_universal'
    } else if(scale_method == 'metric'){
            rep_measure <- 'avg_kld_scaled_metric'
    } else if(scale_method == 'home'){
            rep_measure <- 'avg_kld_scaled_home'
            } else if(scale_method == 'conditional'){
            rep_measure <- 'avg_kld_scaled_conditional'
}
    # plot results
    plot <-
      ggplot(aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster), data = a)+
      geom_line()+
      geom_point(aes(size = n_samples_frac))+ # make size of pooints proportional to n
      scale_size_area(max_size = 2)+
      xlab('Sample Length, days')+
      ylab(rep_measure)+
      # # add threshold lines
      # geom_hline(yintercept=thresh_vector, linetype="dashed",
      #            color = "black", size=0.5)+
      # # to color threshold lines based on value
      # lapply(c(1:3), function(i){
      #         geom_hline(yintercept=thresh_vector[i],
      #                    linetype="dashed", 
      #            color = threshold_colors[i], size=0.5)
      # })+
      coord_cartesian(ylim = c(0,1))+
      ggtitle(paste('Home',hm, ifelse(room == 'pooled',
                                      'Pooled Rooms',
                                      room),
                    scale_method)) +
      scale_x_continuous(breaks=seq(0,28,7))+
    #   # add error bars
    # geom_ribbon(aes(ymin = low_val, ymax = high_val,
    #                 fill = energy_cluster),
    #             alpha = 0.15, color = NA)+
  scale_fill_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        scale_color_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
      theme_bw()+
      #prep for grid if simple is TRUE
      {if(simple ==TRUE) 
        theme(
        legend.position = 'none',
        axis.title = element_blank(),
                    axis.text = element_text(size = small),
            plot.title = element_text(size = small+4, hjust = 0.5),
            legend.title = element_text(size = small+4))
        else
              theme(
                axis.title = element_text(size = medium),
                axis.text = element_text(size = medium-2),
                strip.text = element_text(size = medium)
              )}+
            facet_wrap(vars(metric), labeller = labeller.metrics)+
          {if(!is.na(ach50)) annotate('text', x = 28, y = 0.18,
                   hjust = 1, size = ifelse(simple == TRUE, xsmall+0.5,small-1),
             # label = bquote(ACH[50] ==  ~ .(ach50))
             label = paste( 'ACH50 =', ach50)
             )}+ # annotate with ach50 if available
  scale_y_continuous(breaks = c(0, 0.5, 1),
                     minor_breaks = c(0.25, 0.75))

   }
  plot
}

#function to put plots in a grid
grid.plots <- function(plots, title,
                     y_val = 'Temporal Representativeness',
                     x_val = 'Sample Length, days', ncol = 4, nrow = 4) {
  ##omit NULL values (from homes or rooms without valid data)
  plots <- plots[!sapply(plots, is.null)]
  
  do.call('grid.arrange', c(plots, top = title, left = y_val, bottom = x_val,
                            ncol = ncol, nrow = nrow))
  
}

```


### Pooled Rooms

* Test for one home
```{r plot_single_home_avg_entropy, fig.width = 7, fig.height = 4}

# plot results for one home
entropy.plot('012', meth = 'shape', scale_method = 'conditional'
             ,room = 'pooled')

```

* Plot for all homes
```{r grid_plot_avg_entropy, fig.height=8, fig.width = 10.5, eval = FALSE}

# time ----------------
meth <- 'time'

{

  # make plots for all homes
map(homes_all, function (x_home) {
    entropy.plot(hm = x_home, simple = TRUE, meth = meth,
                 scale_method = max_method ,room = 'pooled')
}) %>%
  grid.plots(title = 'Time-Structured Scaled Relative Entropy')%>%
  annotate_figure(
    fig.lab = paste0('Scale Method: ',
                     max_method))

}

# shape ----------------
meth <- 'shape'

{
# make plots for all homes
map(homes_all, function (x_home) {
    entropy.plot(hm = x_home, simple = TRUE, meth = meth,
                 scale_method = max_method ,room = 'pooled')}) %>%
  grid.plots(title = 'Magnitiude-Based Scaled Relative Entropy') %>%
  annotate_figure(
    fig.lab = paste0('Scale Method: ',
                     max_method))

}



```

* arranged by tier
```{r grid_plot_avg_entropy_tiers, fig.height=4, fig.width = 10.5, eval = FALSE}
# time-------------------
meth <- 'time'


# make plots for all homes
plots_t3 <- map(homes_tier3, function (x_home) {
    entropy.plot(hm = x_home, simple = TRUE, meth = meth,
                 scale_method = max_method ,room = 'pooled')})

plots_t2 <- map(homes_tier2, function (x_home) {
    entropy.plot(hm = x_home, simple = TRUE, meth = meth,
                 scale_method = max_method ,room = 'pooled')})

grid.arrange(grobs = c(plots_t2, plots_t3),
                          top = 'Time-Structured',
                          left = 'Temporal Representativeness',
                          bottom = 'Sample Length, days',
                          nrow = 2)

# shape---------------
meth <- 'shape'

# make plots for all homes
plots_t3 <- map(homes_tier3, function (x_home) {
    entropy.plot(hm = x_home, simple = TRUE, meth = meth,
                 scale_method = max_method ,room = 'pooled')})

plots_t2 <- map(homes_tier2, function (x_home) {
    entropy.plot(hm = x_home, simple = TRUE, meth = meth,
                 scale_method = max_method ,room = 'pooled')})

grid.arrange(grobs = c(plots_t2, plots_t3),
                          top = 'Magnitude-Based',
                          left = 'Temporal Representativeness',
                          bottom = 'Sample Length, days',
                          nrow = 2)

# # may need to use arrange grob in future
# # https://cran.r-project.org/web/packages/gridExtra/vignettes/arrangeGrob.html
# t3_row <- arrangeGrob(plots_t3, nrow = 1)
# t2_row <- arrangeGrob(plots_t2, nrow = 1)
# but will have to figure out how to convert ggplot rows to grob
# https://wilkelab.org/cowplot/reference/as_grob.html

```

### for each room

* Plot for all homes
```{r grid_plot_avg_entropy_rooms, fig.height=8, fig.width = 10.5, eval = FALSE}
# time ----------------
meth <- 'time'

{

  # make plots for all rooms, with all homes gridded
  map(locations_indoor, function (x_location) {
    
map(homes_all, function (x_home) {
    entropy.plot(hm = x_home, simple = TRUE, meth = meth,
                 scale_method = max_method ,room = x_location)
  }) %>%
  grid.plots(title = 'Time-Structured Scaled Relative Entropy')%>%
  annotate_figure(
    fig.lab = paste0('Scale Method: ',
                     max_method))

  })
  
}


# shape ----------------
meth <- 'shape'

{
  # make plots for all rooms, with all homes gridded
  map(locations_indoor, function (x_location) {
    map(homes_all, function (x_home) {
entropy.plot(hm = x_home, simple = TRUE, meth = meth,
                 scale_method = max_method ,room = x_location)
      }) %>%
  grid.plots(title = 'Magnitiude-Based Scaled Relative Entropy') %>%
  annotate_figure(
    fig.lab = paste0('Scale Method: ',
                     max_method))
  })

}



```

* arranged by tier
```{r grid_plot_avg_entropy_tiers_rooms, fig.height=4, fig.width = 10.5, eval = FALSE}
# time-------------------
meth <- 'time'

  # make plots for all rooms, with all homes gridded
  map(locations_indoor, function (x_location) {
    
    # don't try a plot for kitchen if doing home 002
    if(x_location == 'kitchen'){
      homes_tier3 <- homes_tier3[-which(homes_tier3=='002')]
    }
plots_t3 <- map(homes_tier3, function (x_home) {
entropy.plot(hm = x_home, simple = TRUE, meth = meth,
                 scale_method = max_method ,room = x_location)
  })

plots_t2 <- map(homes_tier2, function (x_home) {
entropy.plot(hm = x_home, simple = TRUE, meth = meth,
                 scale_method = max_method ,room = x_location)
  })

grid.arrange(grobs = c(plots_t2, plots_t3),
                          top = 'Time-Structured',
                          left = 'Temporal Representativeness',
                          bottom = 'Sample Length, days',
                          nrow = 2)
})

# shape---------------
meth <- 'shape'

  # make plots for all rooms, with all homes gridded
  map(locations_indoor, function (x_location) {
    
        # don't try a plot for kitchen if doing home 002
    if(x_location == 'kitchen'){
      homes_tier3 <- homes_tier3[-which(homes_tier3=='002')]
    }
    plots_t3 <- map(homes_tier3, function (x_home) {
entropy.plot(hm = x_home, simple = TRUE, meth = meth,
                 scale_method = max_method ,room = x_location)
      })

plots_t2 <- map(homes_tier2, function (x_home) {
entropy.plot(hm = x_home, simple = TRUE, meth = meth,
                 scale_method = max_method ,room = x_location)
  })

grid.arrange(grobs = c(plots_t2, plots_t3),
                          top = 'Magnitude-Based',
                          left = 'Temporal Representativeness',
                          bottom = 'Sample Length, days',
                          nrow = 2)
})

# # may need to use arrange grob in future
# # https://cran.r-project.org/web/packages/gridExtra/vignettes/arrangeGrob.html
# t3_row <- arrangeGrob(plots_t3, nrow = 1)
# t2_row <- arrangeGrob(plots_t2, nrow = 1)
# but will have to figure out how to convert ggplot rows to grob
# https://wilkelab.org/cowplot/reference/as_grob.html

```




## Compare Deviations between differences of summary stats of sample and monitoring period to Representativess Values

```{r correlation, eval = FALSE}
# for one condition
# a <- entropy_df_clean %>% filter(method == 'shape', home == '001',
#                                  location == 'living', metric == 'pm25',
#                                  energy_cluster == 'heat')
# test <- cor.test(a$kld, a$median_diff, method = 'spearman')%>% suppressWarnings()
# list('coeff' = test$estimate, 'p_val' = test$p.value)



# combinations <- expand.grid(homes_all, metrics_all, locations_indoor, clusters_all)
# apply(combinations, 1, function(x_home, x_location, x_metric, x_cluster){
#   a <- entropy_df_clean %>% filter(method == 'shape', home == x_home,
#                                  location == x_location, metric == x_metric,
#                                  energy_cluster == x_cluster)
#   if (nrow(a)>3) {
#     cor.test(a$kld, a$median_diff, method = 'spearman') } else NULL
#   
# }
# )

variables_dependent <- c(
  'median_diff', 'variance_diff', 'mean_diff',
  'max_hour_diff', 'max_diff'
                           )





# for all conditions
cor.table <- function(pooled){
  map(variables_dependent, function(dependent){
      
      # if pooled is all, don't separate by any condition
      if(pooled == 'all'){
            map(c('kld', 'scaled_kld_universal'), function(independent){
              
        a <- scaled_entropy_df
        test <- cor.test(a %>% pull(independent),
                         a %>% pull(dependent), method = 'spearman')%>%
          suppressWarnings()
        
        #return
        list('coeff' = test$estimate, 'p_val' = test$p.value,
             'independent' = independent, 'dependent' = dependent,
             'home' = NA, 'location' = NA,
             'metric' = NA, 'energy_cluster' = NA,
             'kld_max_method' = 'universal', 'pooled' = pooled)
            }) %>% bind_rows()
        
      } else if (pooled == 'none') {
        
            map(c('kld', 'scaled_kld_conditional'), function(independent){
        map(homes_no5, function(x_home){
          map(locations_indoor, function(x_location){
            map(clusters_all, function(x_cluster){
              map(metrics_all, function(x_metric){
                # make a row for the case of an error
                result_error <- 
                  list('coeff' = NA, 'p_val' = NA,
                       'independent' = independent, 
                       'dependent' = dependent, 'home' = x_home,
                       'location' = x_location,
                       'metric' = x_metric, 'energy_cluster' = x_cluster,
                       'kld_max_method' = 'conditional',  'pooled' = pooled)
                
                a <- scaled_entropy_df %>% filter( home == x_home,
                                                   location == x_location,
                                                   metric == x_metric,
                                                   energy_cluster == x_cluster)
                
                if (nrow(a)>3) {
                  test <- cor.test(a %>% pull(independent), a %>% pull(dependent), method = 'spearman')%>%
                    suppressWarnings()
                  
                  # return
                  list('coeff' = test$estimate, 'p_val' = test$p.value,
                       'independent' = independent, 'dependent' = dependent, 'home' = x_home, 'location' = x_location,
                       'metric' = x_metric, 'energy_cluster' = x_cluster, 
                       'kld_max_method' = 'conditional', 'pooled' = pooled)
                }
                else result_error
        }) %>% bind_rows()
              }) %>% bind_rows()
            }) %>% bind_rows()
          }) %>% bind_rows()
        }) %>% bind_rows()
        
      } else if (pooled == 'metric') {
        
            map(c('kld', 'scaled_kld_metric'), function(independent){
        map(metrics_all, function(x_metric){
          
          # make a row for the case of an error
          result_error <- 
            list('coeff' = NA, 'p_val' = NA,
                 'independent' = independent, 'dependent' = dependent,
                 'home' = NA, 'location' = NA,
                 'metric' = x_metric, 'energy_cluster' = NA,
                 'kld_max_method' = 'metric',  'pooled' = pooled)
          
          a <- scaled_entropy_df %>% filter( metric == x_metric)
          
          if (nrow(a)>3) {
            test <- cor.test(a %>% pull(independent), a %>% pull(dependent), method = 'spearman')%>%
              suppressWarnings()
            
            # return
            list('coeff' = test$estimate, 'p_val' = test$p.value,
                 'independent' = independent, 'dependent' = dependent,
                 'home' = NA, 'location' = NA,
                 'metric' = x_metric, 
                 'kld_max_method' = 'metric', 'pooled' = pooled)
          }
          else result_error
          
        }) %>% bind_rows()
            }) %>% bind_rows()
      }
    }) %>% bind_rows()
}


# make a correlation table merging different pooling methods
cor_table <- bind_rows(
  cor.table('all'),
                       cor.table('metric'),
                       cor.table('none')
                       )

# function to plot correlations for given pooling method
cor.plot <- function(var_indep, var_dep){
a <- cor_table %>%
  filter(dependent == var_dep, independent == var_indep, !is.na(coeff))

ggplot(data = a)+
  geom_histogram(aes(x = coeff))+
  ggtitle(label = paste('Correlation'))
}
cor.plot('kld', 'median_diff')
cor.plot('kld', 'variance_diff')
cor.plot('kld', 'max_diff')
cor.plot('kld', 'max_hour_diff')

# cor.plot('scaled_kld_metric', 'median_diff')
cor.plot('scaled_kld_conditional', 'median_diff')
# cor.plot('scaled_kld_metric', 'median_diff')
cor.plot('scaled_kld_conditional', 'mean_diff')
# cor.plot('scaled_kld_metric', 'mean_diff')
cor.plot('scaled_kld_conditional', 'variance_diff')
# cor.plot('scaled_kld_metric', 'max_diff')
cor.plot('scaled_kld_conditional', 'max_diff')
# cor.plot('scaled_kld_metric', 'max_hour_diff')
cor.plot('scaled_kld_conditional', 'max_hour_diff')

```

### Individual homes
```{r heatmap_deviations_vs_rep, fig.height=7, fig.width = 10.5, eval = FALSE}

if(max_method == 'universal'){
      independent <- 'scaled_kld_universal'
    } else if(max_method == 'metric'){
            independent <- 'scaled_kld_metric'
    } else if(max_method == 'home'){
            independent <- 'scaled_kld_home'
            } else if(max_method == 'conditional'){
            independent <- 'scaled_kld_conditional'
            }

dependent <- 'median_diff'

# pm25-----------------------
met <- 'pm25'


a <- scaled_entropy_df %>% filter(metric == met,
                                  !is.na(get(independent)),
                                  !is.na(get(dependent))
                                  )
  
  ggplot(a, aes(x = get(independent), y = get(dependent), color = location))+
    # geom_bin2d(bins = c(1500,3000))+
        geom_point(size = 0.1)+
    ggtitle(label = met)+
    xlab(independent)+
    ylab(dependent)+
      coord_cartesian(
      xlim = c(0,1),
      ylim = c(0,5) #median value to...
    )+ 
    # labs(fill = 'Length of Sample, days')+
    # scale_fill_manual( values = length_colors,
    #                    labels=labels) +
    theme_bw()+
    theme(
      # axis.text.y = element_blank(),
      # axis.ticks.y = element_blank()
    )+
        facet_wrap(vars(home, metric))

  
  # voc-----------------------
met <- 'voc'


a <- scaled_entropy_df %>% filter(metric == met,
                                  !is.na(get(independent)),
                                  !is.na(get(dependent))
                                  )
  
  ggplot(a, aes(x = get(independent), y = get(dependent), color = location))+
    # geom_bin2d(bins = c(150,300))+
            geom_point(size = 0.5)+
    ggtitle(label = met)+
    xlab(independent)+
    ylab(dependent)+
      coord_cartesian(
      xlim = c(0,1),
      ylim = c(0,300) #median value to...
    )+ 
    # labs(fill = 'Length of Sample, days')+
    # scale_fill_manual( values = length_colors,
    #                    labels=labels) +
    theme_bw()+
    theme(
      # axis.text.y = element_blank(),
      # axis.ticks.y = element_blank()
    )+
        facet_wrap(vars(home, metric))


#####################  
  
  
  dependent <- 'max_hour_diff'
# pm25-----------------------
met <- 'pm25'


a <- scaled_entropy_df %>% filter(metric == met,
                                  !is.na(get(independent)),
                                  !is.na(get(dependent))
                                  )
  
  ggplot(a, aes(x = get(independent), y = get(dependent)))+
    geom_bin2d(bins = c(200,24))+
        # geom_point(size = 0.1)+
    ggtitle(label = met)+
    xlab(independent)+
    ylab(dependent)+
      coord_cartesian(
      xlim = c(0,1),
      ylim = c(0,10) #diff value to...
    )+ 
    # labs(fill = 'Length of Sample, days')+
    # scale_fill_manual( values = length_colors,
    #                    labels=labels) +
    theme_bw()+
    theme(
      # axis.text.y = element_blank(),
      # axis.ticks.y = element_blank()
    )+
        facet_wrap(vars(home, metric))

  
  # voc-----------------------
met <- 'voc'


a <- scaled_entropy_df %>% filter(metric == met,
                                  !is.na(get(independent)),
                                  !is.na(get(dependent))
                                  )
  
  ggplot(a, aes(x = get(independent), y = get(dependent)))+
    geom_bin2d(bins = c(200,24))+
        # geom_point(size = 0.5)+
    ggtitle(label = met)+
    xlab(independent)+
    ylab(dependent)+
      coord_cartesian(
      xlim = c(0,1),
      ylim = c(0,10) #median value to...
    )+ 
    # labs(fill = 'Length of Sample, days')+
    # scale_fill_manual( values = length_colors,
    #                    labels=labels) +
    theme_bw()+
    theme(
      # axis.text.y = element_blank(),
      # axis.ticks.y = element_blank()
    )+
        facet_wrap(vars(home, metric))


  
####################
  
dependent <- 'max_diff'

# pm25-----------------------
met <- 'pm25'


a <- scaled_entropy_df %>% filter(metric == met,
                                  !is.na(get(independent)),
                                  !is.na(get(dependent))
                                  )
  
  ggplot(a, aes(x = get(independent), y = get(dependent), color = location))+
    # geom_bin2d(bins = c(1500,3000))+
        geom_point(size = 0.1)+
    ggtitle(label = met)+
    xlab(independent)+
    ylab(dependent)+
      coord_cartesian(
      xlim = c(0,1),
      ylim = c(0,40) #median value to...
    )+ 
    # labs(fill = 'Length of Sample, days')+
    # scale_fill_manual( values = length_colors,
    #                    labels=labels) +
    theme_bw()+
    theme(
      # axis.text.y = element_blank(),
      # axis.ticks.y = element_blank()
    )+
        facet_wrap(vars(home, metric))

  
  # voc-----------------------
met <- 'voc'


a <- scaled_entropy_df %>% filter(metric == met,
                                  !is.na(get(independent)),
                                  !is.na(get(dependent))
                                  )
  
  ggplot(a, aes(x = get(independent), y = get(dependent), color = location))+
    # geom_bin2d(bins = c(150,300))+
            geom_point(size = 0.5)+
    ggtitle(label = met)+
    xlab(independent)+
    ylab(dependent)+
      coord_cartesian(
      xlim = c(0,1),
      ylim = c(0,1000) #median value to...
    )+ 
    # labs(fill = 'Length of Sample, days')+
    # scale_fill_manual( values = length_colors,
    #                    labels=labels) +
    theme_bw()+
    theme(
      # axis.text.y = element_blank(),
      # axis.ticks.y = element_blank()
    )+
        facet_wrap(vars(home, metric))


#####################  
```

### Pooled Homes
```{r heatmap_deviations_vs_rep_pooled_homes, fig.height=7, fig.width = 10.5, eval = FALSE}

if(max_method == 'universal'){
      independent <- 'scaled_kld_universal'
    } else if(max_method == 'metric'){
            independent <- 'scaled_kld_metric'
    } else if(max_method == 'home'){
            independent <- 'scaled_kld_home'
            } else if(max_method == 'conditional'){
            independent <- 'scaled_kld_conditional'
            }

dependent <- 'median_diff'

# all homes heatmap---------------------------------------

met <- 'pm25'

a <- scaled_entropy_df %>% filter(metric == met,
                                  !is.na(get(independent)),
                                  !is.na(get(dependent))
                                  )
  
  ggplot(a, aes(x = get(independent), y = get(dependent)))+
    geom_bin2d(bins = c(3000,6000))+
        # geom_point(size = 0.1)+
    ggtitle(label = met)+
    xlab(independent)+
    ylab(dependent)+
      coord_cartesian(
      xlim = c(0.5,1),
      ylim = c(0,5) #median value to...
    )+ 
    # labs(fill = 'Length of Sample, days')+
    # scale_fill_manual( values = length_colors,
    #                    labels=labels) +
    theme_bw()+
    theme(
      # axis.text.y = element_blank(),
      # axis.ticks.y = element_blank()
    )





```



## Compare Deviations between differences of summary stats of sample and monitoring period to Sample Length

```{r plot_deviation_vs_sample_length, fig.height=7, fig.width = 10.5, eval = FALSE}

if(max_method == 'universal'){
      independent <- 'scaled_kld_universal'
    } else if(max_method == 'metric'){
            independent <- 'scaled_kld_metric'
    } else if(max_method == 'home'){
            independent <- 'scaled_kld_home'
            } else if(max_method == 'conditional'){
            independent <- 'scaled_kld_conditional'
            }


dependent <- 'median_diff'

# pm25--------------------
met <- 'pm25'

a <- scaled_entropy_df %>% filter(
                                  !is.na(get(independent)),
                                  !is.na(get(dependent)))%>%
  filter(metric == met)

# to modify scales individually:
# https://fishandwhistle.net/post/2018/modifying-facet-scales-in-ggplot2/

  ggplot(data = a, aes(group = sample_length, x = sample_length,
                       y = get(dependent)))+
    geom_violin(color = 'grey')+
    geom_boxplot(width=0.35, outlier.shape = NA,
                 color = cbbPalette['dark_orange'],
                 lwd = 0.5)+
    # stat_summary(fun=median, geom="point", color="red")+
        coord_cartesian(ylim = c(0,5))+
    facet_wrap(vars(home, metric))+
    ylab(dependent)+
        theme_bw()
  
  
# voc-------------------------
  met <- 'voc'

  a <- scaled_entropy_df %>% filter(
                                  !is.na(get(independent)),
                                  !is.na(get(dependent)))%>%
  filter(metric == met)

# to modify scales individually:
# https://fishandwhistle.net/post/2018/modifying-facet-scales-in-ggplot2/

  ggplot(data = a, aes(group = sample_length, x = sample_length,
                       y = get(dependent)))+
    geom_violin(color = 'grey')+
    geom_boxplot(width=0.35,
                 outlier.shape = NA,
                 color = cbbPalette['dark_orange'],
                 lwd = 0.5)+
    # stat_summary(fun=median, geom="point", color="red")+
        coord_cartesian(ylim = c(0,700))+
    facet_wrap(vars(home, metric))+
    ylab(dependent)+
        theme_bw()
```

### Compare to KLD
```{r plot_deviations_vs_kld, eval = FALSE}
dependent <- 'median_diff'
independent <- 'kld'
met <- 'pm25'
a <- scaled_entropy_df %>% filter(metric == met,
                                  !is.na(get(independent)),
                                  !is.na(get(dependent))
  )
  
  ggplot(a, aes(x = get(independent), y = get(dependent)))+
    geom_bin2d(bins = c(10000,10000))+
    xlab("Relative Entropy")+
    ggtitle(label = paste('Relative Entropy of', met))+
    coord_cartesian(
      xlim = c(0,0.1),
      ylim = c(0,1) #median value to...
    )+ 
    # labs(fill = 'Length of Sample, days')+
    # scale_fill_manual( values = length_colors,
    #                    labels=labels) +
    theme_classic()+
    theme(
      # axis.text.y = element_blank(),
      # axis.ticks.y = element_blank()
    )

  
  

```

```{r heatmap_deviations_vs_kld_pooled_homes, fig.height=7, fig.width = 10.5, eval = FALSE}
# HOW DO DEVIATIONS CHANGE WITH KLD?
# independent <- 'kld'
# 
# dependent <- 'median_diff'
# 
# # all homes heatmap---------------------------------------
# 
# met <- 'pm25'
# 
# a <- entropy_df_clean %>% filter(metric == met,
#                                   !is.na(get(independent)),
#                                   !is.na(get(dependent))
#                                   )
#   
#   ggplot(a, aes(x = get(independent), y = get(dependent)))+
#     geom_bin2d(bins = c(3000,6000))+
#         # geom_point(size = 0.1)+
#     ggtitle(label = met)+
#     xlab(independent)+
#     ylab(dependent)+
#       coord_cartesian(
#       xlim = c(0,0.5),
#       ylim = c(0,2) #median value to...
#     )+ 
#     # labs(fill = 'Length of Sample, days')+
#     # scale_fill_manual( values = length_colors,
#     #                    labels=labels) +
#     theme_bw()+
#     theme(
#       # axis.text.y = element_blank(),
#       # axis.ticks.y = element_blank()
#     )
# 
# 
# 
# 

```









## Combine Average Representativeness with Deviation Measures

### Boxplots include pooled seasons

### Example Plot

```{r fig.height=3, fig.width = 6, eval = FALSE}

if(max_method == 'universal'){
      independent <- 'scaled_kld_universal'
      rep_measure <- 'avg_kld_scaled_universal'
    } else if(max_method == 'metric'){
            independent <- 'scaled_kld_metric'
      rep_measure <- 'avg_kld_scaled_metric'
    } else if(max_method == 'home'){
            independent <- 'scaled_kld_home'
      rep_measure <- 'avg_kld_scaled_home'
            } else if(max_method == 'conditional'){
            independent <- 'scaled_kld_conditional'
      rep_measure <- 'avg_kld_scaled_conditional'
            }
# shape--------------------------- 
meth <- 'shape'

dependent <- 'median_diff'

## pm25--------------------
met <- 'pm25'
coeff <- 10
hm <- '001'
  a <- avg_pooled_scaled_entropy_df %>%
    filter( metric == met & method == meth,
                                  sample_length %in% c(1,3,5,7:21),
            home == hm)

b <- scaled_entropy_df %>% filter(
                                  !is.na(get(independent)),
                                  !is.na(get(dependent)),
                                  sample_length %in% c(1,3,5,7:21))%>%
  filter(metric == met,
            home == hm)
    
      ggplot()+
    geom_violin(data = b, aes(group = sample_length, x = sample_length,
                       y = get(dependent)/coeff), width = 1.75,
                color = 'darkgrey')+
    geom_boxplot(data = b, aes(group = sample_length, x = sample_length,
                       y = get(dependent)/coeff), width=0.35, outlier.shape = NA,
                 color = 'black',
                 lwd = 0.5)+
        scale_y_continuous(
          breaks = c(0, 0.5, 1),
                     minor_breaks = c(0.25, 0.75),
          limits = c(0,1),
          sec.axis = sec_axis(trans = ~.*coeff, name = dependent)
        )+
    # stat_summary(fun=median, geom="point", color="red")+
    facet_wrap(vars(home))+
              theme_bw()+
    ylab(rep_measure)+
        ggtitle(label = paste0('Representativeness and ', dependent,
                              ' of ', met, ', Varying Sample Length, Scaled by ', max_method))+
        geom_line(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster))+
      geom_point(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster,
                 size = n_samples_frac))+# make size of pooints proportional to n
              scale_size_area(max_size = 2)+
      # # add threshold lines
      # geom_hline(yintercept=thresh_vector, linetype="dashed",
      #            color = "black", size=0.5)+
      # # to color threshold lines based on value
      # lapply(c(1:3), function(i){
      #         geom_hline(yintercept=thresh_vector[i],
      #                    linetype="dashed", 
      #            color = threshold_colors[i], size=0.5)
      # })+
      scale_x_continuous(breaks=seq(0,21,7), limits = c(0,21))+
    #   # add error bars
    # geom_ribbon(aes(ymin = low_val, ymax = high_val,
    #                 fill = energy_cluster),
    #             alpha = 0.15, color = NA)+
  scale_fill_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        scale_color_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        xlab('Sample Length, days')+
        theme(legend.position = 'left')
      

```

```{r fig.height=7, fig.width = 10.5, eval = FALSE}

if(max_method == 'universal'){
      independent <- 'scaled_kld_universal'
      rep_measure <- 'avg_kld_scaled_universal'
    } else if(max_method == 'metric'){
            independent <- 'scaled_kld_metric'
      rep_measure <- 'avg_kld_scaled_metric'
    } else if(max_method == 'home'){
            independent <- 'scaled_kld_home'
      rep_measure <- 'avg_kld_scaled_home'
            } else if(max_method == 'conditional'){
            independent <- 'scaled_kld_conditional'
      rep_measure <- 'avg_kld_scaled_conditional'
            }
# shape--------------------------- 
meth <- 'shape'

dependent <- 'median_diff'

## pm25--------------------
met <- 'pm25'
coeff <- 10

  a <- avg_pooled_scaled_entropy_df %>%
    filter( metric == met & method == meth,
                                  sample_length %in% c(1,3,5,7:21))

b <- scaled_entropy_df %>% filter(
                                  !is.na(get(independent)),
                                  !is.na(get(dependent)),
                                  sample_length %in% c(1,3,5,7:21))%>%
  filter(metric == met)
    
      ggplot()+
    geom_violin(data = b, aes(group = sample_length, x = sample_length,
                       y = get(dependent)/coeff), width = 1.75,
                color = 'darkgrey')+
    geom_boxplot(data = b, aes(group = sample_length, x = sample_length,
                       y = get(dependent)/coeff), width=0.35, outlier.shape = NA,
                 color = 'black',
                 lwd = 0.5)+
        scale_y_continuous(
          breaks = c(0, 0.5, 1),
                     minor_breaks = c(0.25, 0.75),
          limits = c(0,1),
          sec.axis = sec_axis(trans = ~.*coeff, name = dependent)
        )+
    # stat_summary(fun=median, geom="point", color="red")+
    facet_wrap(vars(home))+
              theme_bw()+
    ylab(rep_measure)+
        ggtitle(label = paste0('Representativeness and ', dependent,
                              ' of ', met, ', Varying Sample Length, Scaled by ', max_method))+
        geom_line(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster))+
      geom_point(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster,
                 size = n_samples_frac))+# make size of pooints proportional to n
              scale_size_area(max_size = 2)+
      # # add threshold lines
      # geom_hline(yintercept=thresh_vector, linetype="dashed",
      #            color = "black", size=0.5)+
      # # to color threshold lines based on value
      # lapply(c(1:3), function(i){
      #         geom_hline(yintercept=thresh_vector[i],
      #                    linetype="dashed", 
      #            color = threshold_colors[i], size=0.5)
      # })+
      scale_x_continuous(breaks=seq(0,21,7), limits = c(0,21))+
    #   # add error bars
    # geom_ribbon(aes(ymin = low_val, ymax = high_val,
    #                 fill = energy_cluster),
    #             alpha = 0.15, color = NA)+
  scale_fill_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        scale_color_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        xlab('Sample Length, days')+
        theme(legend.position = 'left')
      
## voc--------------------
met <- 'voc'
coeff <- 500


   a <- avg_pooled_scaled_entropy_df %>%
    filter( metric == met & method == meth,
                                  sample_length %in% c(1,3,5,7:21))

b <- scaled_entropy_df %>% filter(
                                  !is.na(get(independent)),
                                  !is.na(get(dependent)),
                                  sample_length %in% c(1,3,5,7:21))%>%
  filter(metric == met)
    
      ggplot()+
    geom_violin(data = b, aes(group = sample_length, x = sample_length,
                       y = get(dependent)/coeff), width = 1.75,
                color = 'darkgrey')+
    geom_boxplot(data = b, aes(group = sample_length, x = sample_length,
                       y = get(dependent)/coeff), width=0.35, outlier.shape = NA,
                 color = 'black',
                 lwd = 0.5)+
        scale_y_continuous(
          breaks = c(0, 0.5, 1),
                     minor_breaks = c(0.25, 0.75),
          limits = c(0,1),
          sec.axis = sec_axis(trans = ~.*coeff, name = dependent)
        )+
    # stat_summary(fun=median, geom="point", color="red")+
    facet_wrap(vars(home))+
              theme_bw()+
    ylab(rep_measure)+
        ggtitle(label = paste0('Representativeness and ', dependent,
                              ' of ', met, ', Varying Sample Length, Scaled by ', max_method))+
        geom_line(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster))+
      geom_point(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster,
                 size = n_samples_frac))+# make size of pooints proportional to n
              scale_size_area(max_size = 2)+
      # # add threshold lines
      # geom_hline(yintercept=thresh_vector, linetype="dashed",
      #            color = "black", size=0.5)+
      # # to color threshold lines based on value
      # lapply(c(1:3), function(i){
      #         geom_hline(yintercept=thresh_vector[i],
      #                    linetype="dashed", 
      #            color = threshold_colors[i], size=0.5)
      # })+
      scale_x_continuous(breaks=seq(0,21,7), limits = c(0,21))+
    #   # add error bars
    # geom_ribbon(aes(ymin = low_val, ymax = high_val,
    #                 fill = energy_cluster),
    #             alpha = 0.15, color = NA)+
  scale_fill_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        scale_color_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        xlab('Sample Length, days')+
        theme(legend.position = 'left')
      
###############
      dependent <- 'mean_diff'

## pm25--------------------
met <- 'pm25'
coeff <- 20

  a <- avg_pooled_scaled_entropy_df %>%
    filter( metric == met & method == meth,
                                  sample_length %in% c(1,3,5,7:21))

b <- scaled_entropy_df %>% filter(
                                  !is.na(get(independent)),
                                  !is.na(get(dependent)),
                                  sample_length %in% c(1,3,5,7:21))%>%
  filter(metric == met)
    
      ggplot()+
    geom_violin(data = b, aes(group = sample_length, x = sample_length,
                       y = get(dependent)/coeff), width = 1.75,
                color = 'darkgrey')+
    geom_boxplot(data = b, aes(group = sample_length, x = sample_length,
                       y = get(dependent)/coeff), width=0.35, outlier.shape = NA,
                 color = 'black',
                 lwd = 0.5)+
        scale_y_continuous(
          breaks = c(0, 0.5, 1),
                     minor_breaks = c(0.25, 0.75),
          limits = c(0,1),
          sec.axis = sec_axis(trans = ~.*coeff, name = dependent)
        )+
    # stat_summary(fun=median, geom="point", color="red")+
    facet_wrap(vars(home))+
              theme_bw()+
    ylab(rep_measure)+
        ggtitle(label = paste0('Representativeness and ', dependent,
                              ' of ', met, ', Varying Sample Length, Scaled by ', max_method))+
        geom_line(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster))+
      geom_point(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster,
                 size = n_samples_frac))+# make size of pooints proportional to n
              scale_size_area(max_size = 2)+
      # # add threshold lines
      # geom_hline(yintercept=thresh_vector, linetype="dashed",
      #            color = "black", size=0.5)+
      # # to color threshold lines based on value
      # lapply(c(1:3), function(i){
      #         geom_hline(yintercept=thresh_vector[i],
      #                    linetype="dashed", 
      #            color = threshold_colors[i], size=0.5)
      # })+
      scale_x_continuous(breaks=seq(0,21,7), limits = c(0,21))+
    #   # add error bars
    # geom_ribbon(aes(ymin = low_val, ymax = high_val,
    #                 fill = energy_cluster),
    #             alpha = 0.15, color = NA)+
  scale_fill_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        scale_color_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        xlab('Sample Length, days')+
        theme(legend.position = 'left')
      
## voc--------------------
met <- 'voc'
coeff <- 1000


   a <- avg_pooled_scaled_entropy_df %>%
    filter( metric == met & method == meth,
                                  sample_length %in% c(1,3,5,7:21))

b <- scaled_entropy_df %>% filter(
                                  !is.na(get(independent)),
                                  !is.na(get(dependent)),
                                  sample_length %in% c(1,3,5,7:21))%>%
  filter(metric == met)
    
      ggplot()+
    geom_violin(data = b, aes(group = sample_length, x = sample_length,
                       y = get(dependent)/coeff), width = 1.75,
                color = 'darkgrey')+
    geom_boxplot(data = b, aes(group = sample_length, x = sample_length,
                       y = get(dependent)/coeff), width=0.35, outlier.shape = NA,
                 color = 'black',
                 lwd = 0.5)+
        scale_y_continuous(
          breaks = c(0, 0.5, 1),
                     minor_breaks = c(0.25, 0.75),
          limits = c(0,1),
          sec.axis = sec_axis(trans = ~.*coeff, name = dependent)
        )+
    # stat_summary(fun=median, geom="point", color="red")+
    facet_wrap(vars(home))+
              theme_bw()+
    ylab(rep_measure)+
        ggtitle(label = paste0('Representativeness and ', dependent,
                              ' of ', met, ', Varying Sample Length, Scaled by ', max_method))+
        geom_line(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster))+
      geom_point(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster,
                 size = n_samples_frac))+# make size of pooints proportional to n
              scale_size_area(max_size = 2)+
      # # add threshold lines
      # geom_hline(yintercept=thresh_vector, linetype="dashed",
      #            color = "black", size=0.5)+
      # # to color threshold lines based on value
      # lapply(c(1:3), function(i){
      #         geom_hline(yintercept=thresh_vector[i],
      #                    linetype="dashed", 
      #            color = threshold_colors[i], size=0.5)
      # })+
      scale_x_continuous(breaks=seq(0,21,7), limits = c(0,21))+
    #   # add error bars
    # geom_ribbon(aes(ymin = low_val, ymax = high_val,
    #                 fill = energy_cluster),
    #             alpha = 0.15, color = NA)+
  scale_fill_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        scale_color_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        xlab('Sample Length, days')+
        theme(legend.position = 'left')
      
# time--------------------------- 
meth <- 'time'

## difference in peak hour times------------------
      
      dependent <- 'max_hour_diff'

### pm25--------------------
met <- 'pm25'
coeff <- 20

  a <- avg_pooled_scaled_entropy_df %>%
    filter( metric == met & method == meth,
                                  sample_length %in% c(1,3,5,7:21))

b <- scaled_entropy_df %>% filter(
                                  !is.na(get(independent)),
                                  !is.na(get(dependent)),
                                  sample_length %in% c(1,3,5,7:21))%>%
  filter(metric == met)
    
           ggplot()+
    geom_violin(data = b, aes(group = sample_length, x = sample_length,
                       y = get(dependent)/coeff), width = 1.75,
                color = 'darkgrey')+
    geom_boxplot(data = b, aes(group = sample_length, x = sample_length,
                       y = get(dependent)/coeff), width=0.35, outlier.shape = NA,
                 color = 'black',
                 lwd = 0.5)+
        scale_y_continuous(
          breaks = c(0, 0.5, 1),
                     minor_breaks = c(0.25, 0.75),
          limits = c(0,1),
          sec.axis = sec_axis(trans = ~.*coeff, name = dependent)
        )+
    # stat_summary(fun=median, geom="point", color="red")+
    facet_wrap(vars(home))+
              theme_bw()+
    ylab(rep_measure)+
        ggtitle(label = paste0('Representativeness and ', dependent,
                              ' of ', met, ', Varying Sample Length, Scaled by ', max_method))+
        geom_line(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster))+
      geom_point(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster,
                 size = n_samples_frac))+# make size of pooints proportional to n
              scale_size_area(max_size = 2)+
      # # add threshold lines
      # geom_hline(yintercept=thresh_vector, linetype="dashed",
      #            color = "black", size=0.5)+
      # # to color threshold lines based on value
      # lapply(c(1:3), function(i){
      #         geom_hline(yintercept=thresh_vector[i],
      #                    linetype="dashed", 
      #            color = threshold_colors[i], size=0.5)
      # })+
      scale_x_continuous(breaks=seq(0,21,7), limits = c(0,21))+
    #   # add error bars
    # geom_ribbon(aes(ymin = low_val, ymax = high_val,
    #                 fill = energy_cluster),
    #             alpha = 0.15, color = NA)+
  scale_fill_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        scale_color_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        xlab('Sample Length, days')+
        theme(legend.position = 'left')
      
### voc--------------------
met <- 'voc'
coeff <- 20


  a <- avg_pooled_scaled_entropy_df %>%
    filter( metric == met & method == meth,
                                  sample_length %in% c(1,3,5,7:21))

b <- scaled_entropy_df %>% filter(
                                  !is.na(get(independent)),
                                  !is.na(get(dependent)),
                                  sample_length %in% c(1,3,5,7:21))%>%
  filter(metric == met)
    
      ggplot()+
    geom_violin(data = b, aes(group = sample_length, x = sample_length,
                       y = get(dependent)/coeff), width = 1.75,
                color = 'darkgrey')+
    geom_boxplot(data = b, aes(group = sample_length, x = sample_length,
                       y = get(dependent)/coeff), width=0.35, outlier.shape = NA,
                 color = 'black',
                 lwd = 0.5)+
        scale_y_continuous(
          breaks = c(0, 0.5, 1),
                     minor_breaks = c(0.25, 0.75),
          limits = c(0,1),
          sec.axis = sec_axis(trans = ~.*coeff, name = dependent)
        )+
    # stat_summary(fun=median, geom="point", color="red")+
    facet_wrap(vars(home))+
              theme_bw()+
    ylab(rep_measure)+
        ggtitle(label = paste0('Representativeness and ', dependent,
                              ' of ', met, ', Varying Sample Length, Scaled by ', max_method))+
        geom_line(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster))+
      geom_point(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster,
                 size = n_samples_frac))+# make size of pooints proportional to n
              scale_size_area(max_size = 2)+
      # # add threshold lines
      # geom_hline(yintercept=thresh_vector, linetype="dashed",
      #            color = "black", size=0.5)+
      # # to color threshold lines based on value
      # lapply(c(1:3), function(i){
      #         geom_hline(yintercept=thresh_vector[i],
      #                    linetype="dashed", 
      #            color = threshold_colors[i], size=0.5)
      # })+
      scale_x_continuous(breaks=seq(0,21,7), limits = c(0,21))+
    #   # add error bars
    # geom_ribbon(aes(ymin = low_val, ymax = high_val,
    #                 fill = energy_cluster),
    #             alpha = 0.15, color = NA)+
  scale_fill_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        scale_color_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        xlab('Sample Length, days')+
        theme(legend.position = 'left')      
      
## difference in peak hour values------------------

      dependent <- 'max_diff'

## pm25--------------------
met <- 'pm25'
coeff <- 75

  a <- avg_pooled_scaled_entropy_df %>%
    filter( metric == met & method == meth,
                                  sample_length %in% c(1,3,5,7:21))

b <- scaled_entropy_df %>% filter(
                                  !is.na(get(independent)),
                                  !is.na(get(dependent)),
                                  sample_length %in% c(1,3,5,7:21))%>%
  filter(metric == met)
    
           ggplot()+
    geom_violin(data = b, aes(group = sample_length, x = sample_length,
                       y = get(dependent)/coeff), width = 1.75,
                color = 'darkgrey')+
    geom_boxplot(data = b, aes(group = sample_length, x = sample_length,
                       y = get(dependent)/coeff), width=0.35, outlier.shape = NA,
                 color = 'black',
                 lwd = 0.5)+
        scale_y_continuous(
          breaks = c(0, 0.5, 1),
                     minor_breaks = c(0.25, 0.75),
          limits = c(0,1),
          sec.axis = sec_axis(trans = ~.*coeff, name = dependent)
        )+
    # stat_summary(fun=median, geom="point", color="red")+
    facet_wrap(vars(home))+
              theme_bw()+
    ylab(rep_measure)+
        ggtitle(label = paste0('Representativeness and ', dependent,
                              ' of ', met, ', Varying Sample Length, Scaled by ', max_method))+
        geom_line(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster))+
      geom_point(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster,
                 size = n_samples_frac))+# make size of pooints proportional to n
              scale_size_area(max_size = 2)+
      # # add threshold lines
      # geom_hline(yintercept=thresh_vector, linetype="dashed",
      #            color = "black", size=0.5)+
      # # to color threshold lines based on value
      # lapply(c(1:3), function(i){
      #         geom_hline(yintercept=thresh_vector[i],
      #                    linetype="dashed", 
      #            color = threshold_colors[i], size=0.5)
      # })+
      scale_x_continuous(breaks=seq(0,21,7), limits = c(0,21))+
    #   # add error bars
    # geom_ribbon(aes(ymin = low_val, ymax = high_val,
    #                 fill = energy_cluster),
    #             alpha = 0.15, color = NA)+
  scale_fill_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        scale_color_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        xlab('Sample Length, days')+
        theme(legend.position = 'left')
      
## voc--------------------
met <- 'voc'
coeff <- 1250


  a <- avg_pooled_scaled_entropy_df %>%
    filter( metric == met & method == meth,
                                  sample_length %in% c(1,3,5,7:21))

b <- scaled_entropy_df %>% filter(
                                  !is.na(get(independent)),
                                  !is.na(get(dependent)),
                                  sample_length %in% c(1,3,5,7:21))%>%
  filter(metric == met)
    
      ggplot()+
    geom_violin(data = b, aes(group = sample_length, x = sample_length,
                       y = get(dependent)/coeff), width = 1.75,
                color = 'darkgrey')+
    geom_boxplot(data = b, aes(group = sample_length, x = sample_length,
                       y = get(dependent)/coeff), width=0.35, outlier.shape = NA,
                 color = 'black',
                 lwd = 0.5)+
        scale_y_continuous(
          breaks = c(0, 0.5, 1),
                     minor_breaks = c(0.25, 0.75),
          limits = c(0,1),
          sec.axis = sec_axis(trans = ~.*coeff, name = dependent)
        )+
    # stat_summary(fun=median, geom="point", color="red")+
    facet_wrap(vars(home))+
              theme_bw()+
    ylab(rep_measure)+
        ggtitle(label = paste0('Representativeness and ', dependent,
                              ' of ', met, ', Varying Sample Length, Scaled by ', max_method))+
        geom_line(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster))+
      geom_point(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster,
                 size = n_samples_frac))+# make size of pooints proportional to n
              scale_size_area(max_size = 2)+
      # # add threshold lines
      # geom_hline(yintercept=thresh_vector, linetype="dashed",
      #            color = "black", size=0.5)+
      # # to color threshold lines based on value
      # lapply(c(1:3), function(i){
      #         geom_hline(yintercept=thresh_vector[i],
      #                    linetype="dashed", 
      #            color = threshold_colors[i], size=0.5)
      # })+
      scale_x_continuous(breaks=seq(0,21,7), limits = c(0,21))+
    #   # add error bars
    # geom_ribbon(aes(ymin = low_val, ymax = high_val,
    #                 fill = energy_cluster),
    #             alpha = 0.15, color = NA)+
  scale_fill_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        scale_color_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        xlab('Sample Length, days')+
        theme(legend.position = 'left')      
```

### Boxplots, rooms not pooled, non-overlapping samples

```{r function_rep_deviation_boxplot}
# testing---------------------

# met <- 'pm25'
# meth <- 'shape'
# cluster <- 'all'
# coeff <- 'auto'
# room <- 'living'
# dependent <- 'median'
# omit_outliers <- FALSE
# 
# rm(
#   met, meth, cluster, coeff, room, dependent, omit_outliers)

# define function--------------------------

line.boxplot <- function(met, meth, cluster, room, independent, dependent, rep_measure, coeff = 'auto', omit_outliers = FALSE){
  
a <- avg_scaled_entropy_df %>%
    filter( metric == met & method == meth,
                                  sample_length %in% c(1,3,5,7:21),
         energy_cluster == cluster,
         location == room)

b <- scaled_entropy_df %>% filter(
                                  !is.na(get(independent)),
                                  !is.na(get(paste0(dependent,'_sample'))),
                                  !is.na(get(paste0(dependent,'_entire'))),
                                  sample_length %in% c(1,3,5,7:21))%>%
  filter(metric == met, method == meth,
         energy_cluster == cluster,
         location == room) %>%
  group_by(home, sample_length) %>%
  #mark extreme outliers
  mutate(ext_outlier = 
                     case_when(  get(paste0(dependent,'_sample'))> 
                    median(get(paste0(dependent,'_sample')))+
                    3*IQR(get(paste0(dependent,'_sample')))~ TRUE,
                    TRUE ~FALSE))

# count the fraction of extreme outliers for each group
ext_outlier_count <- b %>%
  group_by(home, sample_length) %>%
  summarize(ext_outlier_n = sum(ext_outlier == TRUE)/n(), .groups = 'drop')

b <- left_join(b, ext_outlier_count, by = c('home', 'sample_length'))

# omit extreme outliers from boxplot and violin if omit_outliers is TRUE
b <- if(omit_outliers == FALSE) b else filter(b, ext_outlier == FALSE)

coeff <- if(coeff == 'auto') {
  pull(b, sym(paste0(dependent,'_sample'))) %>% max()
  } else coeff
    
      ggplot()+
    geom_violin(data = b, aes(group = sample_length, x = sample_length,
                       y = get(paste0(dependent,'_sample'))/coeff), width = 1.75,
                color = 'darkgrey')+
    geom_boxplot(data = b, aes(group = sample_length, x = sample_length,
                       y = get(paste0(dependent,'_sample'))/coeff,
                       color = energy_cluster), width=0.35, outlier.shape = NA,
                 color = 'black',
                 lwd = 0.5)+
        scale_y_continuous(
          breaks = c(0, 0.5, 1),
                     minor_breaks = c(0.25, 0.75),
          limits = c(0,1),
          sec.axis = sec_axis(trans = ~.*coeff,
                              name = paste0(dependent,'_sample'))
        )+
    facet_wrap(vars(home))+
              theme_bw()+
    ylab(rep_measure)+
        ggtitle(label = paste0(ifelse(omit_outliers == TRUE,
                                     'EXT OUTLIERS OMITTED- ',
                                     ''),
                               'Representativeness and ', dependent,
                              ' of ', met, ' ', room, ', Varying Sample Length, Scaled by ', max_method))+
        geom_line(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster))+
      geom_point(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster,
                 size = n_samples))+# make size of pooints proportional to n
              scale_size_area(max_size = 2)+
      # # add threshold lines
      # geom_hline(yintercept=thresh_vector, linetype="dashed",
      #            color = "black", size=0.5)+
      # # to color threshold lines based on value
      # lapply(c(1:3), function(i){
      #         geom_hline(yintercept=thresh_vector[i],
      #                    linetype="dashed", 
      #            color = threshold_colors[i], size=0.5)
      # })+
      scale_x_continuous(breaks=seq(0,21,7), limits = c(0,21))+
    #   # add error bars
    # geom_ribbon(aes(ymin = low_val, ymax = high_val,
    #                 fill = energy_cluster),
    #             alpha = 0.15, color = NA)+
  scale_fill_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        scale_color_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        xlab('Sample Length, days')+
        theme(legend.position = 'left')+
        geom_hline(data = b, aes(yintercept = get(paste0(dependent,'_entire'))/coeff),
                   linetype = 'dashed')+
            stat_summary(data = b,aes(x = sample_length,
                 y = get(paste0(dependent,'_sample'))/coeff),
                 fun = median, geom="point", color="red", size = 1)
}
```

### Example Plot (One Home)

```{r fig.height=3, fig.width = 6}

if(max_method == 'universal'){
      independent <- 'scaled_kld_universal'
      rep_measure <- 'avg_kld_scaled_universal'
    } else if(max_method == 'metric'){
            independent <- 'scaled_kld_metric'
      rep_measure <- 'avg_kld_scaled_metric'
    } else if(max_method == 'home'){
            independent <- 'scaled_kld_home'
      rep_measure <- 'avg_kld_scaled_home'
            } else if(max_method == 'conditional'){
            independent <- 'scaled_kld_conditional'
      rep_measure <- 'avg_kld_scaled_conditional'
            }
# shape--------------------------- 
meth <- 'shape'


## pm25--------------------
met <- 'pm25'
coeff <- 5
hm <- '001'
cluster <- 'all'
room <- 'living'
dependent <- 'median'

  a <- avg_scaled_entropy_df %>%
    filter( metric == met & method == meth,
                                  sample_length %in% c(1,3,5,7:21),
            home == hm,
         energy_cluster == cluster,
         location == room)

b <- scaled_entropy_df %>% filter(
                                  !is.na(get(independent)),
                                  !is.na(get(dependent)),
                                  sample_length %in% c(1,3,5,7:21))%>%
  filter(metric == met,
            home == hm,
         energy_cluster == cluster,
         location == room)
    
      ggplot()+
    geom_violin(data = b, aes(group = sample_length, x = sample_length,
                       y = median_sample/coeff), width = 1.75,
                color = 'darkgrey')+
    geom_boxplot(data = b, aes(group = sample_length, x = sample_length,
                       y = median_sample/coeff,
                       color = energy_cluster), width=0.35, outlier.shape = NA,
                 color = 'black',
                 lwd = 0.5)+
        scale_y_continuous(
          breaks = c(0, 0.5, 1),
                     minor_breaks = c(0.25, 0.75),
          limits = c(0,1),
          sec.axis = sec_axis(trans = ~.*coeff, name = 'median_sample')
        )+
    facet_wrap(vars(home))+
              theme_bw()+
    ylab(rep_measure)+
        ggtitle(label = paste0('Representativeness and ', dependent,
                              ' of ', met, ' ', room, ', Varying Sample Length, Scaled by ', max_method))+
        geom_line(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster))+
      geom_point(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster,
                 size = n_samples))+# make size of pooints proportional to n
              scale_size_area(max_size = 2)+
      # # add threshold lines
      # geom_hline(yintercept=thresh_vector, linetype="dashed",
      #            color = "black", size=0.5)+
      # # to color threshold lines based on value
      # lapply(c(1:3), function(i){
      #         geom_hline(yintercept=thresh_vector[i],
      #                    linetype="dashed", 
      #            color = threshold_colors[i], size=0.5)
      # })+
      scale_x_continuous(breaks=seq(0,21,7), limits = c(0,21))+
    #   # add error bars
    # geom_ribbon(aes(ymin = low_val, ymax = high_val,
    #                 fill = energy_cluster),
    #             alpha = 0.15, color = NA)+
  scale_fill_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        scale_color_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        xlab('Sample Length, days')+
        theme(legend.position = 'left')+
        geom_hline(data = b, aes(yintercept = median_entire/coeff),
                   linetype = 'dashed')+
            stat_summary(data = b,aes(x = sample_length,
                 y = median_sample/coeff),
                 fun = median, geom="point", color="red", size = 1)

      

```

### All homes, (One Room)
```{r plot_rep_deviation_boxplot, fig.height=7, fig.width = 10.5, eval = TRUE}

# run for different variables--------------------------


if(max_method == 'universal'){
      independent <- 'scaled_kld_universal'
      rep_measure <- 'avg_kld_scaled_universal'
    } else if(max_method == 'metric'){
            independent <- 'scaled_kld_metric'
      rep_measure <- 'avg_kld_scaled_metric'
    } else if(max_method == 'home'){
            independent <- 'scaled_kld_home'
      rep_measure <- 'avg_kld_scaled_home'
            } else if(max_method == 'conditional'){
            independent <- 'scaled_kld_conditional'
      rep_measure <- 'avg_kld_scaled_conditional'
            }


## median---------------

# pm25
line.boxplot(
  meth = 'shape',
  met = 'pm25',
  # coeff = 30,
  cluster = season,
  room = 'living',
  dependent = 'median',
  independent = independent,
  rep_measure = rep_measure,
  omit_outliers = TRUE
  )

 # voc

line.boxplot(
  meth = 'shape',
  met = 'voc',
  # coeff = 500,
  cluster = season,
  room = 'living',
  dependent = 'median',
  independent = independent,
  rep_measure = rep_measure,
  omit_outliers = TRUE
  )
## iqr---------------

# pm25
line.boxplot(
  meth = 'shape',
  met = 'pm25',
  # coeff = 500,
  cluster = season,
  room = 'living',
  dependent = 'iqr',
  independent = independent,
  rep_measure = rep_measure,
  omit_outliers = TRUE
  )

# voc
line.boxplot(
  meth = 'shape',
  met = 'voc',
  # coeff = 2000,
  cluster = season,
  room = 'living',
  dependent = 'iqr',
  independent = independent,
  rep_measure = rep_measure,
  omit_outliers = TRUE
  )



## max---------------

# pm25
line.boxplot(
  meth = 'time',
  met = 'pm25',
  # coeff = 24,
  cluster = season,
  room = 'living',
  dependent = 'max',
  independent = independent,
  rep_measure = rep_measure,
  omit_outliers = TRUE
  )

# voc
line.boxplot(
  meth = 'time',
  met = 'voc',
  # coeff = 2000,
  cluster = season,
  room = 'living',
  dependent = 'max',
  independent = independent,
  rep_measure = rep_measure,
  omit_outliers = TRUE
  )




## max_hour---------------

# pm25
line.boxplot(
  meth = 'time',
  met = 'pm25',
  # coeff = 24,
  cluster = season,
  room = 'living',
  dependent = 'max_hour',
  independent = independent,
  rep_measure = rep_measure
  )

# voc
line.boxplot(
  meth = 'time',
  met = 'voc',
  # coeff = 2000,
  cluster = season,
  room = 'living',
  dependent = 'max_hour',
  independent = independent,
  rep_measure = rep_measure
  )



```


### fraction of samples within threshold
```{r function_plot_rep_deviation_fraction_samples}
# testing---------------------

# met <- 'pm25'
# meth <- 'shape'
# cluster <- 'all'
# room <- 'living'
# dependent <- 'median'
# threshold <- 10
# independent <- 'scaled_kld_conditional'
# rep_measure <- 'avg_kld_scaled_conditional'
# 
# rm(
#   met, meth, cluster, coeff, room, dependent, threshold)

# define function--------------------------

line.fracplot <- function(met, meth, cluster, room, independent, dependent,
                         rep_measure, threshold, long_term_period = 'year'
                         # coeff = 'auto'
                         ){
  
  difference <- if(dependent == 'max_hour') '_diff' else '_diff_pct'
  difference_unit <- if(dependent == 'max_hour') 'hour' else '%'

  a <- avg_scaled_entropy_df %>%
    filter( metric == met & method == meth,
                                  sample_length %in% c(1,3,5,7:21),
         energy_cluster == cluster,
         location == room,
         period_compare == long_term_period
         )

b <- scaled_entropy_df %>% filter(
                                  !is.na(get(independent)),
                                  !is.na(get(paste0(dependent, difference))),
                                  sample_length %in% c(1,3,5,7:21))%>%
  filter(metric == met, method == meth,
         energy_cluster == cluster,
         location == room,
         period_compare == long_term_period) %>%
  # count fraction of samples within threshold percentage
  # of long period value (within each home/sample length)
  mutate(within_threshold = ifelse(get(paste0(dependent, difference))<=threshold,
                             TRUE, FALSE))%>%
    group_by(home, sample_length)%>%
  summarise(frac_within = sum(within_threshold == TRUE)/n(), .groups = 'drop')

# #test
# ggplot(b %>% filter(home == '001'))+
#   geom_point(aes(x = sample_length, y = get(paste0(dependent, difference)),
#                  color = within_threshold))+
#   geom_hline(aes(yintercept = get(paste0(dependent,'_entire'))), linetype = 'dashed')

coeff <- 1

      ggplot()+
    geom_col(data = b, aes(x = sample_length,
                       y = frac_within/coeff),
                 fill = cbbPalette['light_blue'], width = 1)+
        scale_y_continuous(
          breaks = c(0, 0.5, 1),
                     minor_breaks = c(0.25, 0.75),
          limits = c(0,1),
          sec.axis = sec_axis(trans = ~.*coeff,
                              name = paste('Fraction within',dependent,'Threshold'))
        )+
    facet_wrap(vars(home))+
              theme_bw()+
    ylab(rep_measure)+
        ggtitle(label = paste(
                               'Representativeness and faction of samples within',
                               threshold, difference_unit, 'of overall', met, dependent,
                              'in', room, '- Scaled by', max_method))+
        geom_line(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster))+
      geom_point(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster,
                 size = n_samples))+# make size of pooints proportional to n
              scale_size_area(max_size = 2)+
      # # add threshold lines
      # geom_hline(yintercept=thresh_vector, linetype="dashed",
      #            color = "black", size=0.5)+
      # # to color threshold lines based on value
      # lapply(c(1:3), function(i){
      #         geom_hline(yintercept=thresh_vector[i],
      #                    linetype="dashed", 
      #            color = threshold_colors[i], size=0.5)
      # })+
      scale_x_continuous(breaks=seq(0,21,7), limits = c(0,21))+
  scale_fill_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        scale_color_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        xlab('Sample Length, days')+
        {if(long_term_period=='season') {
          annotate(geom = 'text', label = paste('long=', long_term_period),
                   x = Inf, y = Inf, hjust = 1, vjust = 1)}
          }+
        theme(legend.position = 'left')
        # geom_hline(data = b, aes(yintercept = get(paste0(dependent,'_entire'))/coeff),
        #            linetype = 'dashed')
}
```

```{r plot_rep_deviation_fraction_samples, fig.height=7, fig.width = 10.5, eval = FALSE}


# run for different variables--------------------------


if(max_method == 'universal'){
      independent <- 'scaled_kld_universal'
      rep_measure <- 'avg_kld_scaled_universal'
    } else if(max_method == 'metric'){
            independent <- 'scaled_kld_metric'
      rep_measure <- 'avg_kld_scaled_metric'
    } else if(max_method == 'home'){
            independent <- 'scaled_kld_home'
      rep_measure <- 'avg_kld_scaled_home'
            } else if(max_method == 'conditional'){
            independent <- 'scaled_kld_conditional'
      rep_measure <- 'avg_kld_scaled_conditional'
            }


## median---------------

# pm25
line.fracplot(
  meth = 'shape',
  met = 'pm25',
  # coeff = 30,
  cluster = season,
  room = 'living',
  dependent = 'median',
  independent = independent,
  rep_measure = rep_measure,
  threshold = 10,
  long_term_period = long_term_period)

# pm25
line.fracplot(
  meth = 'shape',
  met = 'pm25',
  # coeff = 30,
  cluster = season,
  room = 'living',
  dependent = 'median',
  independent = independent,
  rep_measure = rep_measure,
  threshold = 40,
  long_term_period = long_term_period)


 # voc

line.fracplot(
  meth = 'shape',
  met = 'voc',
  # coeff = 500,
  cluster = season,
  room = 'living',
  dependent = 'median',
  independent = independent,
  rep_measure = rep_measure,
  threshold = 10,
  long_term_period = long_term_period  )

line.fracplot(
  meth = 'shape',
  met = 'voc',
  # coeff = 500,
  cluster = season,
  room = 'living',
  dependent = 'median',
  independent = independent,
  rep_measure = rep_measure,
  threshold = 40,
  long_term_period = long_term_period  )
## max---------------

# pm25
line.fracplot(
  meth = 'time',
  met = 'pm25',
  # coeff = 24,
  cluster = season,
  room = 'living',
  dependent = 'max',
  independent = independent,
  rep_measure = rep_measure,
  threshold = 10,
  long_term_period = long_term_period
  )

# pm25
line.fracplot(
  meth = 'time',
  met = 'pm25',
  # coeff = 24,
  cluster = season,
  room = 'living',
  dependent = 'max',
  independent = independent,
  rep_measure = rep_measure,
  threshold = 40,
  long_term_period = long_term_period
  )


# voc
line.fracplot(
  meth = 'time',
  met = 'voc',
  # coeff = 2000,
  cluster = season,
  room = 'living',
  dependent = 'max',
  independent = independent,
  rep_measure = rep_measure,
  threshold = 10,
  long_term_period = long_term_period  )


# voc
line.fracplot(
  meth = 'time',
  met = 'voc',
  # coeff = 2000,
  cluster = season,
  room = 'living',
  dependent = 'max',
  independent = independent,
  rep_measure = rep_measure,
  threshold = 40,
  long_term_period = long_term_period  )


## max_hour---------------

# pm25
line.fracplot(
  meth = 'time',
  met = 'pm25',
  # coeff = 24,
  cluster = season,
  room = 'living',
  dependent = 'max_hour',
  independent = independent,
  rep_measure = rep_measure,
  threshold = 1,
  long_term_period = long_term_period
  )

# pm25
line.fracplot(
  meth = 'time',
  met = 'pm25',
  # coeff = 24,
  cluster = season,
  room = 'living',
  dependent = 'max_hour',
  independent = independent,
  rep_measure = rep_measure,
  threshold = 2,
  long_term_period = long_term_period
  )


# voc
line.fracplot(
  meth = 'time',
  met = 'voc',
  # coeff = 2000,
  cluster = season,
  room = 'living',
  dependent = 'max_hour',
  independent = independent,
  rep_measure = rep_measure,
  threshold = 1,
  long_term_period = long_term_period
  )

# voc
line.fracplot(
  meth = 'time',
  met = 'voc',
  # coeff = 2000,
  cluster = season,
  room = 'living',
  dependent = 'max_hour',
  independent = independent,
  rep_measure = rep_measure,
  threshold = 2,
  long_term_period = long_term_period
  )


```

## Combine Representativeness with COV

### rooms not pooled, non-overlapping samples

```{r function_plot_rep_cov}
# define function--------------------------

line.covplot <- function(met, meth, cluster, room, independent, dependent, rep_measure, coeff = 'auto'){
  
a <- avg_scaled_entropy_df %>%
    filter( metric == met & method == meth,
                                  sample_length %in% c(1,3,5,7:21),
         energy_cluster == cluster,
         location == room)

b <- scaled_entropy_df %>% filter(
                                  !is.na(get(independent)),
                                  !is.na(get(paste0(dependent,'_sample'))),
                                  !is.na(get(paste0(dependent,'_entire'))),
                                  sample_length %in% c(1,3,5,7:21))%>%
  filter(metric == met, method == meth,
         energy_cluster == cluster,
         location == room) %>%
  group_by(home, sample_length) %>%
  summarise(
  cov = sd(get(paste0(dependent,'_sample')))/
    mean(get(paste0(dependent,'_sample'))
               ),
  .groups = 'drop'
          )

coeff <- if(coeff == 'auto') {
  pull(b, cov) %>% max()
  } else coeff
    
      ggplot()+
    geom_col(data = b, aes(x = sample_length,
                       y = cov/coeff),
                 fill = cbbPalette['light_orange'], width = 1)+
        scale_y_continuous(
          breaks = c(0, 0.5, 1),
                     minor_breaks = c(0.25, 0.75),
          limits = c(0,1),
          sec.axis = sec_axis(trans = ~.*coeff,
                              name = paste0('COV of ', dependent,'_sample'))
        )+
    facet_wrap(vars(home))+
              theme_bw()+
    ylab(rep_measure)+
        ggtitle(label = paste0(
                               'Representativeness and ', dependent,
                              ' of ', met, ' ', room,
                              ', Varying Sample Length, Scaled by ',
                              max_method))+
        geom_line(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster))+
      geom_point(data = a, aes(x = sample_length,
                 y = get(rep_measure),
                       color = energy_cluster,
                 size = n_samples))+# make size of pooints proportional to n
              scale_size_area(max_size = 2)+
      # # add threshold lines
      # geom_hline(yintercept=thresh_vector, linetype="dashed",
      #            color = "black", size=0.5)+
      # # to color threshold lines based on value
      # lapply(c(1:3), function(i){
      #         geom_hline(yintercept=thresh_vector[i],
      #                    linetype="dashed", 
      #            color = threshold_colors[i], size=0.5)
      # })+
      scale_x_continuous(breaks=seq(0,21,7), limits = c(0,21))+
    #   # add error bars
    # geom_ribbon(aes(ymin = low_val, ymax = high_val,
    #                 fill = energy_cluster),
    #             alpha = 0.15, color = NA)+
  scale_fill_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        scale_color_manual(values = energy_colors,
                    breaks = energy_breaks,
                    labels = energy_labels,
                    name = 'Season')+
        xlab('Sample Length, days')+
        theme(legend.position = 'left')
}
```



### All homes, (One Room)
```{r plot_rep_cov, fig.height=7, fig.width = 10.5, eval = FALSE}


# run for different variables--------------------------


if(max_method == 'universal'){
      independent <- 'scaled_kld_universal'
      rep_measure <- 'avg_kld_scaled_universal'
    } else if(max_method == 'metric'){
            independent <- 'scaled_kld_metric'
      rep_measure <- 'avg_kld_scaled_metric'
    } else if(max_method == 'home'){
            independent <- 'scaled_kld_home'
      rep_measure <- 'avg_kld_scaled_home'
            } else if(max_method == 'conditional'){
            independent <- 'scaled_kld_conditional'
      rep_measure <- 'avg_kld_scaled_conditional'
            }


## median---------------

# pm25
line.covplot(
  meth = 'shape',
  met = 'pm25',
  # coeff = 30,
  cluster = season,
  room = 'living',
  dependent = 'median',
  independent = independent,
  rep_measure = rep_measure)

 # voc

line.covplot(
  meth = 'shape',
  met = 'voc',
  # coeff = 500,
  cluster = season,
  room = 'living',
  dependent = 'median',
  independent = independent,
  rep_measure = rep_measure  )
## variance---------------

# pm25
line.covplot(
  meth = 'shape',
  met = 'pm25',
  # coeff = 500,
  cluster = season,
  room = 'living',
  dependent = 'iqr',
  independent = independent,
  rep_measure = rep_measure  )

# voc
line.covplot(
  meth = 'shape',
  met = 'voc',
  # coeff = 2000,
  cluster = season,
  room = 'living',
  dependent = 'iqr',
  independent = independent,
  rep_measure = rep_measure  )

## max---------------

# pm25
line.covplot(
  meth = 'time',
  met = 'pm25',
  # coeff = 24,
  cluster = season,
  room = 'living',
  dependent = 'max',
  independent = independent,
  rep_measure = rep_measure
  )

# voc
line.covplot(
  meth = 'time',
  met = 'voc',
  # coeff = 2000,
  cluster = season,
  room = 'living',
  dependent = 'max',
  independent = independent,
  rep_measure = rep_measure  )




## max_hour---------------

# pm25
line.covplot(
  meth = 'time',
  met = 'pm25',
  # coeff = 24,
  cluster = season,
  room = 'living',
  dependent = 'max_hour',
  independent = independent,
  rep_measure = rep_measure
  )

# voc
line.covplot(
  meth = 'time',
  met = 'voc',
  # coeff = 2000,
  cluster = season,
  room = 'living',
  dependent = 'max_hour',
  independent = independent,
  rep_measure = rep_measure
  )




```

## COrrelation without Seasons (no overlap)

```{r correlation_metric, eval = TRUE}


variables_dependent <- c(
  'median', 'iqr',
  'max_hour', 'max'
                           )





# for all conditions
cor_table <- 

  map(variables_dependent, function(dependent){
      
            map(c(
              # 'kld',
              'scaled_kld_metric'
              ),
              function(independent){
        map(metrics_all, function(x_metric){
          
          # make a row for the case of an error
          result_error <- 
            list('coeff' = NA, 'p_val' = NA,
                 'independent' = independent, 'dependent' = dependent,
                 'home' = NA, 'location' = NA,
                 'metric' = x_metric, 'energy_cluster' = NA,
                 'kld_max_method' = 'metric')
          
          a <- scaled_entropy_df %>% filter(
                                  !is.na(get(independent)),
                                  !is.na(get(paste0(dependent,'_sample'))),
                                  !is.na(get(paste0(dependent,'_entire'))),
                                  sample_length %in% c(1,3,5,7:21))%>%
  filter(metric == x_metric,
         energy_cluster == season) %>%
            group_by(home, sample_length, location) %>%
  summarise(
  cov = sd(get(paste0(dependent,'_sample')))/
    mean(get(paste0(dependent,'_sample'),
             )),
  avg_scaled_kld = mean(get(independent)),
  .groups = 'drop'
          )
          
          if (nrow(a)>3) {
            test <- cor.test(a %>% pull(avg_scaled_kld), a %>% pull(cov), method = 'spearman')%>%
              suppressWarnings()
            
            # return
            list('coeff' = test$estimate, 'p_val' = test$p.value,
                 'independent' = independent, 'dependent' = dependent,
                 'home' = NA, 'location' = NA,
                 'metric' = x_metric, 
                 'kld_max_method' = 'metric')
          }
          else result_error
          
        }) %>% bind_rows()
            }) %>% bind_rows()
      
    }) %>% bind_rows()

cor_table


write_csv(cor_table, './csv_created/cor_table.csv')


```

---
title: "Representativeness"
output:
  html_document:
    toc: true
    toc_float: true
    theme: paper
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.path = 'figures/',
  warning = FALSE,
  message = FALSE,
  echo = FALSE,
  fig.width = 10, fig.height = 3,
  cache = FALSE)
```

```{r libraries, include=FALSE}
library(dplyr)
library(purrr)
library(tidyr)
library(openair)
library(ggplot2)
library(readr)
library(googlesheets4)
library(lubridate)
library(gridExtra)
library(runner) # for moving window functions
library(ggpubr) # for tesing log-normality
# library(cubature) # for alternative method of integrating kld function
# library(entropy) # for KLD function
# library(fitdistrplus) # for fitting distribution to data NOTE, MASS::select CONFLICTS WITH dplyr::select

```

```{r import_omni_minute_data}
# omni_data<- read_csv('./csv_created/omni_all_locations.csv')

# # remove all variables but omni_data
# rm(list=setdiff(ls(), "omni_data"))

# zero_test <- omni_data %>%
#   group_by(home, location) %>%
#   summarize(pm25_zeros = sum(pm25 == 0), pm25_n = n()) %>%
#   mutate(pm25_zero_pct = pm25_zeros/pm25_n*100) %>%
#   ungroup()

```


```{r import_energy_cluster_homes}
# import energy cluster dataframe for all homes
energy_cluster_df <- read_csv('./csv_created/from_sense/energy_cluster_df.csv')
```

```{r import_pdf_data}

# read in csv files
entropy_df <- bind_rows(
  read_csv(file = './csv_created/representativeness_data/rep_data_shape_pdf.csv'),
  read_csv(file = './csv_created/representativeness_data/rep_data_time_pdf.csv'))


```

```{r import_max_kld_values}
# read in data

kld_max_df <- bind_rows(
  read_csv('./csv_created/representativeness_data/kld_max_shape.csv'), 
  read_csv('./csv_created/representativeness_data/kld_max_time.csv'))

```


```{r functions_misc}

#Function to only display 3 significant figures (for tables)
signif3 <- function(x){
  signif(x, digits = 3)
}

##Define a char vector of home numbers using a number vector,
##ex: x <- home.list(c(1:15)) for homes 1-15
threedig <- function(x) {
  if (nchar(x) == 1) {a <- paste0('00', x)
  return(a)
  }
  
  if (nchar(x) == 2) {a<- paste0('0', x)
  return(a)
  }
  else return(a)
}

home.list <- function(x) sapply(x, threedig)


```



```{r define_variables}
# fraction of sample needed to use sample of certain length
frac_samp_required <- 0.5

# list of all home numbers
homes_all <- home.list(1:17)

clusters_all <- c('heat','shoulder', 'ac')
locations_indoor <- c('living', 'kitchen', 'bedroom')

# sequence of representative thresholds to test
thresh_vector <- c(0.8, 0.90, 0.95)

# sequence of days to test thresholds for shape entropy values

pdf_days_pm <- c(3,7,19,27)

pdf_days_voc <- c(6,10,18,26)




```

```{r cleaning_omissions}
# count omissions --------------

# time
pm_time_no_cluster <- kld_max_df%>% 
  filter(method == 'time', metric == 'pm25',
         grepl('likely_no_cluster', error)) %>%
  group_by(home, location, energy_cluster) %>%
  summarize(n = n(), .groups = 'drop')


# clean dataframes ------------------------

# max kld
# remove na kld values from runs
kld_max_df_clean <- kld_max_df%>% 
  filter(period_compare == 'year', # only comparing sample to whole mon. period
         !is.na(kld), # with insufficient data in cluster/year/no cluster
  n_samp_avail >= frac_samp_required)# with less than certain percentage of available samples
  

test <- kld_max_df_clean %>%
  group_by(home, location, energy_cluster) %>%
  summarise(n = n(), .groups = 'drop')

# kld values
# remove na kld values from runs with insufficient data
entropy_df_clean <- entropy_df%>% 
  filter(period_compare == 'year', # only comparing sample to whole mon. period
    !is.na(kld), # with insufficient data in cluster/year/no cluster
  n_samp_avail >= frac_samp_required)# with less than certain percentage of available samples

test <- kld_max_df_clean %>%
  group_by(home, location, energy_cluster) %>%
  summarise(n = n(), .groups = 'drop')

```


```{r kld_max_determine}

# make box plots of values in each group
ggplot(kld_max_df_clean, aes(y = kld,
                       group = interaction(home, location, energy_cluster)))+
  geom_boxplot()+
  facet_wrap(vars(method))


kld_max_shape <-  kld_max_df_clean %>%
  filter(method== 'shape', n_samp_avail >= 0.5) %>%
  group_by(home, location, energy_cluster, metric) %>%
    summarise(cutoff = median(kld), .groups = 'drop') %>%
  # summarise(cutoff = median(kld)+1.5*IQR(kld), .groups = 'drop') %>%
  pull(cutoff) %>%max()


kld_max_time <-  kld_max_df_clean %>%
  filter(method== 'time', n_samp_avail >= 0.5) %>%
  group_by(home, location, energy_cluster, metric) %>%
    summarise(cutoff = median(kld), .groups = 'drop') %>%
  # summarise(cutoff = median(kld)+1.5*IQR(kld), .groups = 'drop') %>%
  pull(cutoff) %>%max()

```

```{r create_scaled_entropy_df}
scaled_entropy_df <- entropy_df_clean %>%
  mutate(scaled_kld = case_when(
    method == 'time' ~ 1- kld/kld_max_time,
        method == 'shape' ~ 1 - kld/kld_max_shape,
    TRUE ~ NA_real_
  ))


unwanted_scaled_na <- scaled_entropy_df %>%
  filter(scaled_kld %>% is.na())
```

### `r unwanted_scaled_na` unexpected missing values in scaled entropy data

## Testing Different Entropy Thresholds


### Effect on when individual sample Scaled Entropy crosses below threshold

```{r pdf_plots}


# # count the fraction of 3-day samples that have a scaled entropy > 1
# (entropy_all_pdf_shape %>%
#   filter(sample_length == 3, kld >1) %>%
#   nrow())/
#   (entropy_all_pdf_shape %>%
#   filter(sample_length == 3) %>%
#   nrow())

# time -------------------

meth <- 'time'
## pm25 


{
  met <- 'pm25'

a <- scaled_entropy_df %>% filter(metric == met, method == meth,
                                       sample_length %in% pdf_days_pm)

lvls <- levels(as.factor(a$sample_length))
values <- by(a, a$sample_length, function(x) sum(!is.na(x$scaled_kld)))
below0 <- by(a, a$sample_length, function(x) sum(x$scaled_kld <0))
labels <- paste(lvls,", n=",as.integer(values),", ", below0, " values < 0",sep="")

ggplot(a, aes(x = scaled_kld, fill = as.factor(sample_length)))+
    geom_density(alpha = 0.5)+
  xlab("Scaled Entropy")+
    ggtitle(label = paste('Time-Structured Scaled Entropy of', met))+
  coord_cartesian(xlim = c(0,1))+ # limit scaled entropy from 0 to 1
  labs(fill = 'Length of Sample, days')+
  geom_vline(xintercept = thresh_vector, linetype = 'dashed', color = 'red')+
  annotate('text', x=thresh_vector[1]-0.02, y = -0.1,
                label=thresh_vector[1],
            angle=90, size=3, color = 'red') +
   annotate('text', x=thresh_vector[2]-0.02, y = -0.1,
                label=thresh_vector[2],
            angle=90, size=3, color = 'red') +
    annotate('text', x=thresh_vector[3]-0.02, y = -0.1,
                label=thresh_vector[3],
            angle=90, size=3, color = 'red')+
     scale_fill_discrete( labels=labels)
}

##  voc


{
  met <- 'voc'

a <- scaled_entropy_df %>% filter(metric == met, method == meth,
                                       sample_length %in% pdf_days_pm)
lvls <- levels(as.factor(a$sample_length))
values <- by(a, a$sample_length, function(x) sum(!is.na(x$scaled_kld)))
below0 <- by(a, a$sample_length, function(x) sum(x$scaled_kld <0))
labels <- paste(lvls,", n=",as.integer(values),", ", below0, " values < 0",sep="")

ggplot(a, aes(x = scaled_kld, fill = as.factor(sample_length)))+
    geom_density(alpha = 0.5)+
  xlab("Scaled Entropy")+
    ggtitle(label = paste('Time-Structured Scaled Entropy of', met))+
  coord_cartesian(xlim = c(0,1))+ # limit scaled entropy from 0 to 1
  labs(fill = 'Length of Sample, days')+
  geom_vline(xintercept = thresh_vector, linetype = 'dashed', color = 'red')+
  annotate('text', x=thresh_vector[1]-0.02, y = -0.1,
                label=thresh_vector[1],
            angle=90, size=3, color = 'red') +
   annotate('text', x=thresh_vector[2]-0.02, y = -0.1,
                label=thresh_vector[2],
            angle=90, size=3, color = 'red') +
    annotate('text', x=thresh_vector[3]-0.02, y = -0.1,
                label=thresh_vector[3],
            angle=90, size=3, color = 'red')+
     scale_fill_discrete( labels=labels)

}

# shape -------------------

meth <- 'shape'

## pm25 
{
  met <- 'pm25'

a <- scaled_entropy_df %>% filter(metric == met, method == meth,
                                       sample_length %in% pdf_days_pm)
lvls <- levels(as.factor(a$sample_length))
values <- by(a, a$sample_length, function(x) sum(!is.na(x$scaled_kld)))
below0 <- by(a, a$sample_length, function(x) sum(x$scaled_kld <0))
labels <- paste(lvls,", n=",as.integer(values),", ", below0, " values < 0",sep="")

ggplot(a, aes(x = scaled_kld, fill = as.factor(sample_length)))+
    geom_density(alpha = 0.5)+
  xlab("Scaled Entropy")+
    ggtitle(label = paste('Magnitude-Based Scaled Entropy of', met))+
  coord_cartesian(xlim = c(0,1))+ # limit scaled entropy from 0 to 1
  labs(fill = 'Length of Sample, days')+
  geom_vline(xintercept = thresh_vector, linetype = 'dashed', color = 'red')+
  annotate('text', x=thresh_vector[1]-0.02, y = -0.1,
                label=thresh_vector[1],
            angle=90, size=3, color = 'red') +
   annotate('text', x=thresh_vector[2]-0.02, y = -0.1,
                label=thresh_vector[2],
            angle=90, size=3, color = 'red') +
    annotate('text', x=thresh_vector[3]-0.02, y = -0.1,
                label=thresh_vector[3],
            angle=90, size=3, color = 'red')+
     scale_fill_discrete( labels=labels)
}

##  voc


{
  met <- 'voc'

a <- scaled_entropy_df %>% filter(metric == met, method == meth,
                                       sample_length %in% pdf_days_pm)

lvls <- levels(as.factor(a$sample_length))
values <- by(a, a$sample_length, function(x) sum(!is.na(x$scaled_kld)))
below0 <- by(a, a$sample_length, function(x) sum(x$scaled_kld <0))
labels <- paste(lvls,", n=",as.integer(values),", ", below0, " values < 0",sep="")

ggplot(a, aes(x = scaled_kld, fill = as.factor(sample_length)))+
    geom_density(alpha = 0.5)+
  xlab("Scaled Entropy")+
    ggtitle(label = paste('Magnitude-Based Scaled Entropy of', met))+
  coord_cartesian(xlim = c(0,1))+ # limit scaled entropy from 0 to 1
  labs(fill = 'Length of Sample, days')+
  geom_vline(xintercept = thresh_vector, linetype = 'dashed', color = 'red')+
  annotate('text', x=thresh_vector[1]-0.02, y = -0.1,
                label=thresh_vector[1],
            angle=90, size=3, color = 'red') +
   annotate('text', x=thresh_vector[2]-0.02, y = -0.1,
                label=thresh_vector[2],
            angle=90, size=3, color = 'red') +
    annotate('text', x=thresh_vector[3]-0.02, y = -0.1,
                label=thresh_vector[3],
            angle=90, size=3, color = 'red')+
     scale_fill_discrete( labels=labels)

}




```

```{r create_pooled_avg_scaled_kld_df}
pooled_scaled_entropy_df <- scaled_entropy_df %>%
  group_by(metric, home, energy_cluster, sample_length, method) %>%
  summarise(avg_scaled_kld = mean(scaled_kld),
            high_val = avg_scaled_kld+ sd(scaled_kld),
                      low_val = avg_scaled_kld- sd(scaled_kld),
            .groups = 'drop')
  
```



```{r function_avg_entropy_plotter}

entropy.plot <- function (
  hm,
  # omit a sampling period of given length
  # if this proportion of possible samples
  # were not availabel in data
  metrics = c('pm25', 'voc'),
  data = scaled_entropy_df
) {
  
  # for one home:
  a <- data %>%
    filter(home == hm & metric %in% metrics)

  if(nrow(a) == 0) {
    plot <- NULL # return NULL if no data for home/metric/cluster combo
  }else {
    
    # plot results
    plot <- ggplot(aes(x = sample_length, y = avg_scaled_kld,
                       color = energy_cluster), data = a)+
      geom_line()+
      geom_point(size = 1)+
      xlab('Sample Length, days')+
      ylab('Scaled Relative Entropy')+
      geom_hline(yintercept=thresh_vector, linetype="dashed", 
                 color = "black", size=0.5)+
      coord_cartesian(ylim = c(0,1))+
      ggtitle(paste('Home',hm)) +
      facet_wrap(vars(metric)) +
      scale_x_continuous(breaks=seq(0,28,7))+
    geom_ribbon(aes(ymin = low_val, ymax = high_val, fill = energy_cluster),
                alpha = 0.15, color = NA)
  }
  plot
}

#function to put plots in a grid
grid.plots <- function(plots, title,
                     y_val, ncol = 4, nrow = 4) {
  ##omit NULL values (from homes or rooms without valid data)
  plots <- plots[!sapply(plots, is.null)]
  
  do.call('grid.arrange', c(plots, top = title, left = y_val,
                            ncol = ncol, nrow = nrow))
  
}

```

```{r plot_single_sensor_avg_entropy}

# plot results for one home

a <- pooled_scaled_entropy_df %>% filter(home == '009')


ggplot(aes(x = sample_length, y = avg_scaled_kld, color = energy_cluster),
       data = a)+
  geom_line()+
  geom_point(size = 1)+
  xlab('Sample Length, days')+
  ylab('Scaled Relative Entropy')+
  geom_hline(yintercept=thresh_vector, linetype="dashed",
                color = "black", size=0.5)+
  coord_cartesian(ylim = c(0,1)) +
      geom_ribbon(aes(ymin = low_val, ymax = high_val, fill = energy_cluster),
                alpha = 0.15, color = NA)+
  facet_wrap(vars(metric))

```

```{r grid_plot_avg_entropy, fig.height=8, fig. width = 10.5}
# time ----------------
meth <- 'time'

## pm25
{met <- 'pm25'
a <- pooled_scaled_entropy_df %>% filter(metric == met, method == meth)
# make plots for all homes
map(homes_all, function (x_home) {
    entropy.plot(hm = x_home, data = a)
}) %>%
  grid.plots(title = 'Time-Structured Scaled Relative Entropy', y_val = NULL)
}
```

### Testing Different Entropy Thresholds

### Effect on when average Scaled Entropy crosses below threshold

```{r threshold_plots_shape}

# make dataframe of values for minimum sample length (in days)
# where entropy is less than threshold value
threshold.freq.table <- function (threshold) {
  
  
  a <- entropy_shape_df %>%
  filter(n_samp_avail >0.5 & method == 'shape') %>%
  filter(coeff <= threshold) %>% 
  group_by(home, metric, location, energy_cluster) %>%
  summarise_at(vars(sample_length), min) %>%
  ungroup() %>%
    mutate('thresh' = threshold)
}

# apply function to all thresholds in threshold_seq
 a <- lapply(rep_threshold_seq, threshold.freq.table)
 a <- bind_rows(a)

 # ensure there weren't a significant amount of omissions for any metric type
 # (because the threshod may never have been reached)
 
 # test <- a %>%
 #   group_by(metric) %>%
 #   summarise(n = sum(freq)) %>%
 #   ungroup()
 
   lvls <- levels(as.factor(a$thresh))
rows <- by(a, a$thresh, function(x) nrow(x))
labels <- paste(lvls,", n=",as.integer(rows),sep="")

 # histogram of when threshold was reached for all home/month combos
ggplot(aes(x = sample_length, fill = as.factor(thresh)), data = a)+
  geom_density(alpha = 0.5)+
  facet_wrap(vars(metric))+
  xlab("Sample Length Required to Meet Representativeness Threshold, days")+
  scale_x_continuous(breaks = c(7,14,21,28))+
  scale_fill_discrete(labels = labels)+
  annotate('text', x = 14, y = 0.15, label = '*max n = 48 (homes*rooms)')



```






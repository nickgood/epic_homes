---
title: "Representativeness"
output:
  html_document:
    toc: true
    toc_float: true
    theme: paper
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(fig.path = 'figures/',
  warning = FALSE,
  message = FALSE,
  echo = FALSE,
  fig.width = 10, fig.height = 3,
  cache = FALSE)
```

```{r libraries, include=FALSE}
library(dplyr)
library(purrr)
library(tidyr)
library(openair)
library(ggplot2)
library(readr)
library(googlesheets4)
library(lubridate)
library(gridExtra)
library(ggpubr) # for tesing log-normality
# library(cubature) # for alternative method of integrating kld function
# library(entropy) # for KLD function
# library(fitdistrplus) # for fitting distribution to data NOTE, MASS::select CONFLICTS WITH dplyr::select

```



```{r import_energy_cluster_homes}
# import energy cluster dataframe for all homes
energy_cluster_df <- read_csv('../sense/csv_created_sense/energy_cluster_df.csv')
```



```{r import_assessment_data}

assessment_data <- read_csv('../data_thesis/homes/home_assessment_data.csv')

# # using googlesheets4
# assessment_data <- read_sheet('https://docs.google.com/spreadsheets/d/12vWpqdmzIII0vEKH79xpmICUYGuzc8PjfBT2_3YjIHU/edit?usp=sharing', sheet = 'data')
```


```{r functions_misc}

#Function to only display 3 significant figures (for tables)
signif3 <- function(x){
  signif(x, digits = 3)
}

##Define a char vector of home numbers using a number vector,
##ex: x <- home.list(c(1:15)) for homes 1-15
threedig <- function(x) {
  if (nchar(x) == 1) {a <- paste0('00', x)
  return(a)
  }
  
  if (nchar(x) == 2) {a<- paste0('0', x)
  return(a)
  }
  else return(a)
}

home.list <- function(x) sapply(x, threedig)

# make function to label metric names with subscripts
labeller.metrics <- as_labeller(c('pm25'='PM[2.5]', 'voc'="TVOC"),
                           default = label_parsed)

# make function to label metric names with subscripts and seasons
labeller.metrics.seasons <- as_labeller(c(
  'pm25'='PM[2.5]', 'voc'="TVOC",
  'ac' = 'AC', 'shoulder' = 'Shoulder', 'heat' = 'Heat'
  ), default = label_parsed)

```



```{r define_variables}
# fraction of sample needed to use sample of certain length
frac_samp_required <- 0

# method of scaling relative entropy to scaled entropy
# 'universal' or 'conditional'
long_term_period <- 'year'
overlap <- FALSE
month_cluster <- FALSE
omit_outliers <- 'extreme'
pooled_rooms <- FALSE
clusters_all <- c('heat','shoulder', 'ac')

# list of all home numbers
homes_all <- home.list(1:16)
homes_tier3 <- home.list(c(1,2,7,9,12))
homes_tier2 <- home.list(c(4,10,11,13,15))
homes_no5 <- home.list(c(1:4,6:16))


locations_indoor <- c('living', 'kitchen', 'bedroom')
metrics_all <- c('pm25', 'voc')
# sequence of representative thresholds to test
thresh_vector <- c(0.75, 0.9)

# sequence of days to test thresholds for entropy values
sample_days <- c(1,3,5,7,14)


# color blind pallette
# check http://www.cookbook-r.com/Graphs/Colors_(ggplot2)/#a-colorblind-friendly-palette
cbbPalette <- c('black' = "#000000",
                'light_orange' = "#E69F00",
                'light_blue' = "#56B4E9",
                'green' = "#009E73",
                'yellow' = "#F0E442",
                'dark_blue' = "#0072B2",
                'dark_orange' = "#D55E00",
                'purple' = "#CC79A7"
                )
# define colors for energy clusters
energy_colors <- c(cbbPalette['light_blue'],
                   cbbPalette['green'],
                   cbbPalette['dark_orange'],
                   cbbPalette['black'])%>% unname()

energy_breaks <- c('ac', 'shoulder', 'heat', 'all')
energy_labels <- c('AC', 'Shoulder', 'Heat', 'Entire Period')

# define colors for sampling length
length_colors <- c(cbbPalette['black'],
                   cbbPalette['purple'],
                   cbbPalette['light_blue'],
                   cbbPalette['yellow'])%>% unname()

# define colors for thresholds
threshold_colors <- c(cbbPalette['dark_blue'],
                   cbbPalette['green'],
                   cbbPalette['dark_orange'])%>% unname()

# attempt 2
threshold_colors <- c(cbbPalette['dark_blue'],
                   cbbPalette['purple'],
                   cbbPalette['light_orange'])%>% unname()

# for labeling purposes
xsmall <- 2
smaller <- 4
small <- 6
medium <- 16
large <- 24

```

```{r import_pdf_data}

# read in csv files
entropy_df <- 
  
  if(long_term_period == 'year' & overlap == FALSE & month_cluster == FALSE
           & pooled_rooms == TRUE ){
    
    bind_rows(
      # read_rds(file = './csv_created/representativeness_data/rep_data_shape_hourly_pdf_pooled_no_overlap.rds')
      data.frame(median_sample=NA, median_entire=NA,
                 mean_sample = NA, mean_entire = NA,
                 iqr_sample = NA, iqr_entire = NA,
                 variance_sample=NA, variance_entire = NA),

    )%>%
      filter(period_compare == long_term_period)
    
    
  } else if(long_term_period == 'year' & overlap == FALSE & month_cluster == FALSE
           & pooled_rooms == FALSE ){
    
    bind_rows(
      # read_rds(file = './csv_created/representativeness_data/rep_data_shape_hourly_pdf_no_overlap.rds')
      data.frame(median_sample=NA, median_entire=NA,
                 mean_sample = NA, mean_entire = NA,
                 iqr_sample = NA, iqr_entire = NA,
                 variance_sample=NA, variance_entire = NA),
      read_rds(file = './csv_created/representativeness_data/rep_data_time_hourly_pdf_no_overlap.rds')
    )%>%
      filter(period_compare == long_term_period)
    
  }
  
  
  # if(long_term_period == 'year' & overlap == TRUE & month_cluster == FALSE) {
  #   
  #   # bind_rows(
  #   #   read_csv(file = './csv_created/representativeness_data/rep_data_shape_hourly_pdf.csv'),
  #   #   read_csv(file = './csv_created/representativeness_data/rep_data_time_hourly_pdf.csv'))
  #   
  # }else if(long_term_period == 'season'& overlap == TRUE & month_cluster == FALSE){
  #   
  #   # bind_rows(
  #   #   read_csv(file = './csv_created/representativeness_data/rep_data_shape_hourly_pdf_season.csv'),
  #   #   read_csv(file = './csv_created/representativeness_data/rep_data_time_hourly_pdf_season.csv'))
  #   
  # } else if(long_term_period == 'season'& overlap == FALSE & month_cluster == FALSE){
  #   
  #   bind_rows(
  #     read_csv(file = './csv_created/representativeness_data/rep_data_shape_hourly_pdf_season_no_overlap.csv'),
  #     read_csv(file = './csv_created/representativeness_data/rep_data_time_hourly_pdf_season_no_overlap.csv'))
  #   
  # }else if(long_term_period == 'season'& overlap == TRUE & month_cluster == TRUE){
  #   
  #   # bind_rows(
  #   #   read_csv(file = './csv_created/representativeness_data/rep_data_shape_hourly_pdf_season_month.csv'),
  #   #   read_csv(file = './csv_created/representativeness_data/rep_data_time_hourly_pdf_season_month.csv'))
  # }


```

```{r cleaning_omissions}
# count omissions --------------

n_homes_enrolled <- 17 # n of homes enrolled
n_indoor_sensors <- 16*3+2 # Home 002 never had kitchen installed
n_all_data_omitted <- 3 # Home 005 had less than 2 weeks of data
n_homes_data <-16 # n of homes with data used at least partially
n_indoor_sensors_data <- 15*3+2 # n of indoor sensors with data used at least partially
n_sensors_ac <- 5*3+2 # n of sensors in homes with ac detected
n_sensors_ac_ignore <- 3 # Home 011 ac usage ignored because only detected 5 days 

# no cluster

# clustered <- entropy_df%>%
#   filter(home != '005') %>% # omit home 5 from count
#   filter(!(home == '002' & location == 'kitchen')) %>% # omit home 002 kitchen from count
#     filter(!(grepl('likely_no_cluster', error))) %>%
#   filter(grepl('missing', error)) %>%
#   group_by(method, metric, energy_cluster) %>%
#   summarize(n = n(), .groups = 'drop')
# 
# 
# pm_time_no_cluster <- entropy_df%>%
#   filter(method == 'time', metric == 'pm25',
#          grepl('likely_no_cluster', error)) %>%
#   group_by(home, location, energy_cluster) %>%
#   summarize(n = n(), .groups = 'drop')


# clean dataframes ------------------------


# test <- kld_max_df_clean %>%
#   group_by(home, location, energy_cluster) %>%
#   summarise(n = n(), .groups = 'drop')

# kld values
# remove na kld values from runs with insufficient data
entropy_df_clean <- entropy_df%>% 
  filter(
    energy_cluster %in% clusters_all,
    !is.na(kld), # with insufficient data in cluster/year/no cluster
  n_samp_avail >= frac_samp_required) %>% # with less than certain percentage of available samples
# omit home 011 in shoulder season for severe lack of data
  filter(!(home =='011' & location == 'bedroom' & energy_cluster == 'shoulder')) %>%
    mutate(
      median_diff_pct = (median_sample - median_entire)/median_entire*100,
      # mean_diff_pct = (mean_sample - mean_entire)/mean_entire*100,
      # median_ratio = median_sample/median_entire,
      # variance_ratio = variance_sample/variance_entire,
      # iqr_diff_pct = (iqr_sample-iqr_entire)/iqr_entire*100,
      # variance_diff_pct = (variance_sample-variance_entire)/variance_entire*100,
      max_hour_diff = (max_hour_sample - max_hour_entire),
      max_diff_pct = (max_sample - max_entire)/max_entire*100
      # max_ratio = max_sample/max_entire,
      
           ) %>%
    group_by(method, metric, sample_length) %>%
  #mark extreme outliers
  mutate(
            outlier = 
                     case_when(  kld > median(kld)+
                    1.5*IQR(kld)~ TRUE,
                    TRUE ~FALSE),
            ext_outlier = 
                     case_when(  kld > median(kld)+
                    3*IQR(kld)~ TRUE,
                    TRUE ~FALSE),

    ) %>% ungroup()

# count the fraction of extreme outliers overall and for each condition

outlier_count_total_time <- entropy_df_clean %>% filter(method == 'time')%>%
  summarise(outlier_frac = sum(outlier == TRUE)/n(),
            .groups = 'drop') %>% pull(outlier_frac)

outlier_count_total_shape <- entropy_df_clean %>% filter(method == 'shape')%>%
  summarise(outlier_frac = sum(outlier == TRUE)/n(),
            .groups = 'drop') %>% pull(outlier_frac)

ext_outlier_count_total_time <- entropy_df_clean %>% filter(method == 'time')%>%
  summarise(ext_outlier_frac = sum(ext_outlier == TRUE)/n(),
            .groups = 'drop') %>% pull(ext_outlier_frac)

ext_outlier_count_total_shape <- entropy_df_clean %>% filter(method == 'shape')%>%
  summarise(ext_outlier_frac = sum(ext_outlier == TRUE)/n(),
            .groups = 'drop') %>% pull(ext_outlier_frac)

outlier_count <- entropy_df_clean %>%
  group_by(method, metric, sample_length, energy_cluster, home, location) %>%
  summarize(n_samples = n(),
            outlier_n = sum(outlier == TRUE),
            outlier_frac = outlier_n/n_samples,
            ext_outlier_n = sum(ext_outlier == TRUE),
            ext_outlier_frac = ext_outlier_n/n_samples,
            .groups = 'drop')

entropy_df_clean <- left_join(
  entropy_df_clean, outlier_count,
  by = c('method', 'metric', 'sample_length', 'energy_cluster', 'home', 'location'))

# omit extreme outliers from data if omit_outliers is TRUE
entropy_df_clean <- if(omit_outliers == FALSE) {entropy_df_clean
  }else if (omit_outliers == 'normal'){
  filter(entropy_df_clean, outlier == FALSE)
  }else if(omit_outliers == 'extreme'){
  filter(entropy_df_clean, ext_outlier == FALSE)
  }

# find max value for each method and metric for scaling
kld_max_values <- entropy_df_clean %>%
  group_by(method, metric)%>%
  summarize(kld_max = max(kld), .groups = 'drop')


entropy_df_clean <- entropy_df_clean %>%
  left_join(kld_max_values, by = c('method','metric'))%>%
  mutate(rep = 1-kld/kld_max)

entropy_time <- entropy_df_clean %>% filter(method == 'time')
entropy_shape <- entropy_df_clean %>% filter(method == 'shape')

```

* `r signif(outlier_count_total_time*100, 2)`% of sample Time kld values are high outliers within given method, metric, and sample length

* `r signif(ext_outlier_count_total_time*100, 2)`% of sample Time kld values are extreme high outliers within given method, metric, and sample length

* `r signif(outlier_count_total_shape*100, 2)`% of sample Shape kld values are high outliers within given method, metric, and sample length

* `r signif(ext_outlier_count_total_shape*100, 2)`% of sample Shape kld values are extreme high outliers within given method, metric, and sample length

* omitting high outliers does lead to ceratin sensors being underrepresented (but mostly when they had a small sample size)

# Time-Structured Represenetativeness

## Rep Summary Plots

### Example Plot
```{r, fig.height=3, fig.width = 3}
a <- entropy_time %>% filter(metric == 'pm25', energy_cluster == 'heat')

summary <- a %>%
  group_by(method, metric, energy_cluster, sample_length) %>%
  summarize(n_sample_length= n(), y_label = min(rep)-0.05,
            .groups = 'drop')

ggplot(a, aes(x = sample_length, group = sample_length,
                   y = rep))+
  geom_violin(width = 1.75, color = 'darkgrey')+
  geom_boxplot(width=0.35, outlier.shape = NA,
                 color = 'black',
                 lwd = 0.5)+
  # geom_text(aes(label = (ext_outlier_n*100) %>% signif(2)),
  #           y = 0.75, size = xsmall)+
  facet_wrap(vars(metric, energy_cluster))+
  geom_hline(yintercept = thresh_vector, linetype = 'dashed')+
  geom_text(data = summary, aes(label = n_sample_length, y = y_label),
            size = 2)+
  ylab('Time-Structured Representativeness')

```

### All conditions
```{r, fig.height=5, fig.width = 8}

summary <- entropy_time %>%
  group_by(method, metric, energy_cluster, sample_length) %>%
  summarize(n_sample_length= n(), y_label = min(rep)-0.05,
            .groups = 'drop')

ggplot(entropy_time, aes(x = sample_length, group = sample_length,
                   y = rep))+
  geom_violin(width = 1.75, color = 'darkgrey')+
  geom_boxplot(width=0.35, outlier.shape = NA,
                 color = 'black',
                 lwd = 0.5)+
  # geom_text(aes(label = (ext_outlier_n*100) %>% signif(2)),
  #           y = 0.75, size = xsmall)+
  facet_wrap(vars(metric, energy_cluster))+
  geom_hline(yintercept = thresh_vector, linetype = 'dashed')+
  geom_text(data = summary, aes(label = n_sample_length, y = y_label),
            size = 2)+
  ylab('Time-Structured Representativeness')+
  ggtitle('Samples from all homes pooled')


```



```{r, fig.height=3, fig.width = 8}


met <- 'pm25'

map(c('pm25', 'voc'), function(x_metric){
a <- entropy_time %>% filter(sample_length %in% c(3,7,15) &
                               !is.na(rep) &
                               metric == x_metric)

  lvls <- levels(as.factor(a$sample_length))
  n <- by(a, a$sample_length, function(x) sum(x$rep))
  
  above1 <- by(a, a$sample_length, function(x) {
    (sum(x$rep >thresh_vector[1])/length(x$rep)*100) %>%
      signif(2)
  }
  )
  
  above2 <- by(a, a$sample_length, function(x) {
    (sum(x$rep >thresh_vector[2])/length(x$rep)*100) %>%
      signif(2)
  }
  )
  
  labels <- paste0(lvls,", n=",as.integer(n),", ", above1, "%>",
                   thresh_vector[1], ',  ',above2, "%>",thresh_vector[2])
  
  
ggplot(a)+
  geom_density(aes(x = rep, fill = as.factor(sample_length)), alpha = 0.3)+
  # geom_text(aes(label = (ext_outlier_n*100) %>% signif(2)),
  #           y = 0.75, size = xsmall)+
  facet_wrap(vars(metric))+
  geom_vline(xintercept = thresh_vector, linetype = 'dashed')+
  xlab('Time-Structured Representativeness')+
  ggtitle('Samples from all homes, rooms, and seasons pooled')+
      labs(fill = 'Length of Sample, days')+
    theme_classic()+
    theme(
      axis.text.y = element_blank(),
      axis.ticks.y = element_blank()
    )+
    scale_fill_manual( values = length_colors,
                       labels=labels)+
  ylab('Amount of Samples')+
  coord_cartesian(xlim = c(0,1))
}
)
```



### One Home

* find home with most data
```{r}
data_summary <- 
  entropy_time %>%
  filter(home %in% homes_tier3) %>%
  group_by(home, location, energy_cluster) %>%
  summarize(n_samples = n(), .groups = 'drop')

```

** for heating season
```{r}
# top homes for heat season
a <- data_summary %>% filter(energy_cluster == 'heat')

a[ order(a$n_samples, decreasing = TRUE),] %>%
  head(15)
```

** for shoulder season
```{r}
# top homes for shoulder season
a <- data_summary %>% filter(energy_cluster == 'shoulder')

a[ order(a$n_samples, decreasing = TRUE),] %>%
  head(15)
```

** for ac season
```{r}
# top homes for ac season
a <- data_summary %>% filter(energy_cluster == 'ac')

a[ order(a$n_samples, decreasing = TRUE),] %>%
  head(15)
```


* use Homes 9 and 12 as exampes because they have the most data in most seasons for ost rooms
```{r, fig.height=5, fig.width = 8}

loc <- if(pooled_rooms == TRUE) 'pooled' else 'living'

hm <- '009'

a <- entropy_time %>%
  filter(home==hm, location == loc)

summary <- a %>%
  group_by(method, metric, energy_cluster, sample_length) %>%
  summarize(n_sample_length= n(), y_label = min(rep)-0.05,
            .groups = 'drop')

ggplot(a, aes(x = sample_length, group = sample_length,
                   y = rep))+
  geom_violin(width = 1.75, color = 'darkgrey')+
  geom_boxplot(width=0.35, outlier.shape = NA,
                 color = 'black',
                 lwd = 0.5)+
  # geom_text(aes(label = (ext_outlier_n*100) %>% signif(2)),
  #           y = 0.75, size = xsmall)+
  facet_wrap(vars(metric, energy_cluster))+
  geom_hline(yintercept = thresh_vector, linetype = 'dashed')+
  geom_text(data = summary, aes(label = n_sample_length, y = y_label),
            size = 2)+
  ylab('Time-Structured Representativeness')+
  ggtitle(paste('Home', hm, '-- Room=', loc))




hm <- '012'

a <- entropy_time %>%
  filter(home==hm, location == loc)

summary <- a %>%
  group_by(method, metric, energy_cluster, sample_length) %>%
  summarize(n_sample_length= n(), y_label = min(rep)-0.05,
            .groups = 'drop')

ggplot(a, aes(x = sample_length, group = sample_length,
                   y = rep))+
  geom_violin(width = 1.75, color = 'darkgrey')+
  geom_boxplot(width=0.35, outlier.shape = NA,
                 color = 'black',
                 lwd = 0.5)+
  # geom_text(aes(label = (ext_outlier_n*100) %>% signif(2)),
  #           y = 0.75, size = xsmall)+
  facet_wrap(vars(metric, energy_cluster))+
  geom_hline(yintercept = thresh_vector, linetype = 'dashed')+
  geom_text(data = summary, aes(label = n_sample_length, y = y_label),
            size = 2)+
  ylab('Time-Structured Representativeness')+
  ggtitle(paste('Home', hm, '-- Room=', loc))


```


## Comparison of Diurnal Trends of Samples to those of Long-Term Period
```{r}
# variables for testing---------------
# data <- entropy_time
# x_home <- '009'
# x_location <- 'living'
# x_energy_cluster <- 'heat'
# x_metric <- 'pm25'
# x_sample_lengths <- 3
# sample_lengths <- c(3,7,15)

# rm(data, x_home, x_location, x_energy_cluster, x_metric, x_sample_length,
#    sample_lengths)

# function-----------------
diurn.rep.plot <- function(data, x_home, x_location, x_energy_cluster, x_metric,
         sample_lengths = c(3,7,15)){
  
  data_condition <- data %>%
    filter(home == x_home, location == x_location,
           energy_cluster == x_energy_cluster, metric == x_metric)
  
  # pull data set from entire monitoring period of given data set
  # should only be one data set
  entire_data <- data_condition %>%pull(entire_data) %>% unique()
  
  if(length(entire_data)>1) stop(paste('more than one long monitoring period\n',
                                       'check that condition is unique'))
  
  samples <- 
    # for each sample length, extract data from one sample
    map(sample_lengths, function(x_sample_lengths){
  
    data_sample_length <- data_condition %>%
      filter(sample_length == x_sample_lengths)
    
  # find sample closest to median (or 25 percentile) representativeness value
  # for given home in given location in given season for given sample length
  rep_value <- data_sample_length %>% pull(rep) %>% quantile(0.25)
  
  
  
  sample_results <- data_condition[
    which(abs(rep_value - data_condition$rep) ==
            min(abs(rep_value - data_condition$rep))), ]
  
    # pick lower rep sample if median is between two samples
  sample_results <- if(length(sample_results)>1){
    sample_results[which(sample_results$rep == min(sample_results$rep)), ]
  } else sample_results

  # return sample_data
  list(
    'data' = sample_results['sample_data'],
    'rep' = sample_results[['rep']],
    'sample_length' = x_sample_lengths
  )
  
  }
  )
  
  # combine data from samples and entire data set
  all_data <-
  map(samples, function(x_samples){
    tibble(
      hour = c(0:23),
    mean = x_samples[['data']][['sample_data']][['sample_data']],
    sample_length = rep(x_samples[['sample_length']], 24) %>% as.character()
    )
    
  })%>% bind_rows() %>%
    bind_rows(
      tibble(
      hour = c(0:23),
    mean = unlist(entire_data),
    sample_length = rep('entire_period', 24)
    )
    )
  
  rep_values <- 
    map(samples, function(x_samples){
    tibble(
    rep = x_samples[['rep']],
    sample_length = x_samples[['sample_length']]%>% as.character()
    )
  })%>% bind_rows() %>%
    bind_rows(
      tibble(
    rep = NA,
    sample_length = 'entire_period'
    )
    )%>%
    left_join(
      all_data %>%
        filter(hour == 0) %>%
        select(sample_length, mean),
      by = 'sample_length'
    ) %>%mutate(
      # label = paste('Rep=', signif(rep, 2)),
      # y_label = mean*3
    )

      labels <- by(rep_values, rep_values$sample_length,
                   function(x) {
                     paste(x$sample_length, '- Rep=', signif(x$rep, 2))
                   })

  ggplot(all_data, aes(x = hour, y = mean,
                       color = sample_length,
                       fill = sample_length))+
    geom_line()+
    geom_point()+
    # geom_text(data = rep_values, aes(y = y_label,
    #                                  label = paste('Rep=', signif(rep, 2))),
    #           x = -Inf, hjust = 0)+
    scale_fill_manual(
      breaks = c(sample_lengths %>% as.character(), 'entire_period'),
      values = c(cbbPalette['light_blue'],
                   cbbPalette['light_orange'],
                   cbbPalette['purple'],
                   cbbPalette['black'])%>% unname(),
      labels= labels,
      aesthetics = (c('color', 'fill'))
    )+
    ggtitle(label = paste('Home', x_home, '--- Room=', x_location,
                          '--- Season=', x_energy_cluster))+
    ylab(paste('Mean', x_metric))+
    xlab('Hour of Day')

}



```


* pick homes, seasons, (and rooms if not pooled)
```{r}

if(pooled_rooms == TRUE) {
  map(c('pm25', 'voc'), function(y_metric){
  map(c('009', '012'), function(y_home){
  map(c('heat', 'shoulder', 'ac'), function(y_energy_cluster){
    diurn.rep.plot(
    data = entropy_time,
    x_home = y_home, x_location = 'pooled',
    x_energy_cluster = y_energy_cluster, x_metric = y_metric
    )
  })
  })
  })
  

} else if(pooled_rooms == FALSE){

    map(c('pm25', 'voc'), function(y_metric){
  map(c('009', '012'), function(y_home){
  map(c('heat', 'shoulder'), function(y_energy_cluster){
  map(c('living', 'kitchen', 'bedroom'), function(y_location){
    diurn.rep.plot(
    data = entropy_time,
    x_home = y_home, x_location = y_location,
    x_energy_cluster = y_energy_cluster, x_metric = y_metric
    )
  })
  })
  })
    })
  

}


# testing----------



# test specific cases

# # pooled rooms
# diurn.rep.plot(entropy_time, '009', 'pooled', 'heat', 'pm25')
# diurn.rep.plot(entropy_time, '012', 'pooled', 'heat', 'pm25')
# 
# 
# # not pooled rooms
# diurn.rep.plot(entropy_time, '009', 'bedroom', 'heat', 'pm25')
# diurn.rep.plot(entropy_time, '009', 'kitchen', 'heat', 'pm25')
# diurn.rep.plot(entropy_time, '009', 'bedroom', 'heat', 'pm25')
# 
# diurn.rep.plot(entropy_time, '012', 'living', 'heat', 'pm25')
# diurn.rep.plot(entropy_time, '012', 'kitchen', 'heat', 'pm25')
# diurn.rep.plot(entropy_time, '012', 'bedroom', 'heat', 'pm25')


```














# All Lines Commented Out Below


<!-- * for each threshold/sample length, plot deviation from max_hour of entire monitoring -->
<!-- period -->
<!-- ```{r} -->

<!-- # plot with pooled homes -->
<!-- deviation.plot <- function(stat, samp_length, threshold, data){ -->

<!--   if(stat == 'max_hour_diff') { -->

<!--     precision_limits <- c(-1,1) -->
<!--     meth <- 'time' -->
<!--     } else if(stat == 'max_diff_pct'){ -->
<!--     precision_limits <-c(-30,30) -->
<!--           meth <- 'time' -->

<!--       } else if(stat == 'median_diff_pct'){ -->
<!--     precision_limits <-c(-10,10) -->
<!--             meth <- 'shape' -->

<!--     } -->

<!--   if(stat == 'max_hour_diff'){ -->
<!--     y_label <- 'Difference Between\nHour of Sample Avg Maximum\nand Hour of Long-term Avg Maximum' -->
<!--   } else if(stat == 'max_diff_pct'){ -->
<!--     y_label <- 'Percent Difference Between\nSample Maximum Avg Value\nand Long-term Maximum Avg Value' -->
<!--   }else if(stat == 'median_diff_pct'){ -->
<!--     y_label <- 'Percent Difference Between\nSample Median Value\nand Long-term Median Value' -->
<!--   } -->

<!--   df_sample_length <- data %>% -->
<!--     filter(sample_length == samp_length, -->
<!--            method == meth) -->

<!--   a <- df_sample_length %>% -->
<!--     filter(rep > threshold) -->

<!--     percent_over_thresh <- nrow(a)/nrow(df_sample_length)*100 -->

<!--     within_precision <- a %>% -->
<!--     group_by(method, metric, energy_cluster) %>% -->
<!--     summarize(n_precision = sum( -->
<!--       between(get(stat), -->
<!--               precision_limits[1], -->
<!--               precision_limits[2]) -->
<!--       ), -->
<!--               pct_precision = n_precision/n()*100, -->
<!--               .groups = 'drop') %>% -->
<!--   mutate(pct_category = case_when( -->
<!--     pct_precision>66  ~ 'high', -->
<!--     pct_precision>33 & pct_precision<=66 ~ 'medium', -->
<!--     pct_precision<=33  ~ 'low' -->
<!--   )) -->


<!--   ggplot(a, aes(x = energy_cluster, group = energy_cluster, -->
<!--                                y = get(stat)))+ -->
<!--   geom_violin( -->
<!--     # width = 1, -->
<!--     color = 'darkgrey')+ -->
<!--     geom_boxplot( -->
<!--       width=0.1, -->
<!--       outlier.shape = NA, -->
<!--                  color = 'black', -->
<!--                  lwd = 0.5)+ -->
<!--     # geom_jitter(width = 0.1, size = 0.1)+ -->
<!--       facet_wrap(vars(metric))+ -->
<!--     geom_hline(yintercept = precision_limits, linetype = 'dashed')+ -->
<!--     ylab(label = y_label)+ -->
<!--     ggtitle(paste0(samp_length, '-Day Samples Exceeding Rep Threshold of ', -->
<!--                   threshold, ',\n', -->
<!--                   signif(percent_over_thresh,2), '% of all ', samp_length, -->
<!--                   '-Day samples'))+ -->
<!--     geom_text(data = within_precision, -->
<!--               aes(x = energy_cluster, -->
<!--                   color = pct_category, -->
<!--                   label = paste(signif(pct_precision/100,2)) -->
<!--                   ), -->
<!--                y = Inf, vjust = 1, -->
<!--               # position = position_dodge(width = 0.75) -->
<!--               )+ -->
<!--     scale_color_manual( -->
<!--       breaks = c('high', 'medium', 'low'), -->
<!--       labels = c('>0.66', '0.33-0.66', '<0.33'), -->
<!--       values = c(cbbPalette['green'], -->
<!--                  cbbPalette['light_orange'], -->
<!--                  cbbPalette['purple']) %>% unname(), -->
<!--       name = 'Fraction within Precision' -->
<!--     ) -->

<!-- } -->



<!-- ``` -->


<!-- * plot deviations of Hour of Max at different thresholds -->
<!-- ```{r} -->
<!-- dev_stat <- 'max_hour_diff' -->
<!-- dat <- entropy_time %>% filter(metric == 'pm25') -->
<!-- # deviation.plot(dev_stat, 0.5) -->
<!-- deviation.plot(dev_stat, 3, 0.75, data = dat) -->
<!-- deviation.plot(dev_stat, 7, 0.75, data = dat) -->
<!-- deviation.plot(dev_stat, 15, 0.75, data = dat) -->

<!-- deviation.plot(dev_stat, 3, 0.9, data = dat) -->
<!-- deviation.plot(dev_stat, 7, 0.9, data = dat) -->
<!-- deviation.plot(dev_stat, 15, 0.9, data = dat) -->
<!-- ``` -->
<!-- * PM2.5 has a secondary peak where the sample max is about 9-10 hours before long-term max because of dual diurnal peaks (dinner usually but not always larger)  -->

<!-- ```{r} -->
<!-- dev_stat <- 'max_hour_diff' -->
<!-- dat <- entropy_time %>% filter(metric == 'voc') -->
<!-- # deviation.plot(dev_stat, 0.5) -->
<!-- deviation.plot(dev_stat, 3, 0.75, data = dat) -->
<!-- deviation.plot(dev_stat, 7, 0.75, data = dat) -->
<!-- deviation.plot(dev_stat, 15, 0.75, data = dat) -->

<!-- deviation.plot(dev_stat, 3, 0.9, data = dat) -->
<!-- deviation.plot(dev_stat, 7, 0.9, data = dat) -->
<!-- deviation.plot(dev_stat, 15, 0.9, data = dat) -->
<!-- ``` -->
<!-- * VOC do not have the same bi-modal tendency, but the peak is less pronounced and may still deviate by more than a couple hours -->


<!-- * plot deviations of Max Hourly Value at different thresholds -->
<!-- ```{r} -->
<!-- dev_stat <- 'max_diff_pct' -->
<!-- dat <- entropy_time %>% filter(metric == 'pm25') -->
<!-- deviation.plot(dev_stat, 3, 0.75, data = dat) -->
<!-- deviation.plot(dev_stat, 7, 0.75, data = dat) -->
<!-- deviation.plot(dev_stat, 15, 0.75, data = dat) -->

<!-- deviation.plot(dev_stat, 3, 0.9, data = dat) -->
<!-- deviation.plot(dev_stat, 7, 0.9, data = dat) -->
<!-- deviation.plot(dev_stat, 15, 0.9, data = dat) -->
<!-- ``` -->


<!-- * with homes not pooled -->
<!-- ```{r} -->
<!-- deviation.plot.homes <- function(stat, threshold){ -->

<!--   precision_limits <- if(stat == 'max_hour_diff') c(-1,1) else c(-10,10) -->

<!--   if(stat == 'max_hour_diff'){ -->
<!--     y_label <- 'Hour of Sample Avg Maximum - Hour of Long-term Avg Maximum' -->
<!--   } else if(stat == 'max_diff'){ -->
<!--     y_label <- 'Sample Maximum Avg Value - Long-term Maximum Avg Value' -->
<!--   } -->
<!--   a <- entropy_df_clean %>% filter(rep > threshold) -->

<!--   percent_over_thresh <- nrow(a)/nrow(entropy_df_clean)*100 -->

<!--   ggplot(entropy_df_clean, aes(x = home, group = home, y = get(stat)))+ -->
<!--   geom_violin( -->
<!--     # width = 1, -->
<!--     color = 'darkgrey')+ -->
<!--     geom_boxplot( -->
<!--       # width=0.2, -->
<!--       outlier.shape = NA, -->
<!--                  color = 'black', -->
<!--                  lwd = 0.5)+ -->
<!--     # geom_jitter(aes(color = sample_length), width = 0.25, size = 0.1)+ -->
<!--       facet_wrap(vars(metric, energy_cluster))+ -->
<!--     geom_hline(yintercept = precision_limits, linetype = 'dashed')+ -->
<!--     ylab(label = y_label)+ -->
<!--     ggtitle(paste0('Samples Exceeding Rep Threshold of ', -->
<!--                   threshold, ',\n', -->
<!--                   signif(percent_over_thresh,3), '% of all samples')) -->

<!-- } -->

<!-- ``` -->

<!-- # Magnitude-Based Representativeness -->



<!-- ```{r, fig.height=5, fig.width = 8} -->
<!-- summary <- entropy_shape %>% -->
<!--   group_by(method, metric, energy_cluster, sample_length) %>% -->
<!--   summarize(n_sample_length= n(), y_label = min(rep)-0.05, -->
<!--             .groups = 'drop') -->

<!-- ggplot(entropy_shape, aes(x = sample_length, group = sample_length, -->
<!--                    y = rep))+ -->
<!--   geom_violin(width = 1.75, color = 'darkgrey')+ -->
<!--   geom_boxplot(width=0.35, outlier.shape = NA, -->
<!--                  color = 'black', -->
<!--                  lwd = 0.5)+ -->
<!--   # geom_text(aes(label = (ext_outlier_n*100) %>% signif(2)), -->
<!--   #           y = 0.75, size = xsmall)+ -->
<!--   facet_wrap(vars(metric, energy_cluster))+ -->
<!--   geom_hline(yintercept = thresh_vector, linetype = 'dashed')+ -->
<!--   geom_text(data = summary, aes(label = n_sample_length, y = y_label), -->
<!--             size = 2)+ -->
<!--   ylab('Magnitude-Based Representativeness') -->

<!-- ``` -->

<!-- * plot deviations of Median Value at different thresholds -->
<!-- ```{r} -->
<!-- dev_stat <- 'median_diff_pct' -->
<!-- dat <- entropy_shape %>% filter(metric == 'pm25') -->
<!-- deviation.plot(dev_stat, 3, 0.75, data = dat) -->
<!-- deviation.plot(dev_stat, 7, 0.75, data = dat) -->
<!-- deviation.plot(dev_stat, 15, 0.75, data = dat) -->

<!-- deviation.plot(dev_stat, 3, 0.9, data = dat) -->
<!-- deviation.plot(dev_stat, 7, 0.9, data = dat) -->
<!-- deviation.plot(dev_stat, 15, 0.9, data = dat) -->
<!-- ``` -->


